[
["index.html", "Math 245 Notes Getting Started Getting help", " Math 245 Notes Katie St. Clair, Carleton College 2019-09-03 Getting Started This manual is designed to provide students in Math 245 (Applied Regression Analysis) with supplemental notes and examples. Getting help Try to start your homework or projects early enough to seek help from me! You can do this in a variety of ways: Office visit: Stop by office hours or drop by anytime my door is open. This is the easiest way for me to answer any class questions that you have or help you debug troublesome R code. Email: I can usually clarify any homework questions over email. If you are running in an R problem, you should snapshot your R code and error and send it to me via email. I can often figure out your code issue this way! Stats Lab: Visit the stats lab assistants in CMC 201 for help using R. "],
["review.html", "Chapter 1 Review of Statistical Inference 1.1 Sampling Distribution 1.2 Central Limit Theorem 1.3 Hypothesis testing 1.4 Confidence Intervals", " Chapter 1 Review of Statistical Inference 1.1 Sampling Distribution Suppose we take a random sample of size \\(n\\) from a large population of individuals. We record a variable and compute a statistic like a sample mean or sample proportion from this data. The sampling distribution of the statistic describes how the stat is distributed over many random samples: take a random sample of size \\(n\\) record the variable of interest (data) for the \\(n\\) sampled cases compute the statistic from the data repeat 1-3 many, many times plot the distribution of your statistics from step 4. 1.2 Central Limit Theorem Under the right conditions, the distribution of many sample means \\(\\bar{x}\\) or proportions \\(\\hat{p}\\) will look like a normal distribution that is centered at the true population parameter (mean \\(\\mu\\) or proportion \\(p\\)) value. Shape: normally distributed (“bell-shaped”) Center: true population parameter value Variation: called the standard error of the statistic which measures the standard deviation of your statistic over many samples The conditions for “normality” (symmetry) have to do with both the sample sized and the distribution of your variable. If your measurements are very symmetric (e.g. heights of woman in an adult population) then the sample size \\(n\\) can be very small and the sample mean will behave normally. As your measurements get more skewed (e.g. income per person in a large city), then the sample size \\(n\\) needs to get larger for the sample mean to behave normally. Outliers are always a problem, even if you have a large sample size, since means can be easily influenced by one or two very unusual cases. 1.2.1 Standard error The standard error of the sample mean \\(\\bar{x}\\) measures the variability of this statistic and is the standard deviation of the sampling distribution for \\(\\bar{x}\\). Roughly, the SE of any statistic tells us how it will vary from sample to sample. For the sample mean statistic, the estimated SE is equal to \\[ SE(\\bar{x}) = \\dfrac{s}{\\sqrt{n}} \\] where \\(s\\) is the sample standard deviation of your variable. For the difference of two sample means, \\(\\bar{x}_1 - \\bar{x}_2\\), the standard error is \\[ SE(\\bar{x}_1 - \\bar{x}_2) = \\sqrt{\\dfrac{s^2_1}{n_1} + \\dfrac{s^2_2}{n_2}} \\] where \\(n_i\\) is the sample size of sample \\(i\\) and \\(s_i\\) is the sample SD of population \\(i\\). For the sample proportion \\(\\hat{p}\\), the standard error is \\[ SE(\\hat{p}) = \\sqrt{\\dfrac{p(1-p)}{n}} \\] where \\(p\\) is the true population proportion. To estimate this SE we just use the sample proportion \\(\\hat{p}\\) in the SE formula. 1.3 Hypothesis testing Your null hypothesis \\(H_0\\) is a specific claim about a population parameter of interest. Examples include: \\(H_0: p = 0.5\\) (population proportion is 0.50, or 50%) \\(H_0: \\mu_1 - \\mu_2 = 0\\) (the mean of population 1 \\(\\mu_1\\) is equal to the mean of population 2 \\(\\mu_2\\)) The alternative hypothesis specifies another, more general, scenario for the population(s). Examples include: \\(H_0: p &gt; 0.5\\) (population proportion greater than 0.50) \\(H_0: \\mu_1 - \\mu_2 \\neq 0\\) (the two populations have difference means) You then use a test statistic to measure how far the data (e.g. sample statistic) deviates from what is expected assuming the null is true. Often these test stats take form of a standardized values so large absolute values indicate data that deviates a lot from what is expected if the null is true. For a hypothesis about one population mean \\(H_0: \\mu = \\mu_0\\), we use a t-test statistic: \\[ t = \\dfrac{\\bar{x} - \\mu_0}{s/\\sqrt{n}} \\] To test for a difference in two means, we use another t-test stat: \\[ t = \\dfrac{(\\bar{x}_1 - \\bar{x}_2) - 0}{\\sqrt{\\dfrac{s^2_1}{n_1} + \\dfrac{s^2_2}{n_2}}} \\] We then construct the sampling distribution of the test statistic under the assumption that the null hypothesis is true. Using this model, we compute a p-value by finding the probability of getting a test stat as, or more, extreme as the observed test stat. The p-value measures the probability of observing data as unusual, or more usual, than the observed data if the null is true. Small p-values indicate data that would rarely be seen if the null is true which means we have evidence (data) that supports the alternative hypothesis. If we use a t-test statistic, then we use a t-distribution to compute a p-value. If t is the test stat value then either command below will give a one-sided (\\(&lt;\\) or \\(&gt;\\)) p-value: &gt; pt(abs(t), df = , lower.tail = FALSE) # method 1 (gives right tail value) &gt; pt(-abs(t), df = ) # method 2 (gives left tail value) If your alternative is two-sided, you need to double the value given by either command above. The degrees of freedom depends on the type of estimate: for a one-sample mean problem, use \\(df = n-1\\) for a two-sample difference in means problem, let technology get the value! 1.4 Confidence Intervals A confidence interval for a population parameter gives us a range of likely values of the parameter. Most confidence intervals we use in this class are of the form: \\[ \\textrm{estimate} \\pm \\textrm{ margin of error} \\] The idea behind constructing a confidence interval starts with our estimate’s (statistic’s) sampling distribution and margin of error for some level of confidence: The sampling distribution tells us how an estimate varies from sample to sample around the true population parameter. The margin of error for a “C%” confidence interval is computed so that the estimate will be within the margin of error of the true parameter value C% of the time. Another “confidence” interpretation: of all possible samples, C% will yield a confidence interval (using the C% margin of error) that contains the true parameter value. Examples: E.g. for 95% confidence: 95% of all possible samples will give an estimate that is within the (95% level) margin of error of the truth. E.g. for 90% confidence: 90% of all possible samples will give 90% confidence interval that contains the truth. Normally distributed estimates: when a sampling distribution is roughly normally distributed, we can approximately say that 95% margin of error \\(\\approx 1.96 \\times SE\\) 90% margin of error \\(\\approx 1.65 \\times SE\\) 99% margin of error \\(\\approx 2.58 \\times SE\\) A higher level of confidence will lead to a larger margin of error: We need a larger margin of error to get a higher fraction of samples that close to the population parameter. The margin of errors given above are ballpark values. We will mostly be using a more trustworthy distribution in our class, the t-distribution, to compute how many SE’s we go to be a certain level of confidence: \\[ \\textrm{margin of error } = t^*_{df} \\times SE \\] where \\(t^*\\) is the \\((100-C)/2\\) percentile from the t-distribution with \\(df\\) degrees of freedom. Examples of confidence levels: for 95% confidence, \\(t^*\\) is the 2.5% percentile (or 97.5%) &gt; qt(.025, df= ) # for 95% confidence for 90% confidence, \\(t^*\\) is the 5% percentile (or 95%) &gt; qt(.05, df= ) # for 90% confidence Examples of degrees of freedom: for a one-sample mean problem, use \\(df = n-1\\) for a two-sample difference in means problem, let technology get the value! "],
["slr.html", "Chapter 2 Simple Linear Regression", " Chapter 2 Simple Linear Regression "],
["mlr.html", "Chapter 3 Multiple Regression", " Chapter 3 Multiple Regression "],
["logistic.html", "Chapter 4 Logistic Regression", " Chapter 4 Logistic Regression "],
["poisson.html", "Chapter 5 Poisson Regression", " Chapter 5 Poisson Regression "],
["rrstudio.html", "A R and Rstudio A.1 Running Rstudio A.2 Installing R A.3 Installing Rstudio A.4 Installing R packages", " A R and Rstudio R is a free professional statistical software that is available for use on windows, mac and linux computers. R is a popular tool for researchers from many fields so acquiring basic R skills from our stats classes will be beneficial for this course and career plans! RStudio is a free software that provides a user-friendly interface with R. We will be running R through RStudio in our stats classes. R can be more challenging for a brand new user than other software (like Excel, SPSS, etc) because analyzes are done using written commands rather than using a drop down (point-and-click) menu. But R is very powerful because of the huge variety of statistical methods that it supports (due to the addition of free user contributed packages) and the user’s ability to customize their experience (graphics, new functions, data manipulation, etc). Because R is based on written commands that can be recorded in a variety of ways, it is easy for a user to reproduce, re-do or continue analyzes that were started at a different point in time. This is much harder to do when you are using a bunch of drop-down menu commands to run your analysis! We will emphasize reproducibility in this course by using R Markdown scripts (Section D) to complete our analyzes. A.1 Running Rstudio Browser: You can access an online version of Rstudio from mirage.mathcs.carleton.edu. If you are new to using Rstudio, I encourage you to use mirage rather than installing R/Rstudio on your computer. You can access mirage from anywhere on campus using Eduroam wireless if on a laptop, but from off campus you will first need to turn on Carleton’s VPN prior to logging in. Please install this software! Why use mirage? Any work you create (R scripts, Markdown, pdf, or word docs) are saved on your account located on this server (file path /Accounts/username). If you want to download files from this account, use the “More &gt; Export” drop down menu from the “Files” pane (lower right panel). Mirage also has most R packages that we use in our classes preinstalled so you don’t need to install them before using them. Personal computer: You can download R (Section A.2) and Rstudio (Section A.3) software onto your personal computer. You then open Rstudio to start an R session. You will need install certain R packages that we used in our class that aren’t part of the default package installation. See Section A.4. A.2 Installing R Follow the appropriate link below and complete the default installation. Windows: http://cran.r-project.org/bin/windows/base/ Mac: http://cran.r-project.org/bin/macosx/ A.3 Installing Rstudio Follow the link below and download the free RStudio Desktop Open Source Edition. Windows or Mac: http://www.rstudio.com/ide/download/ A.4 Installing R packages R packages provided added analysis tools that R users contribute to the R community. The default R installation only provides us with a fraction of the available packages. The most straightforward way to install a needed package in Rstudio is to click the Packages tab in the lower right pane. Click the Install button and start typing the package name into Packages field, then click Install to add the package to your available package library. You should only need to install a package once. Alternatively, you can install a package by typing an install.packages command into the Console window. For example, the following command installs the R data package Sleuth3 for The Statistical Sleuth textbook: &gt; install.packages(&quot;Sleuth3&quot;) "],
["renviron.html", "B The R enviroment B.1 Workspace B.2 Working directory B.3 Rstudio projects", " B The R enviroment B.1 Workspace Anything that you load or create in Rstudio (data, vectors, models) are called objects. You can see your current objects in your RStudio Environment pane (upper right). These objects, along with your command history, are contained in what R calls your “Workspace”. When you exit Rstudio, you may be asked if you want to save your workspace as a .RData file before exiting. I strongly encourage you not to do this since it can make it very hard to reproduce your workflow (and it can slow down Rstudio start up). Instead, use R markdown (Chapter D) to document your workflow so you can redo any analysis that you’ve previously done. To change Rstudio’s default startup and exit workspace behavior: From the Tools drop down menu (at the top), select Global Options… Under the General tab, uncheck the “Restore .RData into workspace at startup” In the “Save workspace to .RData on exit:” dropdown, select Never B.2 Working directory The default location that R looks for “stuff” or saves “stuff” is called your Working Directory. For example, the default location of this folder is typically your Documents folder for a Windows machine. You can run the getwd() command to see where your current working directory is located. For my desktop Windows computer, the default working directory location is &gt; getwd() [1] &quot;C:/Users/kstclair/Documents&quot; Or from the mirage server, &gt; getwd() [1] &quot;/Accounts/kstclair&quot; B.3 Rstudio projects RStudio (not standalone R) has a feature called Projects that make it easy to start RStudio in a particular working directory. You can create different Projects for different classes (or research projects). Your first task in Rstudio for Math 245 will be to create a Math 245 project: Find the Project button in the upper right-hand corner of Rstudio. Select New Project. Click New Directory from the New Project dialog box. Click on New project (again), then enter Math245 as your Directory name (no spaces). Use the Browse button to put this project in a good spot on your computer or accept the default location on mirage. Click on Create Project. Your Rstudio session should not change in looks all that much but check your computer should now contain a Math245 folder in the location you chose. This folder will contain a Math245.Rproj icon. Your working directory is now set to this Math245 folder. Check this with the getwd() command. Starting your Math245 project: Rstudio default settings are to start up your last project when you reopen Rstudio. So just opening Rstudio (or loggin onto mirage) usually opens your Math245 project. You will see your project name in the upper right-hand project button location. Alternatively, start your R project by double clicking on the project icon in your Math245 folder. You will know you are in You can also open or change projects with the drop-down project menu. "],
["rreview.html", "C R for basic data analysis C.1 Basics C.2 Data C.3 EDA C.4 Factor variables", " C R for basic data analysis C.1 Basics C.1.1 Quick Tips In the Console window: You type commands after the prompt &gt; and hit Enter to execute the command. The results of the command will be displayed below the command and preceded by a line counter enclosed in brackets (e.g. [1]). You can scroll back to, edit, and execute previous commands using the up arrow on your keyboard. If you prematurely hit enter before a command is completed to R’s satisfaction you will see a + prompt which asks you to finish the command. Simply complete the command after the + and hit Enter. If you get stuck in a cycle of + prompts you can get back to a fresh command prompt &gt; by hitting the Esc key. For example, try: &gt; 1+3 &lt;ENTER&gt; [1] 4 &gt; 1+ + 3 &lt;ENTER&gt; [1] 4 &gt; 1+ + &lt;ESC&gt; User interrupt requested For information about a command type ?commandname. C.1.2 Objects Everything in R is an object. You can assign a name to an object by using the assignment operator &lt;-. You can see the current list of objects in your R workspace by typing ls() or by looking in the Environment tab in Rstudio. You can remove objects from your workspace with the command rm(name) where name is the name of the object you want to delete. C.1.3 Vectors Vectors are a simple type of object and even single numbers (called scalars) are vectors with a length of 1. Here are a few ways to create vectors. The : operator creates a sequence of numbers that increase or decrease by 1. &gt; 3:10 ## [1] 3 4 5 6 7 8 9 10 &gt; 0:-3 ## [1] 0 -1 -2 -3 The seq function also creates sequences of a given length or increment. &gt; seq(1,3,by=.5) ## [1] 1.0 1.5 2.0 2.5 3.0 &gt; seq(1,3,length=10) ## [1] 1.000000 1.222222 1.444444 1.666667 1.888889 2.111111 2.333333 ## [8] 2.555556 2.777778 3.000000 Use the combine function c() to create any particular arrangement: &gt; c(5,2,4,-1) ## [1] 5 2 4 -1 &gt; x &lt;- c(5,2,4,-1) &gt; x ## [1] 5 2 4 -1 &gt; y &lt;- c(x,0:3,x) &gt; y ## [1] 5 2 4 -1 0 1 2 3 5 2 4 -1 The rep command allows repetition: &gt; rep(0,5) ## [1] 0 0 0 0 0 &gt; rep(c(0,1),c(3,2)) ## [1] 0 0 0 1 1 You can also create vectors of characters (letters or words): &gt; c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &gt; c(&quot;abc&quot;,&quot;de&quot;) ## [1] &quot;abc&quot; &quot;de&quot; Logical (true/false) vectors do not use double quotes: &gt; c(T,T,F) ## [1] TRUE TRUE FALSE C.1.4 Arithmetic Here’s some basic commands: &gt; x &lt;- 1:4 &gt; x*2 ## [1] 2 4 6 8 &gt; x^2 ## [1] 1 4 9 16 &gt; (x-2)/3 ## [1] -0.3333333 0.0000000 0.3333333 0.6666667 Arithmetic involving vectors is done elementwise. &gt; y &lt;- c(-1,1,-1,1) &gt; x*y ## [1] -1 2 -3 4 &gt; x-y ## [1] 2 1 4 3 Special functions are available that work elementwise or on the entire vector. Here are a few: &gt; sqrt(x) ## [1] 1.000000 1.414214 1.732051 2.000000 &gt; log(x) ## [1] 0.0000000 0.6931472 1.0986123 1.3862944 &gt; exp(x) ## [1] 2.718282 7.389056 20.085537 54.598150 &gt; sum(x) ## [1] 10 &gt; mean(x) ## [1] 2.5 &gt; sd(x) ## [1] 1.290994 &gt; sqrt(sum(x^2)) ## [1] 5.477226 More summary stats can be found with the commands min, max, median, quantile, summary, and var. You usually use the special functions above with numeric vectors (int or num), but you can use these functions with logical vectors too. The logical vector is coerced into a integer vector with 1 for TRUE and 0 for FALSE. &gt; y &lt;- c(T,T,F) &gt; y ## [1] TRUE TRUE FALSE &gt; sum(y) # number of TRUE&#39;s in y ## [1] 2 &gt; mean(y) # proportion of TRUE&#39;s in y ## [1] 0.6666667 C.1.5 Subsetting You can access one or more elements in a vector by specifying a certain index of elements within the vector: vector[index]. &gt; w&lt;-c(30,50,20,60,40,20) &gt; length(w) ## [1] 6 The first element of w: &gt; w[1] ## [1] 30 The first and third elements: &gt; w[c(1,3)] ## [1] 30 20 All elements except the first and third: &gt; w[-c(1,3)] ## [1] 50 60 40 20 The elements that are at most 40: &gt; w[w &lt;= 40] ## [1] 30 20 40 20 The position of these elements that are at most 40: &gt; which(w &lt;= 40) ## [1] 1 3 5 6 The mean of w and the mean of only the elements in w that are less than or equal to 4: &gt; mean(w) ## [1] 36.66667 &gt; mean(w[w &lt;= 40]) ## [1] 27.5 Expressions involving inequalities create a logical vector which is TRUE when the expression is true: &gt; w &lt;= 40 ## [1] TRUE FALSE TRUE FALSE TRUE TRUE &gt; w == 40 ## [1] FALSE FALSE FALSE FALSE TRUE FALSE So when a vector is indexed by a TRUE/FALSE vector only the TRUE entries will be displayed (and used in any command involving this vector). Here is the logical vector for entries in w that are not equal to 40: &gt; w != 40 ## [1] TRUE TRUE TRUE TRUE FALSE TRUE Here are the values of the entries of w excluding those equal to 40: &gt; w[w != 40] ## [1] 30 50 20 60 20 Here is the sum of the values of the entries of w excluding those equal to 40: &gt; sum(w[w != 40]) ## [1] 180 Adding a logical (T/F) vector tells you how many elements in the vector are equal to TRUE. Here is the number of entries in w that are not equal to 40: &gt; sum(w != 40) ## [1] 5 Finally, the vector operators | and &amp; mean OR and AND, respectively. We can find the entries in w that are less than 30 OR greater than 50 with &gt; (w &lt; 30) | (w &gt; 50) ## [1] FALSE FALSE TRUE TRUE FALSE TRUE We can find the entries that are at most 50 AND at least 30 with &gt; (w &gt;= 30) &amp; (w &lt;= 50) ## [1] TRUE TRUE FALSE FALSE TRUE FALSE C.2 Data C.2.1 Reading Data into R The most common way to read data into R is by storing it in a comma separated values (.csv) format. Non-textbook data files for this class will either be on my webpage http://people.carleton.edu/~kstclair/data. You can read a .csv file into R using its URL or file path (which is system dependent): &gt; mydata &lt;- read.csv(&quot;&lt;data file path&gt;/mydata.csv&quot;) Alternatively, you can download (then upload if using mirage) a needed data set to your data folder located in your Mathxxx folder. Once this is done, and your Mathxxx project is started, you can easily read the data set into R using the command &gt; mydata &lt;- read.csv(&quot;data/mydata.csv&quot;) You don’t need an extended file path name because your project should set your working directory to your Mathxxx folder and the data folder containing you .csv is a subfolder in this working directory. Many textbooks have R packages that contain data sets used in the book. Here I’ll use the SDaA packge used in my Math 255 (Sampling) course. Once you load this library you have automatic access to add textbook data files identified by the name given in the book. &gt; # install.packages(&quot;SDaA&quot;) # only run this once, ever &gt; library(SDaA) &gt; class(agstrat) ## [1] &quot;data.frame&quot; The object agstrat is called a data frame. The rest of this handout will explain how R data frames can be explored, used and changed. C.2.2 Investigating a Data Frame You can see an entire data frame by typing its name. You can see the first or last 5 rows of a data frame with the following commands: &gt; head(agstrat) ## county state acres92 acres87 acres82 farms92 farms87 farms82 ## 1 PIERCE COUNTY NE 297326 332862 319619 725 857 865 ## 2 JENNINGS COUNTY IN 124694 131481 139111 658 671 751 ## 3 WAYNE COUNTY OH 246938 263457 268434 1582 1734 1866 ## 4 VAN BUREN COUNTY MI 206781 190251 197055 1164 1278 1464 ## 5 OZAUKEE COUNTY WI 78772 85201 89331 448 483 527 ## 6 CLEARWATER COUNTY MN 210897 229537 213105 583 699 693 ## largef92 largef87 largef82 smallf92 smallf87 smallf82 region rn ## 1 54 54 42 58 67 48 NC 805 ## 2 14 13 14 42 36 38 NC 241 ## 3 20 19 16 175 186 184 NC 913 ## 4 23 17 9 56 66 55 NC 478 ## 5 6 5 5 56 49 48 NC 1028 ## 6 34 32 23 8 19 13 NC 496 ## weight ## 1 10.23301 ## 2 10.23301 ## 3 10.23301 ## 4 10.23301 ## 5 10.23301 ## 6 10.23301 &gt; tail(agstrat) ## county state acres92 acres87 acres82 farms92 farms87 farms82 ## 295 FRANKLIN COUNTY WA 670149 660813 632519 857 894 856 ## 296 LEA COUNTY NM 2149450 2220431 2178568 544 561 534 ## 297 THURSTON COUNTY WA 59890 56799 67628 811 806 856 ## 298 CARSON CITY (IC) NV 5361 17859 18780 28 37 34 ## 299 BANNOCK COUNTY ID 325338 358189 352306 588 655 617 ## 300 LA PLATA COUNTY CO 587339 613579 589167 709 682 625 ## largef92 largef87 largef82 smallf92 smallf87 smallf82 region rn ## 295 127 140 120 107 109 101 W 371 ## 296 208 205 191 59 67 63 W 259 ## 297 5 4 4 171 143 151 W 394 ## 298 3 2 2 15 15 17 W 295 ## 299 79 81 83 98 112 106 W 148 ## 300 67 79 66 25 39 33 W 112 ## weight ## 295 10.29268 ## 296 10.29268 ## 297 10.29268 ## 298 10.29268 ## 299 10.29268 ## 300 10.29268 You can get the dimensions (# rows by # columns) and variable names is a data frame with &gt; dim(agstrat) ## [1] 300 17 You can see the variable names with &gt; names(agstrat) ## [1] &quot;county&quot; &quot;state&quot; &quot;acres92&quot; &quot;acres87&quot; &quot;acres82&quot; &quot;farms92&quot; ## [7] &quot;farms87&quot; &quot;farms82&quot; &quot;largef92&quot; &quot;largef87&quot; &quot;largef82&quot; &quot;smallf92&quot; ## [13] &quot;smallf87&quot; &quot;smallf82&quot; &quot;region&quot; &quot;rn&quot; &quot;weight&quot; or variable names and types with the structure command &gt; str(agstrat) ## &#39;data.frame&#39;: 300 obs. of 17 variables: ## $ county : Factor w/ 261 levels &quot;ALEXANDER COUNTY&quot;,..: 180 115 254 241 175 37 186 94 243 212 ... ## $ state : Factor w/ 46 levels &quot;AL&quot;,&quot;AR&quot;,&quot;AZ&quot;,..: 27 13 32 20 44 21 37 10 22 14 ... ## $ acres92 : int 297326 124694 246938 206781 78772 210897 507101 332358 402202 535359 ... ## $ acres87 : int 332862 131481 263457 190251 85201 229537 552844 337990 396638 503582 ... ## $ acres82 : int 319619 139111 268434 197055 89331 213105 541015 355823 400466 513458 ... ## $ farms92 : int 725 658 1582 1164 448 583 321 986 1249 488 ... ## $ farms87 : int 857 671 1734 1278 483 699 371 1065 1251 518 ... ## $ farms82 : int 865 751 1866 1464 527 693 341 1208 1320 571 ... ## $ largef92: int 54 14 20 23 6 34 163 56 86 216 ... ## $ largef87: int 54 13 19 17 5 32 180 36 78 204 ... ## $ largef82: int 42 14 16 9 5 23 176 42 69 193 ... ## $ smallf92: int 58 42 175 56 56 8 10 90 42 16 ... ## $ smallf87: int 67 36 186 66 49 19 24 115 38 37 ... ## $ smallf82: int 48 38 184 55 48 13 16 132 28 24 ... ## $ region : Factor w/ 4 levels &quot;NC&quot;,&quot;NE&quot;,&quot;S&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ rn : int 805 241 913 478 1028 496 969 42 676 383 ... ## $ weight : num 10.2 10.2 10.2 10.2 10.2 ... You can view the data frame in Rstudio’s viewer window with &gt; View(agstrat) C.2.3 Accessing Data You can also access and edit information in a data frame by subscripting the data frame. Suppose you want to look at the variable farms92 (the number of farms per county in 1992). This variable is the 6th column in the data frame. You can access its contents with either command: &gt; agstrat[,6] ## [1] 725 658 1582 1164 448 583 321 986 1249 488 1308 657 974 780 ## [15] 293 201 362 309 500 530 491 305 1383 740 325 783 440 832 ## [29] 682 198 283 1000 547 953 771 979 427 963 545 942 949 544 ## [43] 822 955 1421 532 272 1669 308 401 171 480 1433 900 378 58 ## [57] 760 1216 1086 833 682 1280 1262 1029 1190 618 554 497 744 698 ## [71] 786 1305 1058 855 741 828 1140 509 759 1080 658 663 1447 1398 ## [85] 511 1529 623 742 386 468 738 759 746 680 792 327 777 205 ## [99] 1190 629 426 395 721 1367 659 249 550 440 438 74 668 147 ## [113] 488 1367 395 940 602 716 0 433 451 142 537 427 689 179 ## [127] 14 547 872 1444 549 345 235 406 40 705 169 394 219 774 ## [141] 74 561 290 414 781 1037 992 342 179 2760 56 315 49 1226 ## [155] 389 226 334 303 1152 403 2086 946 1342 612 407 986 199 17 ## [169] 704 1120 127 261 642 348 1360 297 404 114 1582 328 404 34 ## [183] 330 132 151 966 146 374 694 455 838 915 812 732 540 108 ## [197] 419 1609 417 560 1903 1956 270 433 617 910 298 288 456 199 ## [211] 507 772 476 113 440 110 1004 199 339 818 689 491 659 215 ## [225] 301 606 355 376 695 889 1234 532 195 711 515 1547 90 651 ## [239] 361 147 747 33 128 137 940 477 445 278 447 162 280 640 ## [253] 1579 29 1031 1006 320 849 1232 267 1441 23 850 612 733 451 ## [267] 179 641 233 661 495 195 508 3157 442 358 107 149 1696 1027 ## [281] 415 490 418 134 257 525 599 366 16 874 419 1054 1257 110 ## [295] 857 544 811 28 588 709 &gt; agstrat$farms92 ## [1] 725 658 1582 1164 448 583 321 986 1249 488 1308 657 974 780 ## [15] 293 201 362 309 500 530 491 305 1383 740 325 783 440 832 ## [29] 682 198 283 1000 547 953 771 979 427 963 545 942 949 544 ## [43] 822 955 1421 532 272 1669 308 401 171 480 1433 900 378 58 ## [57] 760 1216 1086 833 682 1280 1262 1029 1190 618 554 497 744 698 ## [71] 786 1305 1058 855 741 828 1140 509 759 1080 658 663 1447 1398 ## [85] 511 1529 623 742 386 468 738 759 746 680 792 327 777 205 ## [99] 1190 629 426 395 721 1367 659 249 550 440 438 74 668 147 ## [113] 488 1367 395 940 602 716 0 433 451 142 537 427 689 179 ## [127] 14 547 872 1444 549 345 235 406 40 705 169 394 219 774 ## [141] 74 561 290 414 781 1037 992 342 179 2760 56 315 49 1226 ## [155] 389 226 334 303 1152 403 2086 946 1342 612 407 986 199 17 ## [169] 704 1120 127 261 642 348 1360 297 404 114 1582 328 404 34 ## [183] 330 132 151 966 146 374 694 455 838 915 812 732 540 108 ## [197] 419 1609 417 560 1903 1956 270 433 617 910 298 288 456 199 ## [211] 507 772 476 113 440 110 1004 199 339 818 689 491 659 215 ## [225] 301 606 355 376 695 889 1234 532 195 711 515 1547 90 651 ## [239] 361 147 747 33 128 137 940 477 445 278 447 162 280 640 ## [253] 1579 29 1031 1006 320 849 1232 267 1441 23 850 612 733 451 ## [267] 179 641 233 661 495 195 508 3157 442 358 107 149 1696 1027 ## [281] 415 490 418 134 257 525 599 366 16 874 419 1054 1257 110 ## [295] 857 544 811 28 588 709 &gt; agstrat[,&quot;farms92&quot;] ## [1] 725 658 1582 1164 448 583 321 986 1249 488 1308 657 974 780 ## [15] 293 201 362 309 500 530 491 305 1383 740 325 783 440 832 ## [29] 682 198 283 1000 547 953 771 979 427 963 545 942 949 544 ## [43] 822 955 1421 532 272 1669 308 401 171 480 1433 900 378 58 ## [57] 760 1216 1086 833 682 1280 1262 1029 1190 618 554 497 744 698 ## [71] 786 1305 1058 855 741 828 1140 509 759 1080 658 663 1447 1398 ## [85] 511 1529 623 742 386 468 738 759 746 680 792 327 777 205 ## [99] 1190 629 426 395 721 1367 659 249 550 440 438 74 668 147 ## [113] 488 1367 395 940 602 716 0 433 451 142 537 427 689 179 ## [127] 14 547 872 1444 549 345 235 406 40 705 169 394 219 774 ## [141] 74 561 290 414 781 1037 992 342 179 2760 56 315 49 1226 ## [155] 389 226 334 303 1152 403 2086 946 1342 612 407 986 199 17 ## [169] 704 1120 127 261 642 348 1360 297 404 114 1582 328 404 34 ## [183] 330 132 151 966 146 374 694 455 838 915 812 732 540 108 ## [197] 419 1609 417 560 1903 1956 270 433 617 910 298 288 456 199 ## [211] 507 772 476 113 440 110 1004 199 339 818 689 491 659 215 ## [225] 301 606 355 376 695 889 1234 532 195 711 515 1547 90 651 ## [239] 361 147 747 33 128 137 940 477 445 278 447 162 280 640 ## [253] 1579 29 1031 1006 320 849 1232 267 1441 23 850 612 733 451 ## [267] 179 641 233 661 495 195 508 3157 442 358 107 149 1696 1027 ## [281] 415 490 418 134 257 525 599 366 16 874 419 1054 1257 110 ## [295] 857 544 811 28 588 709 If you just want the first two entries in farms92: &gt; agstrat[1:2,6] ## [1] 725 658 &gt; agstrat$farms92[1:2] ## [1] 725 658 The variable region is a categorical variable, or factor variable to R. We can see the levels of region with &gt; str(agstrat$region) ## Factor w/ 4 levels &quot;NC&quot;,&quot;NE&quot;,&quot;S&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... &gt; levels(agstrat$region) ## [1] &quot;NC&quot; &quot;NE&quot; &quot;S&quot; &quot;W&quot; So region has 4 levels called NC, NE, S, and W. Note that these levels are ordered alphabetically, which is typically done with factor variables from data sets that are read into R. C.2.4 Subsetting a Data Frame You can subset a data frame just as you can subset a vector (see the Basics handout). We might want to subset a data frame to extract certain columns (variables), or we may want to extract certain rows (observations), or some combination of both. Suppose you want a data frame that only contains the variables region and farms92: One way to do this is with the select command from the dplyr package: &gt; library(dplyr) &gt; agstrat2 &lt;- select(agstrat, region, farms92) &gt; str(agstrat2) ## &#39;data.frame&#39;: 300 obs. of 2 variables: ## $ region : Factor w/ 4 levels &quot;NC&quot;,&quot;NE&quot;,&quot;S&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ farms92: int 725 658 1582 1164 448 583 321 986 1249 488 ... Suppose you want a data frame that only contains data from the north central (NC) and west (W) regions. Here we use the dplyr command filter to specify the criteria that tells us that region should be either \"W\" or \"NC\": &gt; agstrat3 &lt;- filter(agstrat, region %in% c(&quot;W&quot;, &quot;NC&quot;)) &gt; str(agstrat3) ## &#39;data.frame&#39;: 144 obs. of 17 variables: ## $ county : Factor w/ 261 levels &quot;ALEXANDER COUNTY&quot;,..: 180 115 254 241 175 37 186 94 243 212 ... ## $ state : Factor w/ 46 levels &quot;AL&quot;,&quot;AR&quot;,&quot;AZ&quot;,..: 27 13 32 20 44 21 37 10 22 14 ... ## $ acres92 : int 297326 124694 246938 206781 78772 210897 507101 332358 402202 535359 ... ## $ acres87 : int 332862 131481 263457 190251 85201 229537 552844 337990 396638 503582 ... ## $ acres82 : int 319619 139111 268434 197055 89331 213105 541015 355823 400466 513458 ... ## $ farms92 : int 725 658 1582 1164 448 583 321 986 1249 488 ... ## $ farms87 : int 857 671 1734 1278 483 699 371 1065 1251 518 ... ## $ farms82 : int 865 751 1866 1464 527 693 341 1208 1320 571 ... ## $ largef92: int 54 14 20 23 6 34 163 56 86 216 ... ## $ largef87: int 54 13 19 17 5 32 180 36 78 204 ... ## $ largef82: int 42 14 16 9 5 23 176 42 69 193 ... ## $ smallf92: int 58 42 175 56 56 8 10 90 42 16 ... ## $ smallf87: int 67 36 186 66 49 19 24 115 38 37 ... ## $ smallf82: int 48 38 184 55 48 13 16 132 28 24 ... ## $ region : Factor w/ 4 levels &quot;NC&quot;,&quot;NE&quot;,&quot;S&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ rn : int 805 241 913 478 1028 496 969 42 676 383 ... ## $ weight : num 10.2 10.2 10.2 10.2 10.2 ... Note one problem with this new data frame: the region variable still thinks it has 4 levels even though S and NE are not in this data frame &gt; levels(agstrat3$region) ## [1] &quot;NC&quot; &quot;NE&quot; &quot;S&quot; &quot;W&quot; &gt; table(agstrat3$region) ## ## NC NE S W ## 103 0 0 41 This could create a problem when we want to use the region variable in future analyzes. An easy solution exists using the droplevels command on the data frame &gt; agstrat3 &lt;- droplevels(agstrat3) &gt; table(agstrat3$region) ## ## NC W ## 103 41 C.2.5 Creating a data frame One way to create a data frame is to create vectors that will form the variables (columns), then binding them together in a data frame: &gt; x &lt;- 1:10 &gt; y &lt;- rep(c(&quot;a&quot;,&quot;b&quot;),c(5,5)) &gt; my.data &lt;- data.frame(x=x,y=y) &gt; str(my.data) ## &#39;data.frame&#39;: 10 obs. of 2 variables: ## $ x: int 1 2 3 4 5 6 7 8 9 10 ## $ y: Factor w/ 2 levels &quot;a&quot;,&quot;b&quot;: 1 1 1 1 1 2 2 2 2 2 &gt; my.data ## x y ## 1 1 a ## 2 2 a ## 3 3 a ## 4 4 a ## 5 5 a ## 6 6 b ## 7 7 b ## 8 8 b ## 9 9 b ## 10 10 b C.2.6 Adding a new column to a data frame Suppose you want to add a variable called w to the data frame my.data. &gt; w &lt;- rnorm(10, mean=0, sd=1) &gt; my.data &lt;- data.frame(my.data,w=w) &gt; my.data ## x y w ## 1 1 a 0.86176943 ## 2 2 a 0.65275233 ## 3 3 a -1.23782915 ## 4 4 a -1.08926253 ## 5 5 a 1.11091704 ## 6 6 b -0.04507617 ## 7 7 b -0.34517455 ## 8 8 b -2.61160603 ## 9 9 b 1.16716971 ## 10 10 b 0.66298909 C.2.7 Missing Data The missing data value in R is NA. Any blank field (or NA field) in the .csv file will be recognized as a missing value when the data is read into R with the read.csv command. But suppose we have missing data in a data set we’ve entered by hand &gt; u &lt;- c(NA,2,3,4,5,NA,7,8,9,10) &gt; v &lt;- c(rep(NA,5), 1:5) &gt; my.data &lt;- data.frame(my.data,u=u, v=v) &gt; my.data ## x y w u v ## 1 1 a 0.86176943 NA NA ## 2 2 a 0.65275233 2 NA ## 3 3 a -1.23782915 3 NA ## 4 4 a -1.08926253 4 NA ## 5 5 a 1.11091704 5 NA ## 6 6 b -0.04507617 NA 1 ## 7 7 b -0.34517455 7 2 ## 8 8 b -2.61160603 8 3 ## 9 9 b 1.16716971 9 4 ## 10 10 b 0.66298909 10 5 We can see which entries in u are missing with the is.na command &gt; is.na(my.data$u) ## [1] TRUE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE or with the summary command: &gt; summary(my.data) ## x y w u v ## Min. : 1.00 a:5 Min. :-2.61161 Min. : 2.00 Min. :1 ## 1st Qu.: 3.25 b:5 1st Qu.:-0.90324 1st Qu.: 3.75 1st Qu.:2 ## Median : 5.50 Median : 0.30384 Median : 6.00 Median :3 ## Mean : 5.50 Mean :-0.08734 Mean : 6.00 Mean :3 ## 3rd Qu.: 7.75 3rd Qu.: 0.81207 3rd Qu.: 8.25 3rd Qu.:4 ## Max. :10.00 Max. : 1.16717 Max. :10.00 Max. :5 ## NA&#39;s :2 NA&#39;s :5 We can use the drop_na command from the tidyr package to create an NA-free version of our data frame. Applying it to the entire data frame returns only rows that have observations for all variables: &gt; library(tidyr) &gt; my.data.noNA &lt;- drop_na(my.data) &gt; my.data.noNA ## x y w u v ## 7 7 b -0.3451746 7 2 ## 8 8 b -2.6116060 8 3 ## 9 9 b 1.1671697 9 4 ## 10 10 b 0.6629891 10 5 There are times when you only want to remove NA’s for a limited number of variables. Add these variable names as arguments to the drop_na command to only remove rows with NA’s for those variables. Here we only remove NAs from u (rows 1 and 6): &gt; my.data.noNAu &lt;- drop_na(my.data, u) &gt; my.data.noNAu ## x y w u v ## 2 2 a 0.6527523 2 NA ## 3 3 a -1.2378292 3 NA ## 4 4 a -1.0892625 4 NA ## 5 5 a 1.1109170 5 NA ## 7 7 b -0.3451746 7 2 ## 8 8 b -2.6116060 8 3 ## 9 9 b 1.1671697 9 4 ## 10 10 b 0.6629891 10 5 Sometimes data sets (especially “read-world”\" data) do not use blank fields to indicate missing data. For example, perhaps an unrealistic value is given as filler for a missing data point, like -99 for a positive integer variable or 9999 for a smaller scale variable. The source where you find your data should tell you if special fields (like -99 or 9999) are used to indicate missing data. Once you determine what the missing data indicator is, you can import the data set using the read.csv command with the added argument na.strings = c(\"-99\",\" \"). This argument tells R that missing data is coded either as an NA, a blank entry or as a -99 entry. &gt; mydata &lt;- read.csv(&quot;&lt;file path&gt;&quot;, na.strings = c(&quot;NA&quot;, &quot; &quot;, &quot;-99&quot;)) C.3 EDA We are using the agstrat data frame from the SDaA package (see Section C.2). C.3.1 Categorical: The table command is useful when summarizing a categorical variable like region &gt; table(agstrat$region) ## ## NC NE S W ## 103 21 135 41 There are 103 counties in the north central region, 21 in the northeast, 135 in the south, and 41 in the west. We get a contingency table by entering two categorical variables &gt; table(agstrat$state,agstrat$region) ## ## NC NE S W ## AL 0 0 5 0 ## AR 0 0 9 0 ## AZ 0 0 0 1 ## CA 0 0 0 1 ## CO 0 0 0 5 ## CT 0 1 0 0 ## FL 0 0 4 0 ## GA 0 0 15 0 ## HI 0 0 0 2 ## IA 10 0 0 0 ## ID 0 0 0 5 ## IL 16 0 0 0 ## IN 9 0 0 0 ## KS 11 0 0 0 ## KY 0 0 15 0 ## LA 0 0 3 0 ## MA 0 1 0 0 ## MD 0 0 2 0 ## ME 0 1 0 0 ## MI 6 0 0 0 ## MN 9 0 0 0 ## MO 10 0 0 0 ## MS 0 0 6 0 ## MT 0 0 0 7 ## NC 0 0 16 0 ## ND 2 0 0 0 ## NE 12 0 0 0 ## NJ 0 1 0 0 ## NM 0 0 0 2 ## NV 0 0 0 2 ## NY 0 8 0 0 ## OH 4 0 0 0 ## OK 0 0 7 0 ## OR 0 0 0 4 ## PA 0 8 0 0 ## SC 0 0 4 0 ## SD 7 0 0 0 ## TN 0 0 6 0 ## TX 0 0 31 0 ## UT 0 0 0 4 ## VA 0 0 5 0 ## VT 0 1 0 0 ## WA 0 0 0 7 ## WI 7 0 0 0 ## WV 0 0 7 0 ## WY 0 0 0 1 So, for example, the data contains 5 counties in Alabama that are classified as southern. (Note that this isn’t a very interesting summary of two categorical variables, just an easy one to demonstrate the table command using this data set.) C.3.2 Quantitative: Basic summary stats commands are &gt; summary(agstrat$farms92) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0 326.5 544.5 637.4 840.8 3157.0 &gt; mean(agstrat$farms92) ## [1] 637.3833 &gt; median(agstrat$farms92) ## [1] 544.5 &gt; sd(agstrat$farms92) ## [1] 448.2621 &gt; min(agstrat$farms92) ## [1] 0 &gt; max(agstrat$farms92) ## [1] 3157 We can explore which county(s) have the highest number of farms (3157) in 1992 with &gt; which(agstrat$farms92 == 3157) ## [1] 274 &gt; agstrat[274,] ## county state acres92 acres87 acres82 farms92 farms87 farms82 ## 274 HAWAII COUNTY HI 926607 1007287 1172448 3157 2810 2539 ## largef92 largef87 largef82 smallf92 smallf87 smallf82 region rn ## 274 55 60 58 1960 1602 1468 W 142 ## weight ## 274 10.29268 The 0.05 and 0.95 quantiles (i.e. 5th and 95th percentiles) of farms92 are &gt; quantile(agstrat$farms92, c(.05, .95)) ## 5% 95% ## 89.20 1441.15 meaning that 5% of counties have fewer than 89.2 farms and 95% of counties have fewer than 1441.15 farms. C.3.3 Quantitative grouped by a categorical Suppose we want to know the average number of farms per county for each region. The R function tapply(var, grp, fun) will apply the function fun to the variable var for each group in grp and produces a table of output (hence the t in tapply). Here is this command in action for the farms variable &gt; tapply(agstrat$farms92, agstrat$region, summary) ## $NC ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 58.0 489.5 738.0 750.7 968.5 1669.0 ## ## $NE ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0 395.0 451.0 528.1 659.0 1367.0 ## ## $S ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 14.0 265.5 440.0 578.6 777.5 2760.0 ## ## $W ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 16.0 257.0 495.0 602.3 733.0 3157.0 The average number of farms per county in the northeast region is 528.1. The R package dplyr can also be used to get numerical summaries by groups using the group_by and summarize commands. Here we string together these two commands with the piping command %&gt;% to get the mean and standard deviation of farms92 for each level of region: &gt; library(dplyr) &gt; agstrat %&gt;% + group_by(region) %&gt;% + summarize(mean(farms92), sd(farms92)) ## # A tibble: 4 x 3 ## region `mean(farms92)` `sd(farms92)` ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 NC 751. 358. ## 2 NE 528. 359. ## 3 S 579. 472. ## 4 W 602. 558. The output produced by this string of commands is actually a type of a data frame called a tibble. C.3.4 Graphs R has very sophisticated graphing capabilities. This handout just gives you a summary of some of the most basic graphs. More complicated graphic features will be explained as needed in class. R has high-level plotting commands that create a complete graph, low-level commands which add to an existing graph, and a graphing window layout par command. Use the help command to see these options, e.g. ?hist for the histogram options. A bar graph of the categorical variable region is given by &gt; barplot(table(agstrat$region)) The southern region contains the most counties in our sample (135) and the north east region the fewest counties (21). We can add a label to the y-axis and a title to the plot by adding the arguments &gt; barplot(table(agstrat$region), ylab=&quot;count&quot;, main=&quot;Number of counties per region&quot;) A histogram and boxplot of farms92 are given by &gt; hist(agstrat$farms92, main = &quot;Number of farms per county in 1992&quot;) &gt; boxplot(agstrat$farms92, main = &quot;Number of farms per county in 1992&quot;) We can get a side-by-side boxplot of farms92 by region with &gt; boxplot(farms92 ~ region, data = agstrat, main = &quot;Number of farms per county in 1992&quot;) Suppose we want to look at the distribution of counties across regions grouped by counties with fewer than 500 farms vs. 500 or more farms. First we need to create a factor variable that identifies counties as having less or more than 500 farms: &gt; agstrat$farms500 &lt;- ifelse(agstrat$farms92 &lt; 500, &quot;fewer than 500 farms&quot;, &quot;500 or more farms&quot;) &gt; table(agstrat$farms500) ## ## 500 or more farms fewer than 500 farms ## 164 136 The we create the stacked bar graph for farms500 grouped by region using ggplot2: &gt; library(ggplot2) &gt; ggplot(agstrat, aes(x=region, fill = farms500)) + + geom_bar(position = &quot;fill&quot;) + + labs(y=&quot;proportion&quot;, fill = &quot;Number of farms&quot;, + title = &quot;Number of farms (categorized) by region&quot;) &gt; prop.table(table(agstrat$region, agstrat$farms500), 1) ## ## 500 or more farms fewer than 500 farms ## NC 0.7281553 0.2718447 ## NE 0.4285714 0.5714286 ## S 0.4444444 0.5555556 ## W 0.4878049 0.5121951 Of the 103 counties in the North Central region, about 72.8% have 500 or more farms. Of the 135 counties in the Southern region, about 44.4% have 500 or more farms. We can also use ggplot2 to create histograms of farms92 by region: &gt; ggplot(agstrat, aes(x=farms92)) + + geom_histogram() + + facet_wrap(~region) + + labs(title = &quot;Number of farms by region&quot;) We can also use the ggplot2 package to get side-by-side boxplots grouped by a third variable. Here we can compare the distribution of total farm acreage in 1992 (acres92) by region for counties that have fewer than 500 farms vs. 500 or more farms: &gt; ggplot(agstrat, aes(x = farms500, y=acres92)) + + geom_boxplot() + + facet_wrap(~region) + + labs(title = &quot;Farm acres by number of farms and region&quot;) The relationship between median acreage across the four regions looks similar regardless of how many farms are present in a county (with western counties having the highest acreage). But for all four regions, it looks like the median acreage is highest for counties with fewer than 500 farms. Counties with fewer farms may tend to have larger farms than counties with more (smaller) farms across all four regions. C.3.5 Reporting Results Homework and reports should be done using an R Markdown document in RStudio (see Section D). If you do need to copy a graph from Rstudio into another document, use the Copy Plot to Clipboard option in the Export menu. C.4 Factor variables Section C.2.3 showed how to determine the levels of a factor variable. There are many more things you may want to do with a categorical variable that is a factor type. Here are a few hints for manipulating a factor. C.4.1 Renaming factor levels The R package forcats has a fct_recode command to rename the levels of your factor variable &gt; library(forcats) &gt; mydata &lt;- data.frame(myfac=c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;c&quot;,&quot;d&quot;,&quot;e&quot;)) &gt; table(mydata$myfac) ## ## a b c d e ## 1 1 2 1 1 &gt; mydata$new_myfac &lt;- fct_recode(mydata$myfac, + &quot;Aman&quot; = &quot;a&quot;, + &quot;Barb&quot; = &quot;b&quot;, + &quot;Chad&quot; = &quot;c&quot;, + &quot;Daryl&quot; = &quot;d&quot;, + &quot;Eliza&quot; = &quot;e&quot;) &gt; table(mydata$new_myfac) # check work ## ## Aman Barb Chad Daryl Eliza ## 1 1 2 1 1 C.4.2 Recode a categorical variable with many levels Suppose you have a variable var with response levels strongly agree, agree, disagree, and strongly disagree. You want to create a new version of this variable by combining all agree and all disagree answers. Here is one way to do this: &gt; mydata$new_var &lt;- ifelse(mydata$var %in% c(&quot;strongly agree&quot;, &quot;agree&quot;), &quot;agree&quot;, &quot;disagree&quot;) Any row in the dataset where var is in the set of responses listed (c(\"strongly agree\", \"agree\")) will be coded at agree in the newvar. All other responses (disagree, and strongly disagree) will be recoded as disagree in the newvar. If you have lots of levels that you want to collapse into fewer (or you just don’t want to use the ifelse command), then you should use the forcats package command fct_collapse. Here we have a variable called myfac that has levels a-e that we want to collapose into new groups low (just level a), mid (levels b and c) and high (levels d and e) &gt; mydata &lt;- data.frame(myfac=c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;c&quot;,&quot;d&quot;,&quot;e&quot;)) &gt; mydata$new_myfac &lt;- fct_collapse(mydata$myfac, + low = c(&quot;a&quot;), + mid = c(&quot;b&quot;,&quot;c&quot;), + high = c(&quot;d&quot;,&quot;e&quot;)) &gt; table(mydata$myfac,mydata$new_myfac) ## ## low mid high ## a 1 0 0 ## b 0 1 0 ## c 0 2 0 ## d 0 0 1 ## e 0 0 1 Just make sure that original factor levels of myfac are correctly spelled in the right-hand side of the assignment expressions. C.4.3 Converting some factor levels to NAs Sometimes you have too many levels to handle in a factor variable. Collapsing many levels into fewer is one solution (3.1), or we can create a version of the data that ignores the levels we don’t want to analyze. One way to do this is to turn those levels in NA (missing values) that R usually ignores. We can do this in the read.csv command (see section 1.3) or we can do this in the fct_collapse command or fct_recode Here we convert the d and e responses in myfac to missing values, while all other levels stay the same: &gt; mydata$try1 &lt;- fct_recode(mydata$myfac, NULL = &quot;d&quot;, NULL = &quot;e&quot;) &gt; summary(mydata$try1) ## a b c NA&#39;s ## 1 1 2 2 We can use similar syntax in the fct_collapse to both collapse levels and turn d and e into NA: &gt; mydata$try2 &lt;- fct_collapse(mydata$myfac, + low = c(&quot;a&quot;), + mid = c(&quot;b&quot;,&quot;c&quot;), + NULL = c(&quot;d&quot;,&quot;e&quot;)) &gt; summary(mydata$try2) ## low mid NA&#39;s ## 1 3 2 C.4.4 Changing the order of levels You can reorder the levels of a factor variable. Suppose newmyfac has responses that are ordered low, mid, and high. You can rearrange the order of these levels using the forcats package is fct_relevel command: &gt; table(mydata$new_myfac) # first check original order and exact spelling ## ## low mid high ## 1 3 2 &gt; mydata$new_myfac2 &lt;- fct_relevel(mydata$new_myfac, &quot;high&quot;,&quot;mid&quot;,&quot;low&quot;) &gt; table(mydata$new_myfac2) ## ## high mid low ## 2 3 1 C.4.5 Recode a numerically coded categorical variable Suppose you have a variable quant that is a categorical variable that was numerically coded (e.g. a 1=a, 2=b, 3=c, etc). You will need to convert this to a factor variable to analyze it correctly. Here is one way to do this: &gt; library(dplyr) &gt; mydata$quant &lt;- c(1,2,3,3,4,5) &gt; mydata$quant &gt; mydata$quant_fac &lt;- fct_recode(factor(mydata$quant), + &quot;a&quot; = &quot;1&quot;, + &quot;b&quot; = &quot;2&quot;, + &quot;c&quot; = &quot;3&quot;, + &quot;d&quot; = &quot;4&quot;, + &quot;e&quot; = &quot;5&quot;) &gt; mydata$quant_fac C.4.6 Recode a factor into a numeric There are times that a quantitative variable (like age) turns up as a factor after you read your data into R. This is due to at least one response in the column being a text response (non-numeric). R then defaults this column to the factor type. Suppose you’ve identified all character (text) entries in a variable that need to be either recoded into a number or turned into an NA to be ignored. You can use the readr package’s command parse_number to convert a factor variable into a numeric variable with a “best guess” at how to do this. For the ages variable with “over 90”, we see that parse_number strips away the “over” text and just leaves the number 90: &gt; library(readr) &gt; ages &lt;- factor(c(20, 18, 45, 34,&quot;over 90&quot;)) &gt; ages ## [1] 20 18 45 34 over 90 ## Levels: 18 20 34 45 over 90 &gt; new.ages &lt;- parse_number(as.character(ages)) &gt; new.ages ## [1] 20 18 45 34 90 For this version of ages, the function pulls the numbers that occur prior to the first character (-): &gt; ages &lt;- factor(c(20, 18, 45, 34,&quot;90-100&quot;)) &gt; ages ## [1] 20 18 45 34 90-100 ## Levels: 18 20 34 45 90-100 &gt; new.ages &lt;- parse_number(as.character(ages)) &gt; new.ages ## [1] 20 18 45 34 90 Rather than 90, we may want the entry to be the midpoint between 90 and 100: &gt; library(dplyr) &gt; ages2 &lt;- recode(ages, &#39;90-100&#39; = &quot;95&quot;) &gt; ages2 ## [1] 20 18 45 34 95 ## Levels: 18 20 34 45 95 &gt; new.ages &lt;- parse_number(as.character(ages2)) &gt; new.ages ## [1] 20 18 45 34 95 Finally, if there is no numeric value in an entry then parse_number will recode it automatically into an NA and give you a warning that lets you know it did this action: &gt; ages &lt;- factor(c(20, 18, 45, 34,&quot;way old&quot;)) &gt; ages ## [1] 20 18 45 34 way old ## Levels: 18 20 34 45 way old &gt; new.ages &lt;- parse_number(as.character(ages)) &gt; new.ages ## [1] 20 18 45 34 NA ## attr(,&quot;problems&quot;) ## # A tibble: 1 x 4 ## row col expected actual ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 5 NA a number way old &gt; summary(new.ages) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 18.00 19.50 27.00 29.25 36.75 45.00 1 "],
["markdown.html", "D R Markdown D.1 How to write an R Markdown document D.2 Changing R Markdown chunk evaluation behavior D.3 Creating a new R Markdown document D.4 Extra: Graph formatting D.5 Extra: Table formatting", " D R Markdown An R Markdown (.Rmd) file will allow you to integrate your R commands, output and written work in one document. You write your R code and explanations in the .Rmd file, the knit the document to a Word, HTML, or pdf file. A basic R Markdown file has the following elements: Header: this is the stuff in between the three dashes --- located at the top of your .Rmd file. A basic header should specify your document title, author and output type (e.g. word_document). Written work: Write up your work like you would in any word/google doc. Formatting is done with special symbols. E.g. to bold a word or phrase, place two asterisks ** at the start and end of the word or phrase (with no spaces). To get section headers use one or more hash tags # prior to the section name. R code: Your R commands are contained in one or more chunks that contains one or more R commands. A chunk starts with three backticks (to the left of your 1 key) combined with {r} and a chunk ends with three more backticks. See the image below for an example of a chunk that reads in the data files HollywoodMovies2011.csv. A R chunk that reads in a data file Important!! A common error that students run into when first using R Markdown is forgetting to put the read.csv command in their document. An R Markdown document must contain all commands needed to complete an analysis. This includes reading in the data! Basically, what happens during the knitting process is that a fresh version of an Rstudio environment is created that is completely separate from the Rstudio you see running in front of you. The R chunks are run in this new environment, and if you will encounter a Markdown error if you, say, try to use the movies data frame without first including the read.csv chunk shown in Figure 1. D.1 How to write an R Markdown document Write your commands in R chunks, not in the console. Run chunk commands using the suggestions in the Hints section below. Knit your document often. This allows you to catch errors/typos as you make them. You can knit a .Rmd by pressing the Knit button at the top of the doc. You can change output types (e.g. switch from HTML to Word) by typing in the preferred doc type in the header, or by using the drop down menu option found by clicking the down triangle to the right of the Knit button. You can run a line of code in the R console by putting your cursor in the line and selecting Run &gt; Run Selected Line(s). You can run all commands in a chunk by clicking the green triangle on the right side of the chunk. URLs can be embeded between &lt; and &gt; symbols. The image below shows a quick scrolling menu that is available by clicking the double triangle button at the bottom of the .Rmd. This menu shows section headers and available chunks. It is useful for navagating a long .Rmd file. Quick scroll through Markdown document D.2 Changing R Markdown chunk evaluation behavior The default setting in Rstudio when you are running chunks is that the “output” (numbers, graphs) are shown “inline” within the Markdown Rmd. For a variety of reasons, my preference is to have commands run in the console. To see the difference between these two types of chunk evaluation option, you can change this setting as follows: Select Tools &gt; Global Options. Click the R Markdown section and uncheck (if needed) the option Show output inline for all R Markdown documents. Click OK. Now try running R chunks in the .Rmd file to see the difference. You can recheck this box if you prefer the default setting. D.3 Creating a new R Markdown document I suggest using old .Rmd HW file as a template for a new HW assignment. But if you want to create a completely new docment: Click File &gt; New File &gt; R Markdown…. A window like the one shown below should appear. The default settings will give you a basic Markdown (.Rmd) file that will generate an HTML document. Click OK on this window. Opening a Markdown document You should now have an “Untitled1” Markdown file opened in your document pane of Rstudio. Save this file, renamed as “FirstMarkdown.Rmd”, somewhere on your computer. (Ideally in a Math215 folder!) On Mirage, save the file in the default location (which is your account folder on the mirage server). Now click the Knit HTML button on the tool bar at the top of your Markdown document. This will generate a “knitted” (compiled) version of this document. Check that there is now an HTML file named “FirstMarkdown.html” in the same location as your “FirstMarkdown.Rmd” file. D.4 Extra: Graph formatting The data set Cereals contains information on cereals sold at a local grocery store. &gt; # load the data set &gt; Cereals &lt;- read.csv(&quot;http://math.carleton.edu/Stats215/RLabManual/Cereals.csv&quot;) D.4.1 Adding figure numbers and captions To add captions to the figures you make you need to add the argument fig.cap=\"my caption\" to your R chunk that creates the figure. If you have two or more figures created in the R chunk then give the fig.cap argument a vector of captions. If you are knitting to a pdf, you don’t need to add “Figure 1”, etc. numbering to the figure captions (they will be numbered automatically). For HTML and Word output types, you need to manually number figures. D.4.2 Resizing graphs in Markdown Suppose we want to create a boxplot of calories per gram grouped by cereal type and a scatterplot of calories vs. carbs per gram. Here are the basic commands without any extra formatting that create Figures 1 and 2: ```{r, fig.cap=\"Figure 1: Distributions of calories per gram by cereal type\"} boxplot(calgram ~ type, data=Cereals, main=\"Calories by type\", ylab=\"Calories per gram\") ``` Figure D.1: Distributions of calories per gram by cereal type ```{r, fig.cap=\"Figure 2: Calories vs. Carbs per gram\"} plot(carbsgram ~ calgram, data=Cereals, main=\"Carbs vs Calories\") ``` Figure D.2: Calories vs. Carbs per gram We can add fig.height and fig.width parameters to the Markdown R chunk to resize the output size of the graph. The size inputs used here are a height of 3.5 inches and a width of 6 inches. The command below creates Figures 3 and 4. ```{r, fig.height=3.5, fig.width=5, fig.cap=c(\"Figure 3: Distributions of calories per gram by cereal type\",\"Figure 4: Calories vs. Carbs per gram\")} boxplot(calgram ~ type, data=Cereals, main=\"Calories by type\", ylab=\"Calories per gram\") plot(carbsgram ~ calgram, data=Cereals, main=\"Carbs vs Calories\") ``` &gt; boxplot(calgram ~ type, data=Cereals, main=&quot;Calories by type&quot;, ylab=&quot;Calories per gram&quot;) Figure D.3: Distributions of calories per gram by cereal type &gt; plot(carbsgram ~ calgram, data=Cereals, main=&quot;Carbs vs Calories&quot;) Figure D.4: Calories vs. Carbs per gram D.4.3 Changing graph formatting in R You can use the par command to change R’s graphical parameter settings for plots that are not made from ggplot2. There are many options that can be changed, but one of the most useful is to change the layout of the graphical output display. The argument mfrow (multi-frame row) is given a vector c(nr, nc) that draws figures in an nr (number of rows) by nc (number of columns) array. We can arrange our two graphs in a 1 by 2 display (1 row, 2 columns) with the command: &gt; par(mfrow=c(1,2)) &gt; boxplot(calgram ~ type, data=Cereals, main=&quot;Calories by type&quot;, ylab=&quot;Calories per gram&quot;) &gt; plot(carbsgram ~ calgram, data=Cereals, main=&quot;Carbs vs Calories&quot;) Figure D.5: Distribution of calories per gram by cereal type and calories vs. carbs per gram. D.4.4 Hiding R commands You can omit R commands from your final document by adding echo=FALSE to your R chunk argument. Any output produced by your command (graphical or numerical) will still be displayed. For example, the following command creates Figure 6, a boxplot of carbs per gram by cereal type. ```{r, echo=FALSE, fig.cap=\"Figure 6: Distributions of calories per gram and shelf placement by cereal type\", fig.height=3, fig.width=4} boxplot(carbsgram ~ type, data=Cereals, main=\"Carbs by type\", ylab=\"Carbs per gram\") ``` Figure D.6: Distributions of calories per gram and shelf placement by cereal type D.4.5 Global changes in graph format The R chunk options that control graph sizes and output features (like echo) can be set globally for all R chunks either in the header (like with fig.caption) or in an opts_chunk$set() command at the start of the .Rmd file. I usually opt for setting global features with the opts_chunk command which you often see at the start of my .Rmd files. Any global settings, like echo or fig.height, can be overridden locally by changing them in individual chunks. D.4.6 Comments: Markdown is very sensitive to spaces, or lack-there-of. If you get odd formatting issues, try adding a spaces between R chunks, paragrahs, lists, section headers, etc. For example, you always need a space between an R chunk or text and a section header. D.5 Extra: Table formatting This handout gives some basic ways to format numerical output produced in your R chunks. Some of the methods mentioned below might only work when knitting to a PDF. Additional info about formatting text in R Markdown can be found online: http://rmarkdown.rstudio.com/authoring_basics.html http://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf http://rmarkdown.rstudio.com/pdf_document_format.html In homework or R appendices, I expect to see both the commands and output produced by those commands as your “work” for a problem. But in reports, as in any formal research paper, you should not include R commands or output (except for graphs). This handout is designed, primarily, to help you format numerical results to present into your written reports. The data set Cereals contains information on cereals sold at a local grocery store. &gt; # load the data set &gt; Cereals &lt;- read.csv(&quot;http://math.carleton.edu/Stats215/RLabManual/Cereals.csv&quot;) D.5.1 Hiding R commands and R output As mentioned in the graph formatting handout, adding the chunk option echo=FALSE will display output (like graphs) produced by a chunk but not show the commands used in the chunk. You can stop both R commands and output from being displayed in a document by adding the chunk option include=FALSE. As you work through a report analysis, you may initially want to see all of your R results as you are writing your report. But after you’ve summarized results in paragraphs or in tables, you can then use the include=FALSE argument to hid your R commands and output in your final document. If you ever need to rerun or reevaluate your R work for a report, you can easily recreate and edit your analysis since the R chunks used in your original report are still in your R Markdown .Rmd file. D.5.2 Markdown tables The Markdown language allows you to construct simple tables using vertical lines | to separate columns and horizontal lines - to create a header. Make sure to include at least one space before and after your Markdown table or it will not format correctly. I can’t find an easy way to attached an automatic table number and caption to this type of table, so I’ve simply written (and centered) the table number and caption by hand for the table below. Suppose we want to present the 5-number summary of calories per gram by cereal type. The tapply command can be used to obtain these numbers. &gt; tapply(Cereals$calgram, Cereals$type, summary) ## $adult ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2.000 3.208 3.519 3.399 3.667 4.600 ## ## $children ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 3.636 3.931 4.000 4.028 4.074 4.483 We can construct a table of stats by type “by hand” using simple markdown table syntax in our .Rmd file that is shown below: Type | Min | Q1 | Median | Q3 | Max ---- | --- | --- | --- | --- | --- Adult | 2.0 | 3.2 | 3.5 | 3.7 | 4.6 Children | 3.6 | 3.9 | 4.0 | 4.1 | 4.5 The knitted table produced is shown below: Type Min Q1 Median Q3 Max Adult 2.0 3.2 3.5 3.7 4.6 Children 3.6 3.9 4.0 4.1 4.5 D.5.3 Markdown tables via kable The R package knitr contains a simple table making function called kable. You can use this function to, say, show the first few rows of a data frame: &gt; library(knitr) &gt; kable(head(Cereals), digits=3, caption=&quot;Table 1: Cereals data (first 6 cases)&quot;) &gt; library(knitr) &gt; kable(head(Cereals), digits=3, caption=&quot;Cereals data (first 6 cases)&quot;) Table D.1: Cereals data (first 6 cases) brand type shelf cereal serving calgram calfatgram totalfatgram sodiumgram carbsgram proteingram GM children bottom Lucky Charms 30 4.000 0.333 0.033 0.007 0.833 0.067 GM adult bottom Cheerios 30 3.667 0.500 0.067 0.007 0.733 0.100 Kellogs children bottom Smorz 30 4.000 0.667 0.067 0.005 0.833 0.033 Kellogs children bottom Scooby Doo Berry Bones 33 3.939 0.303 0.030 0.007 0.848 0.030 GM adult bottom Wheaties 30 3.667 0.333 0.033 0.007 0.800 0.100 GM children bottom Trix 30 4.000 0.500 0.050 0.006 0.867 0.033 Or you can use kable on a two-way table of counts or proportions: &gt; kable(table(Cereals$brand, Cereals$type), caption=&quot;Table 2: Cereal brand and type&quot;) Table D.2: Cereal brand and type adult children GM 4 11 Kashi 6 0 Kellogs 4 13 Quaker 1 2 WW 2 0 D.5.4 The pander package The R package pander creates simple tables in R that do not need any additional formatting in Markdown. The pander() function takes in an R object, like a summary table or t-test output, and outputs a Markdown table. You can add a caption argument to include a table number and title. Here is a table for the summary of calories per gram: &gt; library(pander) &gt; pander(summary(Cereals$calgram), caption=&quot;Table 3: Summary statistics for calories per gram.&quot;) Table 3: Summary statistics for calories per gram. Min. 1st Qu. Median Mean 3rd Qu. Max. 2 3.636 3.929 3.779 4.031 4.6 Pander can format tables and proportion tables. Here is the table for cereal type and shelf placement (Table 4), along with the distribution of shelf placement by cereal type (Table 5). &gt; my.table &lt;- table(Cereals$type,Cereals$shelf) &gt; pander(my.table,round=3, caption=&quot;Table 4: Cereal type and shelf placement&quot;) Table 4: Cereal type and shelf placement bottom middle top adult 2 1 14 children 7 18 1 &gt; pander(prop.table(my.table,1),round=3, caption=&quot;Table 5: Distribution of shelf placement by cereal type&quot;) Table 5: Distribution of shelf placement by cereal type bottom middle top adult 0.118 0.059 0.824 children 0.269 0.692 0.038 Here are t-test results for comparing mean calories for adult and children cereals (Table 6): &gt; pander(t.test(calgram ~ type, data=Cereals), caption=&quot;Table 6: Comparing calories for adult and children cereals&quot;) Table 6: Comparing calories for adult and children cereals (continued below) Test statistic df P value Alternative hypothesis -4.066 18.45 0.0006942 * * * two.sided mean in group adult mean in group children 3.399 4.028 Here are chi-square test results for testing for an association between shelf placement and cereal type (Table 7). Note that the simulate.p.value option was used to give a randomization p-value since the sample size criteria for the chi-square approximation was not met. &gt; pander(chisq.test(my.table, simulate.p.value = TRUE),caption=&quot;Table 7: Chi-square test for placement and type&quot;) Table 7: Chi-square test for placement and type Test statistic df P value 28.63 NA 0.0004998 * * * Here are the basic results for the regression of carbs on calories (Table 8). &gt; pander(lm(carbsgram ~ calgram, data=Cereals), caption=&quot;Table 8: Regression of carbs on calories&quot;) Table 8: Regression of carbs on calories Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 0.1021 0.0804 1.27 0.2111 calgram 0.1798 0.02108 8.528 1.264e-10 D.5.5 The stargazer package The stargazer package, like pander, automatically generates Markdown tables from R objects. The stargazer function has more formatting options than pander and can generate summary stats from a data frame table. It can also provide nicely formatted comparisons between 2 or more regression models. See the help file ?stargazer for more options. You will need to add the R chunk option results='asis' to get the table formatted correctly. I also include the message=FALSE option in the chunk below that runs the library command to suppress the automatic message created when running the library command with stargazer. When you give stargazer a data frame, it gives you summary stats for all numeric variables in the data frame (Table 10): ```{r, results='asis', message=FALSE} library(stargazer) stargazer(Cereals, type=\"html\", title=\"Table 9: Default summary stats using stargazer\") ``` Table 9: Default summary stats using stargazer Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max serving 43 36.953 10.542 27 30 50 60 calgram 43 3.779 0.517 2 3.6 4.0 5 calfatgram 43 0.490 0.261 0.000 0.328 0.600 1.034 totalfatgram 43 0.053 0.031 0.000 0.033 0.063 0.121 sodiumgram 43 0.005 0.002 0.000 0.003 0.006 0.007 carbsgram 43 0.782 0.116 0.280 0.767 0.850 0.920 proteingram 43 0.082 0.057 0.030 0.034 0.097 0.267 The default table type is \"latex\" which is the format you want when knitting to a pdf document. When knitting to an html document we need to change type to \"html\". Unfortunately, there is no type that works nicely with Word documents so you would be better off using pander if you want a Word document. Note: When using the latex type and knitting to a pdf, you will get an annoying stargazer message about the creation of your latex table. Include the argument header=FALSE in the stargazer command to suppress this message when knitting to a pdf. You can subset the Cereals data frame to only include the variables (columns) that you want displayed. In Table 11 we only see calories and carbs. You can also edit the summary stats displayed by specifying them in the summary.stat argument. See the stargazer help file for more stat options. &gt; stargazer(Cereals[,c(&quot;calgram&quot;,&quot;carbsgram&quot;)], + type=&quot;html&quot;, + title=&quot;Table 10: Five number summary stats&quot;, + summary.stat=c(&quot;max&quot;,&quot;p25&quot;,&quot;median&quot;,&quot;p75&quot;,&quot;max&quot;)) Table 10: Five number summary stats Statistic Max Pctl(25) Median Pctl(75) Max calgram 5 3.6 3.9 4.0 5 carbsgram 0.920 0.767 0.800 0.850 0.920 The stargazer package was created to display results of statistical models. Here is the basic display for the regression of carbs on calories (Table 12). The argument single.row puts estimates and standard errors (in parentheses) in one row. There are many options that can be tweaked, like including p-values or confidence intervals. &gt; my.lm &lt;- lm(carbsgram ~ calgram, data=Cereals) &gt; stargazer(my.lm, type=&quot;html&quot;, + title=&quot;Table 11: Regression of carbs on calories&quot;, + single.row=TRUE) Table 11: Regression of carbs on calories Dependent variable: carbsgram calgram 0.180*** (0.021) Constant 0.102 (0.080) Observations 43 R2 0.639 Adjusted R2 0.631 Residual Std. Error 0.071 (df = 41) F Statistic 72.721*** (df = 1; 41) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 Table 13 adds the argument keep.stat to specify that only sample size and \\(R^2\\) should be included in the table. See the help file for more options to this argument. &gt; stargazer(my.lm, type=&quot;html&quot;, + title=&quot;Table 12: Regression of carbs on calories&quot;, + single.row=TRUE, + keep.stat=c(&quot;n&quot;,&quot;rsq&quot;)) Table 12: Regression of carbs on calories Dependent variable: carbsgram calgram 0.180*** (0.021) Constant 0.102 (0.080) Observations 43 R2 0.639 Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 "],
["mathreview.html", "E Math review E.1 Linear equations E.2 Logarithms E.3 Exercises", " E Math review E.1 Linear equations E.2 Logarithms Let \\(b&gt;0\\) and \\(x&gt;0\\). The logarithm (base-\\(b\\)) of \\(x\\) is denoted \\(\\log_b(x)\\) and equal to \\[ \\log_b(x) = a \\] where \\(a\\) tells us what power we must raise \\(b\\) to to obtain the value \\(x\\): \\[ b^a = x \\] Easy examples are: \\(b=2\\), \\(x=8\\) and \\(a=3\\), \\[ \\log_2(8) = 3 \\] since \\(2^3 = 8\\). Or using base \\(b=10\\), then \\[ \\log_{10}(0.01) = -2 \\] since \\(10^{-2} = 0.01\\). Some basic facts logarithm facts are \\[ \\log_b(b) = 1 \\] since \\(b^1 = b\\) and \\[ \\log_b(1) = 0 \\] since \\(b^0 = 1\\). E.2.1 Interpreting logged variables Multiplicative changes in \\(x\\) result in additive changes in \\(\\log_b(x)\\). If \\(m&gt;0\\), then \\[ \\log_b(mx) = \\log_b(m) + \\log_b(x) \\] For example, a doubling of \\(x=8\\) results in an increase in \\(\\log_2(8)\\) of one unit: \\[ \\log_2(16) = \\log_2(2\\times 8) = \\log_2(2) + \\log_2(8) = 1 + 3 = 4 \\] More generally if we use a base-2 logarithm, a doubling of \\(x\\) results in an additive increase in \\(\\log(x)\\) of 1 unit: \\[ \\log_2(2\\times x) = \\log_2(2) + \\log_2(x) = 1 + \\log_2(x) \\] E.2.2 Inverse (i.e. reversing the log, getting rid of the log, …) The logarithm and exponential functions are inverses of one another. This means we can “get rid” of the log by calculating \\(b\\) raised to the logged-function: \\[ b^{\\log_b(x)} = x \\] This will be useful in regression when we have a linear relationship between logged-response \\(y\\) and a set of predictors. For example, suppose we know that \\[ \\log_2(y) = 3 + 5x + \\epsilon \\] To return this to an expression on the original (unlogged) scale of \\(y\\), we need take both sides raised to the base 2: \\[ 2^{\\log_2(y)} = 2^{3 + 5x+ \\epsilon} \\] Simplifying both sides gives \\[ y = 2^3 \\times 2^{5x} \\times x^{\\epsilon} \\] E.2.3 Logarithms in R The R function log gives the natural logarithm (base-\\(e\\)): &gt; log(2) ## [1] 0.6931472 &gt; log(exp(1)) ## [1] 1 Other common logarithm bases are base-2 and base-10: &gt; log2(8) ## [1] 3 &gt; log10(100) ## [1] 2 General bases can be added as an argument: &gt; log(49, base = 7) ## [1] 2 E.3 Exercises Write the following as the sum of two logarithms. Simplify as much as possible: \\(\\log_2(2x)\\) \\(\\log_2(0.5x)\\) \\(\\ln(2x)\\) where \\(\\ln\\) is the natural log (base-\\(e\\)) Write the following expressions in terms of \\(y\\), not \\(\\log(y)\\). Simplify as much as possible: \\(\\log_2(y) = 1 - 3x\\) \\(\\log_{10}(y) = -2 + 0.4x\\) \\(\\ln(y) = 1 - 3x\\) Write the following expressions in terms of \\(y\\) and \\(x\\), not \\(\\log(y)\\) and \\(\\log(x)\\). Simplify as much as possible: \\(\\log_2(y) = 1 - 3\\log_2(x)\\) \\(\\ln(y) = -2 + 0.4\\ln(x)\\) \\(\\ln(y) = 1 - 3\\log_2(x)\\) Logarithmic model: Regression of \\(Y\\) on \\(\\log(x)\\) obtains the following estimated mean of \\(Y\\): \\[ \\hat{\\mu}(Y \\mid x) = 1 - 3 \\log_2(x) \\] What is the change in estimated mean response if we double the value of \\(x\\)? What is the change in estimated mean response if we triple the value of \\(x\\)? What is the change in estimated mean response if we reduce the value of \\(x\\) by 20%? Exponential model: Regression of \\(\\log_2(Y)\\) on \\(x\\) obtains the following estimated median of \\(Y\\): \\[ \\hat{median}(\\log_2(Y) \\mid x) = -2 + 0.4x \\] Write the median in terms of \\(Y\\) instead of \\(\\log_2(Y)\\). Simplify as much as possible. What is the multiplicative change in estimated median response if we increase \\(x\\) by 1 unit? What is the percent change in estimated median response if we increase \\(x\\) by 1 unit? What is the multiplicative change in estimated median response if we decrease \\(x\\) by 2 units? What is the percent change in estimated median response if we decrease \\(x\\) by 2 units? Power model: Regression of \\(\\log_2(Y)\\) on \\(\\log_2(x)\\) obtains the following estimated median of \\(Y\\): \\[ \\hat{median}(\\log_2(Y) \\mid x) = 1 -3\\log_2(x) \\] Write the median in terms of \\(Y\\) and \\(x\\) instead of \\(\\log\\)s. Simplify as much as possible. What is the multiplicative change in estimated median response if we increase \\(x\\) by 50%? What is the percent change in estimated median response if we increase \\(x\\) by 50%? What is the multiplicative change in estimated median response if we reduce the value of \\(x\\) by 20%? What is the percent change in estimated median response if we reduce the value of \\(x\\) by 20%? "],
["references.html", "References", " References "]
]
