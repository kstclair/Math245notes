<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Poisson Regression | Math 245 Notes</title>
  <meta name="description" content="Course notes and examples for Applied Regression Analysis" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Poisson Regression | Math 245 Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes and examples for Applied Regression Analysis" />
  <meta name="github-repo" content="kstclair/Math245notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Poisson Regression | Math 245 Notes" />
  
  <meta name="twitter:description" content="Course notes and examples for Applied Regression Analysis" />
  

<meta name="author" content="Katie St. Clair, Carleton College" />


<meta name="date" content="2020-08-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="logistic.html"/>
<link rel="next" href="rrstudio.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Math 245 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Getting Started</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#getting-help"><i class="fa fa-check"></i>Getting help</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="review.html"><a href="review.html"><i class="fa fa-check"></i><b>1</b> Review of Statistical Inference</a><ul>
<li class="chapter" data-level="1.1" data-path="review.html"><a href="review.html#sampling-distribution"><i class="fa fa-check"></i><b>1.1</b> Sampling Distribution</a></li>
<li class="chapter" data-level="1.2" data-path="review.html"><a href="review.html#central-limit-theorem"><i class="fa fa-check"></i><b>1.2</b> Central Limit Theorem</a><ul>
<li class="chapter" data-level="1.2.1" data-path="review.html"><a href="review.html#standard-error"><i class="fa fa-check"></i><b>1.2.1</b> Standard error</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="review.html"><a href="review.html#hypothesis-testing"><i class="fa fa-check"></i><b>1.3</b> Hypothesis testing</a></li>
<li class="chapter" data-level="1.4" data-path="review.html"><a href="review.html#confidence-intervals"><i class="fa fa-check"></i><b>1.4</b> Confidence Intervals</a></li>
<li class="chapter" data-level="1.5" data-path="review.html"><a href="review.html#review_activity"><i class="fa fa-check"></i><b>1.5</b> Review activity (day 2)</a><ul>
<li class="chapter" data-level="1.5.1" data-path="review.html"><a href="review.html#general-questions"><i class="fa fa-check"></i><b>1.5.1</b> General questions</a></li>
<li class="chapter" data-level="1.5.2" data-path="review.html"><a href="review.html#comparing-two-means"><i class="fa fa-check"></i><b>1.5.2</b> Comparing two means</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="slr.html"><a href="slr.html"><i class="fa fa-check"></i><b>2</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="2.1" data-path="slr.html"><a href="slr.html#the-variables"><i class="fa fa-check"></i><b>2.1</b> The variables</a></li>
<li class="chapter" data-level="2.2" data-path="slr.html"><a href="slr.html#slr-model"><i class="fa fa-check"></i><b>2.2</b> The model form</a><ul>
<li class="chapter" data-level="2.2.1" data-path="slr.html"><a href="slr.html#interpretation"><i class="fa fa-check"></i><b>2.2.1</b> Interpretation</a></li>
<li class="chapter" data-level="2.2.2" data-path="slr.html"><a href="slr.html#slr-model-ex"><i class="fa fa-check"></i><b>2.2.2</b> Example: Woodpecker nests</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="slr.html"><a href="slr.html#slr-est"><i class="fa fa-check"></i><b>2.3</b> Theory: Estimation</a><ul>
<li class="chapter" data-level="2.3.1" data-path="slr.html"><a href="slr.html#sampling-distributions-for-slr-estimates"><i class="fa fa-check"></i><b>2.3.1</b> Sampling Distributions for SLR estimates</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="slr.html"><a href="slr.html#slr-sim"><i class="fa fa-check"></i><b>2.4</b> SLR model simulation</a><ul>
<li class="chapter" data-level="2.4.1" data-path="slr.html"><a href="slr.html#simulation-function"><i class="fa fa-check"></i><b>2.4.1</b> Simulation function</a></li>
<li class="chapter" data-level="2.4.2" data-path="slr.html"><a href="slr.html#run-the-function-once"><i class="fa fa-check"></i><b>2.4.2</b> Run the function once</a></li>
<li class="chapter" data-level="2.4.3" data-path="slr.html"><a href="slr.html#simulated-sampling-distribution-for-hatbeta_1"><i class="fa fa-check"></i><b>2.4.3</b> Simulated sampling distribution for <span class="math inline">\(\hat{\beta}_1\)</span></a></li>
<li class="chapter" data-level="2.4.4" data-path="slr.html"><a href="slr.html#slr-simcor"><i class="fa fa-check"></i><b>2.4.4</b> Are slope and intercept estimates correlated?</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="slr.html"><a href="slr.html#slr-inf"><i class="fa fa-check"></i><b>2.5</b> Inference for mean parameters</a><ul>
<li class="chapter" data-level="2.5.1" data-path="review.html"><a href="review.html#confidence-intervals"><i class="fa fa-check"></i><b>2.5.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="2.5.2" data-path="slr.html"><a href="slr.html#hypothesis-tests"><i class="fa fa-check"></i><b>2.5.2</b> Hypothesis tests</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="slr.html"><a href="slr.html#slr-inf2"><i class="fa fa-check"></i><b>2.6</b> Inference for average or predicted response</a><ul>
<li class="chapter" data-level="2.6.1" data-path="slr.html"><a href="slr.html#confidence-intervals-for-mu_y-mid-x"><i class="fa fa-check"></i><b>2.6.1</b> Confidence intervals for <span class="math inline">\(\mu_{y \mid x}\)</span></a></li>
<li class="chapter" data-level="2.6.2" data-path="slr.html"><a href="slr.html#prediction-intervals-for-new-cases"><i class="fa fa-check"></i><b>2.6.2</b> Prediction intervals for new cases</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="slr.html"><a href="slr.html#slr-example1"><i class="fa fa-check"></i><b>2.7</b> Example: SLR model (day 3)</a><ul>
<li class="chapter" data-level="2.7.1" data-path="slr.html"><a href="slr.html#load-data"><i class="fa fa-check"></i><b>2.7.1</b> Load data</a></li>
<li class="chapter" data-level="2.7.2" data-path="slr.html"><a href="slr.html#eda"><i class="fa fa-check"></i><b>2.7.2</b> EDA</a></li>
<li class="chapter" data-level="2.7.3" data-path="slr.html"><a href="slr.html#the-least-squares-line-the-estimated-slr-model"><i class="fa fa-check"></i><b>2.7.3</b> The least squares line (the estimated SLR model):</a></li>
<li class="chapter" data-level="2.7.4" data-path="slr.html"><a href="slr.html#inference-for-coefficients"><i class="fa fa-check"></i><b>2.7.4</b> Inference for coefficients</a></li>
<li class="chapter" data-level="2.7.5" data-path="slr.html"><a href="slr.html#additional-lm-information"><i class="fa fa-check"></i><b>2.7.5</b> Additional <code>lm</code> information</a></li>
<li class="chapter" data-level="2.7.6" data-path="slr.html"><a href="slr.html#slr-broom"><i class="fa fa-check"></i><b>2.7.6</b> <code>broom</code> package: Tidy <code>lm</code> output</a></li>
<li class="chapter" data-level="2.7.7" data-path="slr.html"><a href="slr.html#inference-for-the-mean-and-predicted-response"><i class="fa fa-check"></i><b>2.7.7</b> Inference for the mean and predicted response</a></li>
<li class="chapter" data-level="2.7.8" data-path="slr.html"><a href="slr.html#adding-confidence-bands-to-a-scatterplot"><i class="fa fa-check"></i><b>2.7.8</b> Adding confidence bands to a scatterplot</a></li>
<li class="chapter" data-level="2.7.9" data-path="slr.html"><a href="slr.html#tools-for-displaying-your-model"><i class="fa fa-check"></i><b>2.7.9</b> Tools for displaying your model</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="slr.html"><a href="slr.html#slr-assump"><i class="fa fa-check"></i><b>2.8</b> Checking model assumptions and fit</a><ul>
<li class="chapter" data-level="2.8.1" data-path="slr.html"><a href="slr.html#residuals"><i class="fa fa-check"></i><b>2.8.1</b> Residuals</a></li>
<li class="chapter" data-level="2.8.2" data-path="slr.html"><a href="slr.html#residual-plot-linearity-and-constant-variance"><i class="fa fa-check"></i><b>2.8.2</b> Residual plot: linearity and constant variance</a></li>
<li class="chapter" data-level="2.8.3" data-path="slr.html"><a href="slr.html#slr-normality"><i class="fa fa-check"></i><b>2.8.3</b> Residual normal QQ plot</a></li>
<li class="chapter" data-level="2.8.4" data-path="slr.html"><a href="slr.html#slr-indep"><i class="fa fa-check"></i><b>2.8.4</b> Independence</a></li>
<li class="chapter" data-level="2.8.5" data-path="slr.html"><a href="slr.html#slr-robust"><i class="fa fa-check"></i><b>2.8.5</b> Robustness against violations</a></li>
<li class="chapter" data-level="2.8.6" data-path="slr.html"><a href="slr.html#fixes-to-violations"><i class="fa fa-check"></i><b>2.8.6</b> “Fixes” to violations</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="slr.html"><a href="slr.html#slr-example2"><i class="fa fa-check"></i><b>2.9</b> Example: SLR assumptions (day 4/5)</a><ul>
<li class="chapter" data-level="2.9.1" data-path="slr.html"><a href="slr.html#drug-offender-sentences"><i class="fa fa-check"></i><b>2.9.1</b> Drug offender sentences</a></li>
<li class="chapter" data-level="2.9.2" data-path="slr.html"><a href="slr.html#case-study-15.2---global-warming"><i class="fa fa-check"></i><b>2.9.2</b> Case study 15.2 - Global Warming</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="slr.html"><a href="slr.html#slr-trans"><i class="fa fa-check"></i><b>2.10</b> Transformations</a><ul>
<li class="chapter" data-level="2.10.1" data-path="slr.html"><a href="slr.html#transformation-choices"><i class="fa fa-check"></i><b>2.10.1</b> Transformation choices</a></li>
<li class="chapter" data-level="2.10.2" data-path="slr.html"><a href="slr.html#transformations-in-r"><i class="fa fa-check"></i><b>2.10.2</b> Transformations in R</a></li>
<li class="chapter" data-level="2.10.3" data-path="slr.html"><a href="slr.html#interpretation-1"><i class="fa fa-check"></i><b>2.10.3</b> Interpretation</a></li>
<li class="chapter" data-level="2.10.4" data-path="slr.html"><a href="slr.html#slr-logs"><i class="fa fa-check"></i><b>2.10.4</b> Review: Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="slr.html"><a href="slr.html#examples-transformations-day-6"><i class="fa fa-check"></i><b>2.11</b> Examples: Transformations (day 6)</a><ul>
<li class="chapter" data-level="2.11.1" data-path="slr.html"><a href="slr.html#cars-2004"><i class="fa fa-check"></i><b>2.11.1</b> Cars 2004</a></li>
<li class="chapter" data-level="2.11.2" data-path="slr.html"><a href="slr.html#residential-energy-survey-recs"><i class="fa fa-check"></i><b>2.11.2</b> 2005 Residential Energy Survey (RECS)</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="slr.html"><a href="slr.html#r2-and-anova-for-slr"><i class="fa fa-check"></i><b>2.12</b> <span class="math inline">\(R^2\)</span> and ANOVA for SLR</a><ul>
<li class="chapter" data-level="2.12.1" data-path="slr.html"><a href="slr.html#example-r2"><i class="fa fa-check"></i><b>2.12.1</b> Example: <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="2.12.2" data-path="slr.html"><a href="slr.html#slr-anova"><i class="fa fa-check"></i><b>2.12.2</b> ANOVA for SLR</a></li>
<li class="chapter" data-level="2.12.3" data-path="slr.html"><a href="slr.html#example-anova"><i class="fa fa-check"></i><b>2.12.3</b> Example: ANOVA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mlr.html"><a href="mlr.html"><i class="fa fa-check"></i><b>3</b> Multiple Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="slr.html"><a href="slr.html#the-variables"><i class="fa fa-check"></i><b>3.1</b> The variables</a></li>
<li class="chapter" data-level="3.2" data-path="mlr.html"><a href="mlr.html#mlr-model"><i class="fa fa-check"></i><b>3.2</b> The model form</a><ul>
<li class="chapter" data-level="3.2.1" data-path="mlr.html"><a href="mlr.html#mlr-interpretation"><i class="fa fa-check"></i><b>3.2.1</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="mlr.html"><a href="mlr.html#mlr-example1"><i class="fa fa-check"></i><b>3.3</b> Example: MLR fit and visuals</a><ul>
<li class="chapter" data-level="3.3.1" data-path="mlr.html"><a href="mlr.html#lm-fit"><i class="fa fa-check"></i><b>3.3.1</b> <code>lm</code> fit</a></li>
<li class="chapter" data-level="3.3.2" data-path="mlr.html"><a href="mlr.html#graphics-for-mlr"><i class="fa fa-check"></i><b>3.3.2</b> Graphics for MLR</a></li>
<li class="chapter" data-level="3.3.3" data-path="mlr.html"><a href="mlr.html#mlr-resid1"><i class="fa fa-check"></i><b>3.3.3</b> Residual plots for MLR</a></li>
<li class="chapter" data-level="3.3.4" data-path="mlr.html"><a href="mlr.html#eda-for-interactions"><i class="fa fa-check"></i><b>3.3.4</b> EDA for interactions</a></li>
<li class="chapter" data-level="3.3.5" data-path="mlr.html"><a href="mlr.html#quadratic-models-corn-yields-exercise-9.15"><i class="fa fa-check"></i><b>3.3.5</b> Quadratic models: Corn yields (exercise 9.15)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="mlr.html"><a href="mlr.html#mlr-cat"><i class="fa fa-check"></i><b>3.4</b> Categorical Predictors</a><ul>
<li class="chapter" data-level="3.4.1" data-path="mlr.html"><a href="mlr.html#interpretation-adding-a-categorical"><i class="fa fa-check"></i><b>3.4.1</b> Interpretation: adding a categorical</a></li>
<li class="chapter" data-level="3.4.2" data-path="mlr.html"><a href="mlr.html#interpretation-adding-a-categorical-interaction"><i class="fa fa-check"></i><b>3.4.2</b> Interpretation: adding a categorical interaction</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="mlr.html"><a href="mlr.html#mlr-inf"><i class="fa fa-check"></i><b>3.5</b> Inference for MLR</a><ul>
<li class="chapter" data-level="3.5.1" data-path="mlr.html"><a href="mlr.html#mlr-inf2"><i class="fa fa-check"></i><b>3.5.1</b> Inference for a linear combination of <span class="math inline">\(\beta\)</span>’s</a></li>
<li class="chapter" data-level="3.5.2" data-path="mlr.html"><a href="mlr.html#mlr-agstrat2"><i class="fa fa-check"></i><b>3.5.2</b> Example: Agstrat</a></li>
<li class="chapter" data-level="3.5.3" data-path="mlr.html"><a href="mlr.html#mlr-sleep2"><i class="fa fa-check"></i><b>3.5.3</b> Example: Sleep</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="mlr.html"><a href="mlr.html#mlr-anova"><i class="fa fa-check"></i><b>3.6</b> ANOVA for MLR</a><ul>
<li class="chapter" data-level="3.6.1" data-path="mlr.html"><a href="mlr.html#mean-squares"><i class="fa fa-check"></i><b>3.6.1</b> Mean Squares</a></li>
<li class="chapter" data-level="3.6.2" data-path="mlr.html"><a href="mlr.html#r2-and-adjusted-r2"><i class="fa fa-check"></i><b>3.6.2</b> <span class="math inline">\(R^2\)</span> and adjusted <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="3.6.3" data-path="mlr.html"><a href="mlr.html#anova-f-tests"><i class="fa fa-check"></i><b>3.6.3</b> ANOVA F-tests</a></li>
<li class="chapter" data-level="3.6.4" data-path="mlr.html"><a href="mlr.html#mlr-sleep3"><i class="fa fa-check"></i><b>3.6.4</b> Example: Sleep</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="mlr.html"><a href="mlr.html#model-checking"><i class="fa fa-check"></i><b>3.7</b> Model Checking</a><ul>
<li class="chapter" data-level="3.7.1" data-path="mlr.html"><a href="mlr.html#residual-plots"><i class="fa fa-check"></i><b>3.7.1</b> Residual plots</a></li>
<li class="chapter" data-level="3.7.2" data-path="mlr.html"><a href="mlr.html#outliers"><i class="fa fa-check"></i><b>3.7.2</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="mlr.html"><a href="mlr.html#mlr-visualizing-effects"><i class="fa fa-check"></i><b>3.8</b> MLR: Visualizing effects</a><ul>
<li class="chapter" data-level="3.8.1" data-path="mlr.html"><a href="mlr.html#partial-residual-plots"><i class="fa fa-check"></i><b>3.8.1</b> Partial residual plots</a></li>
<li class="chapter" data-level="3.8.2" data-path="mlr.html"><a href="mlr.html#example-sleep-1"><i class="fa fa-check"></i><b>3.8.2</b> Example: Sleep</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="mlr.html"><a href="mlr.html#collinearity"><i class="fa fa-check"></i><b>3.9</b> Collinearity</a><ul>
<li class="chapter" data-level="3.9.1" data-path="mlr.html"><a href="mlr.html#example-sleep-2"><i class="fa fa-check"></i><b>3.9.1</b> Example: Sleep</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>4</b> Logistic Regression</a><ul>
<li class="chapter" data-level="4.1" data-path="slr.html"><a href="slr.html#the-variables"><i class="fa fa-check"></i><b>4.1</b> The variables</a><ul>
<li class="chapter" data-level="4.1.1" data-path="logistic.html"><a href="logistic.html#logistic-donner1"><i class="fa fa-check"></i><b>4.1.1</b> Example: Donner party EDA</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="logistic.html"><a href="logistic.html#logistic-bernoulli"><i class="fa fa-check"></i><b>4.2</b> The Bernoulli distribution</a></li>
<li class="chapter" data-level="4.3" data-path="logistic.html"><a href="logistic.html#logistic-model"><i class="fa fa-check"></i><b>4.3</b> The logistic model form</a><ul>
<li class="chapter" data-level="4.3.1" data-path="logistic.html"><a href="logistic.html#logistic-int"><i class="fa fa-check"></i><b>4.3.1</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="logistic.html"><a href="logistic.html#logistic-est"><i class="fa fa-check"></i><b>4.4</b> Inference and estimation</a><ul>
<li class="chapter" data-level="4.4.1" data-path="logistic.html"><a href="logistic.html#confidence-intervals-for-pmbbeta_i"><i class="fa fa-check"></i><b>4.4.1</b> Confidence intervals for <span class="math inline">\(\pmb{\beta_i}\)</span></a></li>
<li class="chapter" data-level="4.4.2" data-path="logistic.html"><a href="logistic.html#hypothesis-tests-for-pmbbeta_i"><i class="fa fa-check"></i><b>4.4.2</b> Hypothesis tests for <span class="math inline">\(\pmb{\beta_i}\)</span></a></li>
<li class="chapter" data-level="4.4.3" data-path="logistic.html"><a href="logistic.html#r-glm"><i class="fa fa-check"></i><b>4.4.3</b> R <code>glm</code></a></li>
<li class="chapter" data-level="4.4.4" data-path="logistic.html"><a href="logistic.html#logistic-donner2"><i class="fa fa-check"></i><b>4.4.4</b> Example: Donner party model</a></li>
<li class="chapter" data-level="4.4.5" data-path="logistic.html"><a href="logistic.html#logistic-donner3"><i class="fa fa-check"></i><b>4.4.5</b> Example: Donner party, adding sex</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="logistic.html"><a href="logistic.html#logistic-dev"><i class="fa fa-check"></i><b>4.5</b> Deviance</a><ul>
<li class="chapter" data-level="4.5.1" data-path="logistic.html"><a href="logistic.html#drop-in-deviance-test"><i class="fa fa-check"></i><b>4.5.1</b> Drop in Deviance test</a></li>
<li class="chapter" data-level="4.5.2" data-path="logistic.html"><a href="logistic.html#example-nes"><i class="fa fa-check"></i><b>4.5.2</b> Example: NES</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="logistic.html"><a href="logistic.html#logistic-assump"><i class="fa fa-check"></i><b>4.6</b> Checking Assumptions</a><ul>
<li class="chapter" data-level="4.6.1" data-path="logistic.html"><a href="logistic.html#example-bwca1"><i class="fa fa-check"></i><b>4.6.1</b> Example: Boundary Waters Canoe Area (BWCA) blowdown</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="logistic.html"><a href="logistic.html#logistic-resid"><i class="fa fa-check"></i><b>4.7</b> Residuals and Case influence</a><ul>
<li class="chapter" data-level="4.7.1" data-path="logistic.html"><a href="logistic.html#example-bwca2"><i class="fa fa-check"></i><b>4.7.1</b> Example: Boundary Waters Canoe Area (BWCA) blowdown</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="logistic.html"><a href="logistic.html#binomial-responses"><i class="fa fa-check"></i><b>4.8</b> Binomial responses</a><ul>
<li class="chapter" data-level="4.8.1" data-path="logistic.html"><a href="logistic.html#connection-to-binary-responses"><i class="fa fa-check"></i><b>4.8.1</b> Connection to binary responses</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="logistic.html"><a href="logistic.html#inference-for-binomial-response-models"><i class="fa fa-check"></i><b>4.9</b> Inference for Binomial response models</a><ul>
<li class="chapter" data-level="4.9.1" data-path="logistic.html"><a href="logistic.html#example-krunnit-islands-archipelago-sleuth-case-study-21.1"><i class="fa fa-check"></i><b>4.9.1</b> Example: Krunnit Islands archipelago (Sleuth Case Study 21.1)</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="logistic.html"><a href="logistic.html#logistic-binomDev"><i class="fa fa-check"></i><b>4.10</b> Deviance for Binomial responses</a><ul>
<li class="chapter" data-level="4.10.1" data-path="logistic.html"><a href="logistic.html#logistic-gof"><i class="fa fa-check"></i><b>4.10.1</b> Goodness-of-fit test</a></li>
<li class="chapter" data-level="4.10.2" data-path="logistic.html"><a href="logistic.html#example-krunnit-islands-archipelago-sleuth-case-study-21.1-1"><i class="fa fa-check"></i><b>4.10.2</b> Example: Krunnit Islands archipelago (Sleuth Case Study 21.1)</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="logistic.html"><a href="logistic.html#logistic-assump"><i class="fa fa-check"></i><b>4.11</b> Checking Assumptions</a><ul>
<li class="chapter" data-level="4.11.1" data-path="logistic.html"><a href="logistic.html#example-krunnit-islands-archipelago-sleuth-case-study-21.1-2"><i class="fa fa-check"></i><b>4.11.1</b> Example: Krunnit Islands archipelago (Sleuth Case Study 21.1)</a></li>
</ul></li>
<li class="chapter" data-level="4.12" data-path="logistic.html"><a href="logistic.html#logistic-binomResid"><i class="fa fa-check"></i><b>4.12</b> Residuals and case influence for binomial responses</a><ul>
<li class="chapter" data-level="4.12.1" data-path="logistic.html"><a href="logistic.html#example-krunnit-islands-archipelago-sleuth-case-study-21.1-3"><i class="fa fa-check"></i><b>4.12.1</b> Example: Krunnit Islands archipelago (Sleuth Case Study 21.1)</a></li>
</ul></li>
<li class="chapter" data-level="4.13" data-path="logistic.html"><a href="logistic.html#logistic-quasi"><i class="fa fa-check"></i><b>4.13</b> Quasi-binomial logistic model</a><ul>
<li class="chapter" data-level="4.13.1" data-path="logistic.html"><a href="logistic.html#example-moth-predation-case-study-21.2"><i class="fa fa-check"></i><b>4.13.1</b> Example: Moth predation (Case Study 21.2)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="poisson.html"><a href="poisson.html"><i class="fa fa-check"></i><b>5</b> Poisson Regression</a><ul>
<li class="chapter" data-level="5.1" data-path="poisson.html"><a href="poisson.html#pois-dist"><i class="fa fa-check"></i><b>5.1</b> The Poisson distribution</a></li>
<li class="chapter" data-level="5.2" data-path="logistic.html"><a href="logistic.html#logistic-model"><i class="fa fa-check"></i><b>5.2</b> The Poisson model form</a><ul>
<li class="chapter" data-level="5.2.1" data-path="slr.html"><a href="slr.html#interpretation"><i class="fa fa-check"></i><b>5.2.1</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="slr.html"><a href="slr.html#eda"><i class="fa fa-check"></i><b>5.3</b> EDA</a><ul>
<li class="chapter" data-level="5.3.1" data-path="poisson.html"><a href="poisson.html#example-possums"><i class="fa fa-check"></i><b>5.3.1</b> Example: Possums</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="poisson.html"><a href="poisson.html#poisson-est"><i class="fa fa-check"></i><b>5.4</b> Inference and estimation</a><ul>
<li class="chapter" data-level="5.4.1" data-path="logistic.html"><a href="logistic.html#confidence-intervals-for-pmbbeta_i"><i class="fa fa-check"></i><b>5.4.1</b> Confidence intervals for <span class="math inline">\(\pmb{\beta_i}\)</span></a></li>
<li class="chapter" data-level="5.4.2" data-path="logistic.html"><a href="logistic.html#hypothesis-tests-for-pmbbeta_i"><i class="fa fa-check"></i><b>5.4.2</b> Hypothesis tests for <span class="math inline">\(\pmb{\beta_i}\)</span></a></li>
<li class="chapter" data-level="5.4.3" data-path="logistic.html"><a href="logistic.html#r-glm"><i class="fa fa-check"></i><b>5.4.3</b> R <code>glm</code></a></li>
<li class="chapter" data-level="5.4.4" data-path="poisson.html"><a href="poisson.html#pois-ex2"><i class="fa fa-check"></i><b>5.4.4</b> Example: Possums</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="poisson.html"><a href="poisson.html#pois-dev"><i class="fa fa-check"></i><b>5.5</b> Deviance for Binomial responses</a><ul>
<li class="chapter" data-level="5.5.1" data-path="poisson.html"><a href="poisson.html#pois-did"><i class="fa fa-check"></i><b>5.5.1</b> Drop-in-deviance test</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="poisson.html"><a href="poisson.html#pois-assump"><i class="fa fa-check"></i><b>5.6</b> Checking Assumptions</a><ul>
<li class="chapter" data-level="5.6.1" data-path="poisson.html"><a href="poisson.html#pois-gof"><i class="fa fa-check"></i><b>5.6.1</b> Goodness-of-fit test</a></li>
<li class="chapter" data-level="5.6.2" data-path="poisson.html"><a href="poisson.html#gof-alternative"><i class="fa fa-check"></i><b>5.6.2</b> GOF alternative</a></li>
<li class="chapter" data-level="5.6.3" data-path="poisson.html"><a href="poisson.html#example-possums-1"><i class="fa fa-check"></i><b>5.6.3</b> Example: Possums</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="poisson.html"><a href="poisson.html#pois-resid"><i class="fa fa-check"></i><b>5.7</b> Residuals and case influence for binomial responses</a><ul>
<li class="chapter" data-level="5.7.1" data-path="poisson.html"><a href="poisson.html#example-possums-2"><i class="fa fa-check"></i><b>5.7.1</b> Example: Possums</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="poisson.html"><a href="poisson.html#pois-quasi"><i class="fa fa-check"></i><b>5.8</b> Quasi-Poisson logistic model</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="rrstudio.html"><a href="rrstudio.html"><i class="fa fa-check"></i><b>A</b> R and Rstudio</a><ul>
<li class="chapter" data-level="A.1" data-path="rrstudio.html"><a href="rrstudio.html#running-rstudio"><i class="fa fa-check"></i><b>A.1</b> Running Rstudio</a></li>
<li class="chapter" data-level="A.2" data-path="rrstudio.html"><a href="rrstudio.html#r"><i class="fa fa-check"></i><b>A.2</b> Installing R</a></li>
<li class="chapter" data-level="A.3" data-path="rrstudio.html"><a href="rrstudio.html#rstudio"><i class="fa fa-check"></i><b>A.3</b> Installing Rstudio</a></li>
<li class="chapter" data-level="A.4" data-path="rrstudio.html"><a href="rrstudio.html#packages"><i class="fa fa-check"></i><b>A.4</b> Installing R packages</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="renviron.html"><a href="renviron.html"><i class="fa fa-check"></i><b>B</b> The R enviroment</a><ul>
<li class="chapter" data-level="B.1" data-path="renviron.html"><a href="renviron.html#workspace"><i class="fa fa-check"></i><b>B.1</b> Workspace</a></li>
<li class="chapter" data-level="B.2" data-path="renviron.html"><a href="renviron.html#working-directory"><i class="fa fa-check"></i><b>B.2</b> Working directory</a></li>
<li class="chapter" data-level="B.3" data-path="renviron.html"><a href="renviron.html#project"><i class="fa fa-check"></i><b>B.3</b> Rstudio projects</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="rreview.html"><a href="rreview.html"><i class="fa fa-check"></i><b>C</b> R for basic data analysis</a><ul>
<li class="chapter" data-level="C.1" data-path="rreview.html"><a href="rreview.html#basics"><i class="fa fa-check"></i><b>C.1</b> Basics</a><ul>
<li class="chapter" data-level="C.1.1" data-path="rreview.html"><a href="rreview.html#quick-tips"><i class="fa fa-check"></i><b>C.1.1</b> Quick Tips</a></li>
<li class="chapter" data-level="C.1.2" data-path="rreview.html"><a href="rreview.html#objects"><i class="fa fa-check"></i><b>C.1.2</b> Objects</a></li>
<li class="chapter" data-level="C.1.3" data-path="rreview.html"><a href="rreview.html#vectors"><i class="fa fa-check"></i><b>C.1.3</b> Vectors</a></li>
<li class="chapter" data-level="C.1.4" data-path="rreview.html"><a href="rreview.html#arithmetic"><i class="fa fa-check"></i><b>C.1.4</b> Arithmetic</a></li>
<li class="chapter" data-level="C.1.5" data-path="rreview.html"><a href="rreview.html#subsetting"><i class="fa fa-check"></i><b>C.1.5</b> Subsetting</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="rreview.html"><a href="rreview.html#data"><i class="fa fa-check"></i><b>C.2</b> Data</a><ul>
<li class="chapter" data-level="C.2.1" data-path="rreview.html"><a href="rreview.html#reading-data-into-r"><i class="fa fa-check"></i><b>C.2.1</b> Reading Data into R</a></li>
<li class="chapter" data-level="C.2.2" data-path="rreview.html"><a href="rreview.html#investigating-a-data-frame"><i class="fa fa-check"></i><b>C.2.2</b> Investigating a Data Frame</a></li>
<li class="chapter" data-level="C.2.3" data-path="rreview.html"><a href="rreview.html#access"><i class="fa fa-check"></i><b>C.2.3</b> Accessing Data</a></li>
<li class="chapter" data-level="C.2.4" data-path="rreview.html"><a href="rreview.html#Rreview-subset"><i class="fa fa-check"></i><b>C.2.4</b> Subsetting a Data Frame</a></li>
<li class="chapter" data-level="C.2.5" data-path="rreview.html"><a href="rreview.html#creating-a-data-frame"><i class="fa fa-check"></i><b>C.2.5</b> Creating a data frame</a></li>
<li class="chapter" data-level="C.2.6" data-path="rreview.html"><a href="rreview.html#adding-a-new-column-to-a-data-frame"><i class="fa fa-check"></i><b>C.2.6</b> Adding a new column to a data frame</a></li>
<li class="chapter" data-level="C.2.7" data-path="rreview.html"><a href="rreview.html#missing-data"><i class="fa fa-check"></i><b>C.2.7</b> Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="C.3" data-path="slr.html"><a href="slr.html#eda"><i class="fa fa-check"></i><b>C.3</b> EDA</a><ul>
<li class="chapter" data-level="C.3.1" data-path="rreview.html"><a href="rreview.html#categorical"><i class="fa fa-check"></i><b>C.3.1</b> Categorical:</a></li>
<li class="chapter" data-level="C.3.2" data-path="rreview.html"><a href="rreview.html#quantitative"><i class="fa fa-check"></i><b>C.3.2</b> Quantitative:</a></li>
<li class="chapter" data-level="C.3.3" data-path="rreview.html"><a href="rreview.html#Rreview-stats"><i class="fa fa-check"></i><b>C.3.3</b> Quantitative grouped by a categorical</a></li>
<li class="chapter" data-level="C.3.4" data-path="rreview.html"><a href="rreview.html#Rreview-graphs"><i class="fa fa-check"></i><b>C.3.4</b> Graphs</a></li>
<li class="chapter" data-level="C.3.5" data-path="rreview.html"><a href="rreview.html#reporting-results"><i class="fa fa-check"></i><b>C.3.5</b> Reporting Results</a></li>
</ul></li>
<li class="chapter" data-level="C.4" data-path="rreview.html"><a href="rreview.html#factors"><i class="fa fa-check"></i><b>C.4</b> Factor variables</a><ul>
<li class="chapter" data-level="C.4.1" data-path="rreview.html"><a href="rreview.html#renaming-factor-levels"><i class="fa fa-check"></i><b>C.4.1</b> Renaming factor levels</a></li>
<li class="chapter" data-level="C.4.2" data-path="rreview.html"><a href="rreview.html#recode-a-categorical-variable-with-many-levels"><i class="fa fa-check"></i><b>C.4.2</b> Recode a categorical variable with many levels</a></li>
<li class="chapter" data-level="C.4.3" data-path="rreview.html"><a href="rreview.html#converting-some-factor-levels-to-nas"><i class="fa fa-check"></i><b>C.4.3</b> Converting some factor levels to <code>NA</code>s</a></li>
<li class="chapter" data-level="C.4.4" data-path="rreview.html"><a href="rreview.html#changing-the-order-of-levels"><i class="fa fa-check"></i><b>C.4.4</b> Changing the order of levels</a></li>
<li class="chapter" data-level="C.4.5" data-path="rreview.html"><a href="rreview.html#recode-a-numerically-coded-categorical-variable"><i class="fa fa-check"></i><b>C.4.5</b> Recode a numerically coded categorical variable</a></li>
<li class="chapter" data-level="C.4.6" data-path="rreview.html"><a href="rreview.html#recode-a-factor-into-a-numeric"><i class="fa fa-check"></i><b>C.4.6</b> Recode a factor into a numeric</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="markdown.html"><a href="markdown.html"><i class="fa fa-check"></i><b>D</b> R Markdown</a><ul>
<li class="chapter" data-level="D.1" data-path="markdown.html"><a href="markdown.html#how-to-write-an-r-markdown-document"><i class="fa fa-check"></i><b>D.1</b> How to write an R Markdown document</a></li>
<li class="chapter" data-level="D.2" data-path="markdown.html"><a href="markdown.html#changing-r-markdown-chunk-evaluation-behavior"><i class="fa fa-check"></i><b>D.2</b> Changing R Markdown chunk evaluation behavior</a></li>
<li class="chapter" data-level="D.3" data-path="markdown.html"><a href="markdown.html#creating-a-new-r-markdown-document"><i class="fa fa-check"></i><b>D.3</b> Creating a new R Markdown document</a></li>
<li class="chapter" data-level="D.4" data-path="markdown.html"><a href="markdown.html#markdown-graphs"><i class="fa fa-check"></i><b>D.4</b> Extra: Graph formatting</a><ul>
<li class="chapter" data-level="D.4.1" data-path="markdown.html"><a href="markdown.html#adding-figure-numbers-and-captions"><i class="fa fa-check"></i><b>D.4.1</b> Adding figure numbers and captions</a></li>
<li class="chapter" data-level="D.4.2" data-path="markdown.html"><a href="markdown.html#resizing-graphs-in-markdown"><i class="fa fa-check"></i><b>D.4.2</b> Resizing graphs in Markdown</a></li>
<li class="chapter" data-level="D.4.3" data-path="markdown.html"><a href="markdown.html#changing-graph-formatting-in-r"><i class="fa fa-check"></i><b>D.4.3</b> Changing graph formatting in R</a></li>
<li class="chapter" data-level="D.4.4" data-path="markdown.html"><a href="markdown.html#hiding-r-commands"><i class="fa fa-check"></i><b>D.4.4</b> Hiding R commands</a></li>
<li class="chapter" data-level="D.4.5" data-path="markdown.html"><a href="markdown.html#global-changes-in-graph-format"><i class="fa fa-check"></i><b>D.4.5</b> Global changes in graph format</a></li>
<li class="chapter" data-level="D.4.6" data-path="markdown.html"><a href="markdown.html#comments"><i class="fa fa-check"></i><b>D.4.6</b> Comments:</a></li>
</ul></li>
<li class="chapter" data-level="D.5" data-path="markdown.html"><a href="markdown.html#markdown-tables"><i class="fa fa-check"></i><b>D.5</b> Extra: Table formatting</a><ul>
<li class="chapter" data-level="D.5.1" data-path="markdown.html"><a href="markdown.html#hiding-r-commands-and-r-output"><i class="fa fa-check"></i><b>D.5.1</b> Hiding R commands and R output</a></li>
<li class="chapter" data-level="D.5.2" data-path="markdown.html"><a href="markdown.html#markdown-tables-1"><i class="fa fa-check"></i><b>D.5.2</b> Markdown tables</a></li>
<li class="chapter" data-level="D.5.3" data-path="markdown.html"><a href="markdown.html#markdown-tables-via-kable"><i class="fa fa-check"></i><b>D.5.3</b> Markdown tables via <code>kable</code></a></li>
<li class="chapter" data-level="D.5.4" data-path="markdown.html"><a href="markdown.html#the-pander-package"><i class="fa fa-check"></i><b>D.5.4</b> The <code>pander</code> package</a></li>
<li class="chapter" data-level="D.5.5" data-path="markdown.html"><a href="markdown.html#the-stargazer-package"><i class="fa fa-check"></i><b>D.5.5</b> The <code>stargazer</code> package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="E" data-path="mathreview.html"><a href="mathreview.html"><i class="fa fa-check"></i><b>E</b> Math review</a><ul>
<li class="chapter" data-level="E.1" data-path="mathreview.html"><a href="mathreview.html#math-linear"><i class="fa fa-check"></i><b>E.1</b> Linear equations</a></li>
<li class="chapter" data-level="E.2" data-path="mathreview.html"><a href="mathreview.html#math-log"><i class="fa fa-check"></i><b>E.2</b> Logarithms</a><ul>
<li class="chapter" data-level="E.2.1" data-path="slr.html"><a href="slr.html#interpreting-logged-variables"><i class="fa fa-check"></i><b>E.2.1</b> Interpreting logged variables</a></li>
<li class="chapter" data-level="E.2.2" data-path="slr.html"><a href="slr.html#inverse-i.e.-reversing-the-log-getting-rid-of-the-log"><i class="fa fa-check"></i><b>E.2.2</b> Inverse (i.e. reversing the log, getting rid of the log, …)</a></li>
<li class="chapter" data-level="E.2.3" data-path="mathreview.html"><a href="mathreview.html#logarithms-in-r"><i class="fa fa-check"></i><b>E.2.3</b> Logarithms in R</a></li>
</ul></li>
<li class="chapter" data-level="E.3" data-path="mathreview.html"><a href="mathreview.html#math-exercises"><i class="fa fa-check"></i><b>E.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Math 245 Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="poisson" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Poisson Regression</h1>
<p>This chapter covers material from chapter 23 of Sleuth.</p>
<div id="pois-dist" class="section level2">
<h2><span class="header-section-number">5.1</span> The Poisson distribution</h2>
<p>The Poisson distribution is a probability model for a random variable that counts the number of “events” (or successes) that occur in a fixed period of time and/or space. For example:</p>
<ul>
<li>the number of accidents that occur <em>per month</em> at an intersection</li>
<li>the number of cancer cases <em>per year</em> in a county</li>
<li>the number of potholes <em>per mile</em> on interstate 35</li>
</ul>
<p>To model these types of counts with a Poisson distribution, we must assume that</p>
<ul>
<li>two events can’t occur at exactly the same time/location (e.g. two different accidents can’t occur at exactly the same time)</li>
<li>events occur independently over time/space (e.g. the occurance of one accident isn’t going to make another more or less likely)</li>
</ul>
<p>If <span class="math inline">\(Y\)</span> is a random variable with a Poisson distribution, then the probability that it equals some number <span class="math inline">\(y\)</span> is
<span class="math display">\[
P(Y = y) = \dfrac{e^{\lambda}\lambda^y}{y!}  \ \ \textrm{ for any } y = 0,1,2,\dotsc
\]</span>
Note that Poisson counts <span class="math inline">\(Y\)</span> don’t have an “upper limit” like Binomial counts do so it can take on any integer value from 0 on up.</p>
<p>The parameter <span class="math inline">\(\lambda\)</span> (“lambda”) in this model tells us the <em>mean</em> response value, or the expected number of events per unit of time/space:
<span class="math display">\[
E(Y) = \mu = \lambda
\]</span>
We need to have <span class="math inline">\(\lambda &gt;0\)</span> since our counts can’t take on negative values. The variance of <span class="math inline">\(Y\)</span> is <em>also</em> equal to the mean:
<span class="math display">\[
Var(Y) = \sigma^2 = \lambda
\]</span>
and the standard deviation is then equal to
<span class="math display">\[
SD(Y) = \sigma = \sqrt{\lambda}
\]</span></p>
<p>So the expected rate of events <span class="math inline">\(\mu = \lambda\)</span> also tells us how variable our observed counts are likely to be. The larger the mean rate of events, the more variable our counts will be. Hence, our Poisson regression model will <em>not</em> have a “constant variance” assumption. The Poisson distribution is also skewed right for small values of the mean rate but becomes more symmetric as <span class="math inline">\(\mu\)</span> gets bigger. The plots below display Poisson distributions for a few values of <span class="math inline">\(\mu\)</span>.</p>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-241-1.png" width="672" /></p>
</div>
<div id="logistic-model" class="section level2">
<h2><span class="header-section-number">5.2</span> The Poisson model form</h2>
<p>We will assume that our response <span class="math inline">\(Y_i\)</span> for case <span class="math inline">\(i\)</span> is modeled by a Poisson distribution with mean (expected rate) that we will denote as <span class="math inline">\(\mu(Y_i \mid X_i)\)</span> (instead of <span class="math inline">\(\lambda\)</span>, just to be consistent with earlier models):
<span class="math display">\[
Y_i \mid X_i \overset{indep.}{\sim} Pois(\mu(Y_i \mid X_i))
\]</span></p>
<p>Our modeling goal is once again to model the mean response <span class="math inline">\(\mu(Y_i \mid X_i)\)</span> as a function of predictor <span class="math inline">\(X_i = (x_{1,i}, \dotsc, x_{p,i})\)</span>. To do this we need to ensure that we have a model that always maps values of <span class="math inline">\(X_i\)</span> to <em>positive</em> values of <span class="math inline">\(\mu(Y_i \mid X_i)\)</span>. We will do this by using another <strong>generalized linear model</strong>.</p>
<p>The <strong>link function</strong> for our model is the log function defines the linear combination of predictors as the log of the mean response:
<span class="math display">\[
\ln(\mu(Y_i \mid X_i)) = \eta_i = \beta_0 + \beta_1 x_{1,i} + \dotsm +  \beta_p x_{p,i}
\]</span>
The <strong>kernel mean function</strong> for our model, which is the inverse of the link, is the exponential function so that
<span class="math display">\[
\mu(Y_i \mid X_i)  = e^{\eta_i} =e^{\beta_0 + \beta_1 x_{1,i} + \dotsm +  \beta_p x_{p,i}}
\]</span>
This ensures that for any value of <span class="math inline">\(\eta_i\)</span>, we get a positive value for our mean response. This is an example of a <em>log-linear</em> model.</p>
<p>The scatterplots below show an example of data generated from a SLR model and a Poisson model. Notice that the mean line in a SLR is a linear function of <span class="math inline">\(x\)</span> and we see symmetric, constant variation around the mean line. In the Poisson model data, we see a non-linear increase in the mean response as <span class="math inline">\(x\)</span> grows, along with increasing variation around the mean line. The variation around the mean line is right-skewed for smaller mean values but becomes more symmetric for larger mean values.
<img src="Math245notes_files/figure-html/unnamed-chunk-242-1.png" width="672" /></p>
<div id="interpretation" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Interpretation</h3>
<p>If we have untransformed predictors, we can say that a 1 unit increase in <span class="math inline">\(x_1\)</span>, for example, is associated with a <span class="math inline">\(e^{\beta_1}\)</span> <em>multiplicative</em> change in the <strong>mean response</strong> <span class="math inline">\(\mu\)</span>:
<span class="math display">\[
\mu(Y \mid X+1)  = e^{\beta_0 + \beta_1 (x_{1}+1) + \dotsm +  \beta_p x_{p}} = \mu(Y \mid X)e^{\beta_1} 
\]</span></p>
<p>Notice that this is similar to interpretation of an exponential model in SLR/MLR (Section <a href="slr.html#slr-trans">2.10</a>), except that in the Poisson model we are setting our linear combination of terms equal to the <strong>logged-mean response</strong> <span class="math inline">\(\ln(\mu_Y \mid X)\)</span>. In the SLR/MLR model, we are setting our linear combination of terms equal to the <strong>mean of the logged-responses</strong> <span class="math inline">\(\mu(\ln(y) \mid X)\)</span>. Interpretation of the Poisson log-linear model is easier because exponentiating the linear combination returns to us the the <em>mean</em> response.</p>
<p>If we took the natural log of <span class="math inline">\(x_1\)</span>, we can say that a multiplicative change of <span class="math inline">\(m\)</span> in <span class="math inline">\(x_1\)</span> is associated with a <span class="math inline">\(m^{\beta_1}\)</span> <em>multiplicative</em> change in the <strong>mean response</strong> <span class="math inline">\(\mu\)</span>:
<span class="math display">\[
\mu(Y \mid mX)  = e^{\beta_0 + \beta_1 \ln(mx_{1}) + \dotsm +  \beta_p x_{p}} = \mu(Y \mid X)m^{\beta_1} 
\]</span></p>
</div>
</div>
<div id="eda" class="section level2">
<h2><span class="header-section-number">5.3</span> EDA</h2>
<p>The Poisson model assumes that the quantitative predictors are linearly related to the log of the mean response. EDA to check this assume consists of a scatterplot of <span class="math inline">\(\ln(y)\)</span> vs. <span class="math inline">\(x\)</span>, looking for a transformation of <span class="math inline">\(x\)</span>, if needed, that displays a linear relationship. Constant variance is not assumed.</p>
<div id="example-possums" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Example: Possums</h3>
<p>The data in <code>possums</code> was collected from a sample of <span class="math inline">\(n = 151\)</span> 3-hectare sites in Australia. Our goal is to determine which factors are associated with good habitat for possums. The response recored for each site is <code>y</code>= the number of possum species found on the site. We will start by just considering the predictors <code>Bark</code> = bark quality index (low to high quality).</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="poisson.html#cb229-1"></a><span class="op">&gt;</span><span class="st"> </span>possums &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://people.carleton.edu/~kstclair/data/possums.csv&quot;</span>)</span>
<span id="cb229-2"><a href="poisson.html#cb229-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(possums<span class="op">$</span>y)</span>
<span id="cb229-3"><a href="poisson.html#cb229-3"></a><span class="co">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span></span>
<span id="cb229-4"><a href="poisson.html#cb229-4"></a><span class="co">##   0.000   0.000   1.000   1.477   2.000   5.000</span></span>
<span id="cb229-5"><a href="poisson.html#cb229-5"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(possums<span class="op">$</span>Bark)</span>
<span id="cb229-6"><a href="poisson.html#cb229-6"></a><span class="co">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span></span>
<span id="cb229-7"><a href="poisson.html#cb229-7"></a><span class="co">##   1.000   6.000   8.000   8.914  10.000  30.000</span></span></code></pre></div>
<p>At least 25% of sites had no possum species observed, and about 75% of sites had 2 or fewer species observed. The middle 50% of sites had bark indices between 6 and 10.</p>
<p>To check if <code>Bark</code> needs to be transformed, we need look at log-<code>y</code> vs <code>Bark</code>. Since <code>y</code> has many 0 species counts we will need to add a small amount (.5) to the vector <code>y</code> before plotting. As bark index increases, there is a slightly non-linear increase in number of species observed for untransformed <code>Bark</code>. The plot of <code>log(y)</code> vs. <code>log(bark)</code> looks more linear. A small amount of jitter was added in both directions to avoid overplotting issues.</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="poisson.html#cb230-1"></a><span class="op">&gt;</span><span class="st"> </span>plotA &lt;-<span class="st"> </span><span class="kw">ggplot</span>(possums, <span class="kw">aes</span>(<span class="dt">x=</span>Bark, <span class="dt">y =</span> y <span class="op">+</span><span class="st"> </span><span class="fl">.5</span>)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb230-2"><a href="poisson.html#cb230-2"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="fl">.01</span>, <span class="dt">height=</span>.<span class="dv">01</span>) <span class="op">+</span><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">se=</span><span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb230-3"><a href="poisson.html#cb230-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">scale_y_log10</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb230-4"><a href="poisson.html#cb230-4"></a><span class="op">+</span><span class="st">   </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&quot;Log-Number species vs. Bark index&quot;</span>)</span>
<span id="cb230-5"><a href="poisson.html#cb230-5"></a><span class="op">&gt;</span><span class="st"> </span></span>
<span id="cb230-6"><a href="poisson.html#cb230-6"></a><span class="er">&gt;</span><span class="st"> </span>plotB &lt;-<span class="st"> </span><span class="kw">ggplot</span>(possums, <span class="kw">aes</span>(<span class="dt">x=</span>Bark, <span class="dt">y =</span> y <span class="op">+</span><span class="st"> </span><span class="fl">.5</span>)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb230-7"><a href="poisson.html#cb230-7"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="fl">.01</span>, <span class="dt">height=</span>.<span class="dv">01</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_smooth</span>(<span class="dt">se=</span><span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb230-8"><a href="poisson.html#cb230-8"></a><span class="op">+</span><span class="st">   </span><span class="kw">scale_y_log10</span>() <span class="op">+</span><span class="st"> </span><span class="kw">scale_x_log10</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb230-9"><a href="poisson.html#cb230-9"></a><span class="op">+</span><span class="st">   </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&quot;Log-number species vs. log-Bark index&quot;</span>)</span>
<span id="cb230-10"><a href="poisson.html#cb230-10"></a><span class="op">&gt;</span><span class="st"> </span></span>
<span id="cb230-11"><a href="poisson.html#cb230-11"></a><span class="er">&gt;</span><span class="st"> </span></span>
<span id="cb230-12"><a href="poisson.html#cb230-12"></a><span class="er">&gt;</span><span class="st"> </span><span class="kw">grid.arrange</span>(plotA, plotB, <span class="dt">nrow=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-244-1.png" width="672" /></p>
</div>
</div>
<div id="poisson-est" class="section level2">
<h2><span class="header-section-number">5.4</span> Inference and estimation</h2>
<p>Estimation of Poisson model parameters <span class="math inline">\(\beta_0, \dotsc, \beta_p\)</span> is done using <strong>maximum likelihood</strong> estimation (again!). The likelihood function is the probability of the observed data, writen as a function of our unknown <span class="math inline">\(\beta\)</span>’s where here <span class="math inline">\(\mu(X_i) = e^{\beta_0 + \beta_1 x_{1,i} + \dotsm + \beta_p x_{p,i}}\)</span>
<span class="math display">\[
L(\beta) = \prod_{i=1}^n \dfrac{e^{\mu(X_i)}\mu(X_i)^{y_i}}{y_i!} 
\]</span></p>
<p>Like other GLMs, these MLE estimates of <span class="math inline">\(\beta\)</span> parameters are approximately normally distributed and unbiased when n is “large enough” or when <span class="math inline">\(\mu(X_i)\)</span>’s are “large enough.”</p>
<div id="confidence-intervals-for-pmbbeta_i" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Confidence intervals for <span class="math inline">\(\pmb{\beta_i}\)</span></h3>
<p>A <span class="math inline">\(C\)</span>% confidence interval for <span class="math inline">\(\beta_i\)</span> equals
<span class="math display">\[
\hat{\beta}_i \pm z^*SE(\hat{\beta}_i)
\]</span>
where <span class="math inline">\(z^*\)</span> is the <span class="math inline">\((100-C)/2\)</span> percentile from the <span class="math inline">\(N(0,1)\)</span> distribution. To get the multiplicative change in the mean response, we just exponentiate the CI:
<span class="math display">\[
e^{\hat{\beta}_i \pm z^*SE(\hat{\beta}_i)}
\]</span></p>
</div>
<div id="hypothesis-tests-for-pmbbeta_i" class="section level3">
<h3><span class="header-section-number">5.4.2</span> Hypothesis tests for <span class="math inline">\(\pmb{\beta_i}\)</span></h3>
<p>We can test the hypothesis
<span class="math display">\[
H_0: \beta_i = \beta^*_i
\]</span>
with the following z-test statistic:
<span class="math display">\[
z =\dfrac{\hat{\beta}_i - \beta^*_i}{SE(\hat{\beta}_i)}
\]</span>
where <span class="math inline">\(\beta^*_i\)</span> is our hypothesized value of <span class="math inline">\(\beta_i\)</span> . The <span class="math inline">\(N(0,1)\)</span> is used to compute the p-value that is appropriate for whatever <span class="math inline">\(H_A\)</span> is specified.</p>
<p>The usual test results given by standard regression output tests whether a parameter value (intercept or slope) is equal to 0 vs. not equal to 0:
<span class="math display">\[
H_0: \beta_i = 0 \ \ \ \ \ H_A: \beta_i \neq 0
\]</span>
with a test stat of
<span class="math display">\[
z =\dfrac{\hat{\beta}_i - 0}{SE(\hat{\beta}_i)}
\]</span></p>
</div>
<div id="r-glm" class="section level3">
<h3><span class="header-section-number">5.4.3</span> R <code>glm</code></h3>
<p>We fit a Poisson regression model in R with the <code>glm</code> function. The basic syntax is</p>
<pre><code>glm(y ~ x1 + x2, family = poisson, data= )</code></pre>
<p>Careful not to forget the <code>family=poisson</code> argument! If you omit this, you will just be trying to fit a regular MLR model which is not appropriate for a categorical response.</p>
<p>Once you fit a <code>glm</code> model, you can extract attributes of the model</p>
<ul>
<li><code>fitted(my.glm)</code> gives the estimated mean response <span class="math inline">\(\hat{\mu}_i\)</span> for each case in your data</li>
<li><code>predict(my.glm)</code> gives estimated <strong>log-mean</strong> <span class="math inline">\(\hat{\eta}_i\)</span> for each case in your data. Add <code>newdata=</code> to get predicted log-mean for new data.</li>
<li><code>predict(my.glm, type = "response")</code> gives estimated <strong>mean</strong> <span class="math inline">\(\hat{\mu}_i\)</span> for each case in your data. Add <code>newdata=</code> to get predicted means for new data.</li>
</ul>
<p>The <code>broom</code> package also allows us to get fitted probabilities or log odds for all cases in the data, or for new data:</p>
<ul>
<li><code>augment(my.glm)</code> gets estimated <strong>log-mean</strong> <span class="math inline">\(\hat{\eta}_i\)</span> added to the variables used in the <code>glm</code> fit.
<ul>
<li>add <code>data=my.data</code> to get estimated log-means added to the full data set <code>my.data</code> used in the <code>glm</code> fit</li>
<li>add <code>newdata= new.data</code> to get predicted log-means added to the new data set <code>new.data</code></li>
</ul></li>
<li><code>augment(my.glm, type.predict= "response")</code> gets estimated <strong>mean</strong> <span class="math inline">\(\hat{\mu}_i\)</span> added to the variables used in the <code>glm</code> fit.
<ul>
<li>add <code>data=my.data</code> to get estimated means added to the full data set <code>my.data</code> used in the <code>glm</code> fit</li>
<li>add <code>newdata= new.data</code> to get predicted means added to the new data set <code>new.data</code></li>
</ul></li>
</ul>
</div>
<div id="pois-ex2" class="section level3">
<h3><span class="header-section-number">5.4.4</span> Example: Possums</h3>
<p>Our EDA above used <code>log(y)</code> just to explore whether we needed to transform our predictors bark. (Since log of our response should be linearly related to our predictor in Poisson regression.) But our Poisson model is just fit with <code>y</code>, not <code>log(y)</code> since our Poisson model already assumes log-linearity. We will fit the following Poisson regression of number of species on log-bark index:
<span class="math display">\[
\ln(\mu(Y \mid x)) = \beta_0 + \beta_1 \ln(Bark)
\]</span></p>
<p>The model fit is below.</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="poisson.html#cb232-1"></a><span class="op">&gt;</span><span class="st"> </span>pos.glm &lt;-<span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(Bark), <span class="dt">family=</span>poisson, <span class="dt">data=</span>possums)</span>
<span id="cb232-2"><a href="poisson.html#cb232-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(pos.glm)</span>
<span id="cb232-3"><a href="poisson.html#cb232-3"></a><span class="co">## </span></span>
<span id="cb232-4"><a href="poisson.html#cb232-4"></a><span class="co">## Call:</span></span>
<span id="cb232-5"><a href="poisson.html#cb232-5"></a><span class="co">## glm(formula = y ~ log(Bark), family = poisson, data = possums)</span></span>
<span id="cb232-6"><a href="poisson.html#cb232-6"></a><span class="co">## </span></span>
<span id="cb232-7"><a href="poisson.html#cb232-7"></a><span class="co">## Deviance Residuals: </span></span>
<span id="cb232-8"><a href="poisson.html#cb232-8"></a><span class="co">##      Min        1Q    Median        3Q       Max  </span></span>
<span id="cb232-9"><a href="poisson.html#cb232-9"></a><span class="co">## -2.18523  -1.26246  -0.07764   0.55078   2.11368  </span></span>
<span id="cb232-10"><a href="poisson.html#cb232-10"></a><span class="co">## </span></span>
<span id="cb232-11"><a href="poisson.html#cb232-11"></a><span class="co">## Coefficients:</span></span>
<span id="cb232-12"><a href="poisson.html#cb232-12"></a><span class="co">##             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span id="cb232-13"><a href="poisson.html#cb232-13"></a><span class="co">## (Intercept)  -0.8801     0.3027  -2.907  0.00365 ** </span></span>
<span id="cb232-14"><a href="poisson.html#cb232-14"></a><span class="co">## log(Bark)     0.5945     0.1335   4.453 8.45e-06 ***</span></span>
<span id="cb232-15"><a href="poisson.html#cb232-15"></a><span class="co">## ---</span></span>
<span id="cb232-16"><a href="poisson.html#cb232-16"></a><span class="co">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb232-17"><a href="poisson.html#cb232-17"></a><span class="co">## </span></span>
<span id="cb232-18"><a href="poisson.html#cb232-18"></a><span class="co">## (Dispersion parameter for poisson family taken to be 1)</span></span>
<span id="cb232-19"><a href="poisson.html#cb232-19"></a><span class="co">## </span></span>
<span id="cb232-20"><a href="poisson.html#cb232-20"></a><span class="co">##     Null deviance: 187.49  on 150  degrees of freedom</span></span>
<span id="cb232-21"><a href="poisson.html#cb232-21"></a><span class="co">## Residual deviance: 167.51  on 149  degrees of freedom</span></span>
<span id="cb232-22"><a href="poisson.html#cb232-22"></a><span class="co">## AIC: 452.31</span></span>
<span id="cb232-23"><a href="poisson.html#cb232-23"></a><span class="co">## </span></span>
<span id="cb232-24"><a href="poisson.html#cb232-24"></a><span class="co">## Number of Fisher Scoring iterations: 5</span></span></code></pre></div>
<p>The estimated log mean function is
<span class="math display">\[
\ln(\hat{\mu}(y \mid x)) =  -0.8801 + 0.5945 \ln(Bark)
\]</span>
and the estimated mean function is
<span class="math display">\[
\hat{\mu}(Y \mid x) = e^{-0.8801 + 0.5945 \ln(Bark)} =  e^{-0.8801}Bark^{0.5945}
\]</span>
The estimated mean number of possums per 3-hectare when Bark quality is 10 is 1.63 species:
<span class="math display">\[
\hat{\mu}(Y \mid x=10) =   e^{-0.8801}10^{0.5945} =1.6302
\]</span></p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="poisson.html#cb233-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">predict</span>(pos.glm, <span class="dt">newdata=</span><span class="kw">list</span>(<span class="dt">Bark=</span><span class="dv">10</span>))  <span class="co"># log mean</span></span>
<span id="cb233-2"><a href="poisson.html#cb233-2"></a><span class="co">##         1 </span></span>
<span id="cb233-3"><a href="poisson.html#cb233-3"></a><span class="co">## 0.4887215</span></span>
<span id="cb233-4"><a href="poisson.html#cb233-4"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">exp</span>(<span class="kw">predict</span>(pos.glm, <span class="dt">newdata=</span><span class="kw">list</span>(<span class="dt">Bark=</span><span class="dv">10</span>)))  <span class="co"># mean </span></span>
<span id="cb233-5"><a href="poisson.html#cb233-5"></a><span class="co">##        1 </span></span>
<span id="cb233-6"><a href="poisson.html#cb233-6"></a><span class="co">## 1.630231</span></span>
<span id="cb233-7"><a href="poisson.html#cb233-7"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">predict</span>(pos.glm, <span class="dt">newdata=</span><span class="kw">list</span>(<span class="dt">Bark=</span><span class="dv">10</span>), <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)  <span class="co"># mean</span></span>
<span id="cb233-8"><a href="poisson.html#cb233-8"></a><span class="co">##        1 </span></span>
<span id="cb233-9"><a href="poisson.html#cb233-9"></a><span class="co">## 1.630231</span></span></code></pre></div>
<p>With <span class="math inline">\(n=151\)</span>, we have a large enough sample size to trust normal-inference methods for our MLE estimates. If <span class="math inline">\(n\)</span> was smaller, you would want to check summaries of the estimated mean values. Here we see that they range from an estimated 0.4 species per plot to 3.1 species per plot.</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="poisson.html#cb234-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(<span class="kw">fitted</span>(pos.glm))</span>
<span id="cb234-2"><a href="poisson.html#cb234-2"></a><span class="co">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span></span>
<span id="cb234-3"><a href="poisson.html#cb234-3"></a><span class="co">##  0.4147  1.2033  1.4277  1.4768  1.6302  3.1325</span></span></code></pre></div>
<p>Bark index has a statistically significant effect on the mean number of species (z=4.45, p &lt; 0.0001). Doubling bark index is associated with a 51% increase in the estimated mean number of species per 3-hectare plot (95% CI 26% to 81%).
<span class="math display">\[
2^{0.5945}  = 1.5099492 \ \ \ 2^{0.5945 + c(-1,1)*qnorm(.975)*0.1335} = 1.2594945, 1.8102076
\]</span></p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="poisson.html#cb235-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span>(.<span class="dv">5945</span>)  <span class="co"># double bark index</span></span>
<span id="cb235-2"><a href="poisson.html#cb235-2"></a><span class="co">## [1] 1.509949</span></span>
<span id="cb235-3"><a href="poisson.html#cb235-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="dv">100</span><span class="op">*</span>(<span class="dv">2</span><span class="op">^</span>(.<span class="dv">5945</span>) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb235-4"><a href="poisson.html#cb235-4"></a><span class="co">## [1] 50.99492</span></span>
<span id="cb235-5"><a href="poisson.html#cb235-5"></a><span class="op">&gt;</span><span class="st"> </span><span class="co"># 95% CI for beta1</span></span>
<span id="cb235-6"><a href="poisson.html#cb235-6"></a><span class="er">&gt;</span><span class="st"> </span><span class="fl">0.5945</span> <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">*</span><span class="kw">qnorm</span>(.<span class="dv">975</span>)<span class="op">*</span><span class="fl">0.1335</span></span>
<span id="cb235-7"><a href="poisson.html#cb235-7"></a><span class="co">## [1] 0.3328448 0.8561552</span></span>
<span id="cb235-8"><a href="poisson.html#cb235-8"></a><span class="op">&gt;</span><span class="st"> </span><span class="co"># 95% CI for factor change in mu (doubling bark)</span></span>
<span id="cb235-9"><a href="poisson.html#cb235-9"></a><span class="er">&gt;</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span>(<span class="fl">0.5945</span> <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">*</span><span class="kw">qnorm</span>(.<span class="dv">975</span>)<span class="op">*</span><span class="fl">0.1335</span>)</span>
<span id="cb235-10"><a href="poisson.html#cb235-10"></a><span class="co">## [1] 1.259494 1.810208</span></span>
<span id="cb235-11"><a href="poisson.html#cb235-11"></a><span class="op">&gt;</span><span class="st"> </span><span class="dv">100</span><span class="op">*</span>(<span class="dv">2</span><span class="op">^</span>(<span class="fl">0.5945</span> <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">*</span><span class="kw">qnorm</span>(.<span class="dv">975</span>)<span class="op">*</span><span class="fl">0.1335</span>) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb235-12"><a href="poisson.html#cb235-12"></a><span class="co">## [1] 25.94945 81.02076</span></span></code></pre></div>
<p>We can visualize the mean response <span class="math inline">\(\hat{\mu}(Y \mid x) = e^{-0.8801 + 0.5945 \ln(Bark)}\)</span> on a plot log-bark and number of species by first plotting (un-logged) <code>y</code> against the log of <code>Bark</code>. Then we add the <code>geom_smooth</code> with <code>glm</code> smoother method and a <code>poisson</code> family listed as the argument. Here we also include a smaller amount of <code>jitter</code> to avoid overplotting.
$as a function of Bark index</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="poisson.html#cb236-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(possums, <span class="kw">aes</span>(<span class="dt">x=</span>Bark, <span class="dt">y=</span>y)) <span class="op">+</span></span>
<span id="cb236-2"><a href="poisson.html#cb236-2"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="fl">.01</span>, <span class="dt">height=</span>.<span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">scale_x_log10</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb236-3"><a href="poisson.html#cb236-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;glm&quot;</span>, <span class="dt">method.args =</span> <span class="kw">list</span>(<span class="dt">family=</span>poisson), <span class="dt">se=</span><span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb236-4"><a href="poisson.html#cb236-4"></a><span class="op">+</span><span class="st">   </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&quot;Poisson regression of # species on log-bark index&quot;</span>, </span>
<span id="cb236-5"><a href="poisson.html#cb236-5"></a><span class="op">+</span><span class="st">        </span><span class="dt">y =</span> <span class="st">&quot;# of species&quot;</span>, <span class="dt">x=</span><span class="st">&quot;bark index&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-249-1.png" width="672" /></p>
</div>
</div>
<div id="pois-dev" class="section level2">
<h2><span class="header-section-number">5.5</span> Deviance for Binomial responses</h2>
<p>In Poisson regression, the deviance is equal to
<span class="math display">\[
G^2 = 2[\ln L(\bar{\mu}) - \ln L(\hat{\mu}(X))] = 2\sum_{i=1}^n \left[ y_i \ln \left( \dfrac{y_i}{\hat{\mu}(X_i)} \right) - (y_i- \hat{\mu}(X_i))  \right]
\]</span>
Note that cases with large <span class="math inline">\(y_i\)</span> can contribute the most to this summation of individual case-level deviance.</p>
<p>Again, the two likelihoods that are used to construct residual deviance are:</p>
<ul>
<li><span class="math inline">\(L(\hat{\mu}(X)):\)</span> likelihood of the data that plugs in estimates <span class="math inline">\(\hat{\mu}(X_i)\)</span> from the Poisson model.</li>
<li><span class="math inline">\(L(\bar{\mu}):\)</span> likelihood of the data that plugs in estimates <span class="math inline">\(\bar{\mu} = y_i\)</span>, basing a case’s “predicted” value soley on the response observed for that case. This again is called a <strong>saturated</strong> model and it will always have a higher likelihood than the logistic model: <span class="math inline">\(L(\bar{\mu}) \geq L(\hat{\mu}(X))\)</span>.</li>
</ul>
<p>Deviance for binomial models can be used for two types of hypothesis tests:</p>
<div id="pois-did" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Drop-in-deviance test</h3>
<p>This test is used to compare two models, just like in logistic models. Details are in Section <a href="logistic.html#logistic-dev">4.5</a>. One difference between the logistic model and Poisson is the “large sample size” condition needed to trust the drop-in-deviance p-value approximation. In Poisson models, we need either a large sample size <span class="math inline">\(n\)</span> or <span class="math inline">\(\hat{\mu}\)</span>’s that are large.</p>
<p>Two compare two Poisson models using deviance, run</p>
<pre><code>anova(pois.red, pois.full, test = &quot;Chisq&quot;)</code></pre>
</div>
</div>
<div id="pois-assump" class="section level2">
<h2><span class="header-section-number">5.6</span> Checking Assumptions</h2>
<p><strong>Assumptions</strong> in a Poisson model include</p>
<ul>
<li><strong>Cases are independent:</strong> Independence of cases takes an understanding of how the data was collected.</li>
<li><strong>Log-mean linearity:</strong> Log-mean linearity can be checked with an a plot of log-response against quantitative predictors and residual plots.</li>
</ul>
<p>A <strong>third assumption</strong> is that given predictor values, the <strong>counts of events <span class="math inline">\(Y_i\)</span> has a Poisson distribution</strong>. This means that for each case <span class="math inline">\(i\)</span> we assume the following:</p>
<ul>
<li><strong>The events occur independently</strong>, and there is no clustering of events across time or space. Clustering of event occurrences induces more variation in our responses than our Poisson model assumes.</li>
</ul>
<p>For example, if one rush hour accident makes more accidents more likely in that time period, then we could see big swings in monthly accident counts. Some months with no rush hour accidents will see low counts while months with a rush hour accident could see a big uptick in total accident counts. This idea is demonstrated in the code below with the <code>y.clus</code> variable (10 accidents per month in winter months and 0 in other months) which has the same mean as a Poisson vector of accident counts, but which has a much larger measure of SD.</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="poisson.html#cb238-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="co"># monthly accident counts from a Poisson with mean around 3:</span></span>
<span id="cb238-2"><a href="poisson.html#cb238-2"></a><span class="er">&gt;</span><span class="st"> </span>y.pois &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">0</span>, <span class="dv">4</span>)</span>
<span id="cb238-3"><a href="poisson.html#cb238-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">mean</span>(y.pois)</span>
<span id="cb238-4"><a href="poisson.html#cb238-4"></a><span class="co">## [1] 3.333333</span></span>
<span id="cb238-5"><a href="poisson.html#cb238-5"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">sd</span>(y.pois)</span>
<span id="cb238-6"><a href="poisson.html#cb238-6"></a><span class="co">## [1] 1.922751</span></span>
<span id="cb238-7"><a href="poisson.html#cb238-7"></a><span class="op">&gt;</span><span class="st"> </span><span class="co"># monthly accident counts clustered in winter with mean around 3:</span></span>
<span id="cb238-8"><a href="poisson.html#cb238-8"></a><span class="er">&gt;</span><span class="st"> </span>y.clus &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">10</span>,<span class="dv">10</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">10</span>)</span>
<span id="cb238-9"><a href="poisson.html#cb238-9"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">mean</span>(y.clus)   <span class="co"># same average</span></span>
<span id="cb238-10"><a href="poisson.html#cb238-10"></a><span class="co">## [1] 3.333333</span></span>
<span id="cb238-11"><a href="poisson.html#cb238-11"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">sd</span>(y.clus)     <span class="co"># much bigger variance than poisson counts!</span></span>
<span id="cb238-12"><a href="poisson.html#cb238-12"></a><span class="co">## [1] 4.92366</span></span></code></pre></div>
<ul>
<li><strong>We have enough explanatory power in our predictors to adequately model the mean response.</strong> If we lack this, then we can’t adequately explain variations in our observed counts and we our residual deviance will be very large.</li>
</ul>
<p>If one, or both, of these assumptions is violated, then it often induces <strong>extra-Poisson variation</strong> (a.k.a. <strong>overdispersion</strong>). This means that the actual variation in our response <span class="math inline">\(SD(Y\mid X_i)\)</span> is <strong>larger</strong> than the Poisson SD of <span class="math inline">\(\sqrt{\mu(X_i)}\)</span> that our model assumes. So the response variation is more dispersed than what our model assumes, making our reported <strong>standard errors and p-values too small</strong> and we could be over-reporting statistical significance.</p>
<p>We can use another goodness-of-fit test, when <span class="math inline">\(\mu_i\)</span> are large enough, to check our Poisson distribution assumption. If we do find evidence of lack-of-fit in our model, then you should</p>
<ul>
<li>Check deviance residuals as case influence stats to see if an outlier(s) is affecting GOF results.</li>
<li>Check the log mean form and see if transformations of quantitative predictors are needed</li>
<li>If outliers and transformations aren’t a concern, then consider an alternative model:
<ul>
<li>quasi-Poisson logistic model</li>
<li>a model that allows for correlated trials (like a mixed-effects Poisson model)</li>
</ul></li>
</ul>
<div id="pois-gof" class="section level3">
<h3><span class="header-section-number">5.6.1</span> Goodness-of-fit test</h3>
<p>In our Poisson model, we are assuming that an observed count for case <span class="math inline">\(i\)</span> behaves like a Poisson random variable. We compare our Poisson model’s estimated mean counts for each case to the observed counts from the saturated model described above. The saturated model will have the best “fit” (highest likelihood) of the two models, but if the “fit” (likelihood) of the logistic model is “close” then we can claim that the logistic model is adequate. This is the motivation behind a “goodness-of-fit” test.</p>
<p>Our hypothese for the GOF test are:
<span class="math display">\[
H_0: \textrm{Poisson model}
\]</span>
vs. 
<span class="math display">\[
H_A: \textrm{saturated model}
\]</span></p>
<p>The test statistic for this is equal to the <strong>residual deviance of the Poisson model</strong> (difference in the <span class="math inline">\(H_A\)</span> and <span class="math inline">\(H_0\)</span> likelihoods):
<span class="math display">\[
G^2 = 2[\ln L(\bar{\mu}) - \ln L(\hat{\mu}(X))]
\]</span></p>
<p>If <span class="math inline">\(H_0\)</span> is true and the data does fit the Poisson model, then when estimated <span class="math inline">\(\hat{\mu}_i\)</span>’s are large, <span class="math inline">\(G^2\)</span> will have an approximate <strong>chi-square distribution</strong> with <span class="math inline">\(n - (p+1)\)</span> (model) degrees of freedom. (Note that <span class="math inline">\(n-(p+1)\)</span> is the difference in the number of parameters in the two models.) The p-value is the probability of observing deviance larger than our model’s value:
<span class="math display">\[
p-value = 1-P(\chi^2 &gt; G^2) = 1-pchisq(G^2, df=n-(p+1))
\]</span>
The suggested rule of thumb for “large <span class="math inline">\(\hat{\mu}_i\)</span>”" is that we want most <span class="math inline">\(\hat{\mu}_i\)</span>’s to be at least 5.</p>
<p>For a GOF test, you should consider the following interpretations for “large” or “small” p-values:</p>
<ul>
<li><strong>Do not reject the null:</strong> (large p-value)
<ul>
<li>Your Poisson model is adequate.</li>
<li>You don’t have a large enough sample size <span class="math inline">\(n\)</span> to have the <em>power</em> to detect inadequacies in your model.</li>
</ul></li>
<li><strong>Reject the null:</strong> (small p-value)
<ul>
<li>You have outlier(s) that are inflating the residual deviance.</li>
<li>Your logistic model is inadequate.
<ul>
<li>Your mean model is inadequate, it is ill-fitting and transformations are needed</li>
<li>Extra-Poisson variation: your response counts aren’t well modeled by a Poisson model. For each case:
<ul>
<li>events occurances are not independent, usually clustered in some way</li>
<li>your choice of predictors isn’t sufficient (i.e. you are missing key explanatory variables)</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="gof-alternative" class="section level3">
<h3><span class="header-section-number">5.6.2</span> GOF alternative</h3>
<p>If the GOF p-value approximation is suspect due to small estimated means, then one ad hoc method of assessing the “Poisson-ness” of the data would be to compare the sample mean and variances of cases with similar predictor values. Since a Poisson variable should have mean and variances that are similar in size, this can be used to detect if our counts are overdispersed. The basic algorithm is similar to that used in the BWCA empirical log-odds plot outlined in Section @ref(#example-bwca1).</p>
<ol style="list-style-type: decimal">
<li>Group cases into groups with similar predictor values</li>
<li>Within each group, compute the sample mean and sample variance of the observed counts <code>y</code></li>
<li>Plot means against variances, if they following the y=x line then the Poisson assumption looks adequate.</li>
</ol>
</div>
<div id="example-possums-1" class="section level3">
<h3><span class="header-section-number">5.6.3</span> Example: Possums</h3>
<p>In Section <a href="poisson.html#pois-ex2">5.4.4</a> we tested the statistical significance of log-Bark with a Wald z-test. We could have instead used a drop in deviance test for this one term. Hypotheses are the same but the mechanics of each are slightly different. Either method is ok since n=151 is fairly large so their conclusions should be similar.</p>
<p>Using <code>anova</code> for this one-term model will test the significance of the one term, log-Bark, against the “null” model with only the intercept term. Here our test statistic is <span class="math inline">\(G^2 = 19.979\)</span> since this is the amount that the residual deviance decreases when adding log-Bark. The p-value, comptuted from a chi-square distribution with 1 degree of freedom, is extremely small indicating the strong significance of this term.</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="poisson.html#cb239-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">anova</span>(pos.glm, <span class="dt">test=</span><span class="st">&quot;Chisq&quot;</span>)</span>
<span id="cb239-2"><a href="poisson.html#cb239-2"></a><span class="co">## Analysis of Deviance Table</span></span>
<span id="cb239-3"><a href="poisson.html#cb239-3"></a><span class="co">## </span></span>
<span id="cb239-4"><a href="poisson.html#cb239-4"></a><span class="co">## Model: poisson, link: log</span></span>
<span id="cb239-5"><a href="poisson.html#cb239-5"></a><span class="co">## </span></span>
<span id="cb239-6"><a href="poisson.html#cb239-6"></a><span class="co">## Response: y</span></span>
<span id="cb239-7"><a href="poisson.html#cb239-7"></a><span class="co">## </span></span>
<span id="cb239-8"><a href="poisson.html#cb239-8"></a><span class="co">## Terms added sequentially (first to last)</span></span>
<span id="cb239-9"><a href="poisson.html#cb239-9"></a><span class="co">## </span></span>
<span id="cb239-10"><a href="poisson.html#cb239-10"></a><span class="co">## </span></span>
<span id="cb239-11"><a href="poisson.html#cb239-11"></a><span class="co">##           Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    </span></span>
<span id="cb239-12"><a href="poisson.html#cb239-12"></a><span class="co">## NULL                        150     187.49              </span></span>
<span id="cb239-13"><a href="poisson.html#cb239-13"></a><span class="co">## log(Bark)  1   19.979       149     167.51 7.828e-06 ***</span></span>
<span id="cb239-14"><a href="poisson.html#cb239-14"></a><span class="co">## ---</span></span>
<span id="cb239-15"><a href="poisson.html#cb239-15"></a><span class="co">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span></code></pre></div>
<div id="goodness-of-fit" class="section level4">
<h4><span class="header-section-number">5.6.3.1</span> Goodness-of-fit</h4>
<p>We might be tempted to take the deviance from our log-Bark model and run a GOF test to assess Poisson model adequacy:</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="poisson.html#cb240-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(pos.glm)</span>
<span id="cb240-2"><a href="poisson.html#cb240-2"></a><span class="co">## </span></span>
<span id="cb240-3"><a href="poisson.html#cb240-3"></a><span class="co">## Call:</span></span>
<span id="cb240-4"><a href="poisson.html#cb240-4"></a><span class="co">## glm(formula = y ~ log(Bark), family = poisson, data = possums)</span></span>
<span id="cb240-5"><a href="poisson.html#cb240-5"></a><span class="co">## </span></span>
<span id="cb240-6"><a href="poisson.html#cb240-6"></a><span class="co">## Deviance Residuals: </span></span>
<span id="cb240-7"><a href="poisson.html#cb240-7"></a><span class="co">##      Min        1Q    Median        3Q       Max  </span></span>
<span id="cb240-8"><a href="poisson.html#cb240-8"></a><span class="co">## -2.18523  -1.26246  -0.07764   0.55078   2.11368  </span></span>
<span id="cb240-9"><a href="poisson.html#cb240-9"></a><span class="co">## </span></span>
<span id="cb240-10"><a href="poisson.html#cb240-10"></a><span class="co">## Coefficients:</span></span>
<span id="cb240-11"><a href="poisson.html#cb240-11"></a><span class="co">##             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span id="cb240-12"><a href="poisson.html#cb240-12"></a><span class="co">## (Intercept)  -0.8801     0.3027  -2.907  0.00365 ** </span></span>
<span id="cb240-13"><a href="poisson.html#cb240-13"></a><span class="co">## log(Bark)     0.5945     0.1335   4.453 8.45e-06 ***</span></span>
<span id="cb240-14"><a href="poisson.html#cb240-14"></a><span class="co">## ---</span></span>
<span id="cb240-15"><a href="poisson.html#cb240-15"></a><span class="co">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb240-16"><a href="poisson.html#cb240-16"></a><span class="co">## </span></span>
<span id="cb240-17"><a href="poisson.html#cb240-17"></a><span class="co">## (Dispersion parameter for poisson family taken to be 1)</span></span>
<span id="cb240-18"><a href="poisson.html#cb240-18"></a><span class="co">## </span></span>
<span id="cb240-19"><a href="poisson.html#cb240-19"></a><span class="co">##     Null deviance: 187.49  on 150  degrees of freedom</span></span>
<span id="cb240-20"><a href="poisson.html#cb240-20"></a><span class="co">## Residual deviance: 167.51  on 149  degrees of freedom</span></span>
<span id="cb240-21"><a href="poisson.html#cb240-21"></a><span class="co">## AIC: 452.31</span></span>
<span id="cb240-22"><a href="poisson.html#cb240-22"></a><span class="co">## </span></span>
<span id="cb240-23"><a href="poisson.html#cb240-23"></a><span class="co">## Number of Fisher Scoring iterations: 5</span></span>
<span id="cb240-24"><a href="poisson.html#cb240-24"></a><span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="fl">167.51</span>, <span class="dt">df=</span><span class="dv">149</span>)  <span class="co"># p-value??</span></span>
<span id="cb240-25"><a href="poisson.html#cb240-25"></a><span class="co">## [1] 0.1425203</span></span></code></pre></div>
<p>While the goodness of fit test gives a p-value of 0.1425, suggesting adequacy, we should be suspect because most estimated means are small and well below our “large <span class="math inline">\(\hat{\mu}_i\)</span>” threshold of 5.</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="poisson.html#cb241-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(<span class="kw">fitted</span>(pos.glm))</span>
<span id="cb241-2"><a href="poisson.html#cb241-2"></a><span class="co">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span></span>
<span id="cb241-3"><a href="poisson.html#cb241-3"></a><span class="co">##  0.4147  1.2033  1.4277  1.4768  1.6302  3.1325</span></span></code></pre></div>
<p>Our alternative method of checking whether our response is behaving like Poisson counts is the EDA check of sample means vs variances. We need to group cases by similar bark amounts. We can first note that the bark index is a rather discrete measure with many values (especially in mid-range values)</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="poisson.html#cb242-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">table</span>(possums<span class="op">$</span>Bark)</span>
<span id="cb242-2"><a href="poisson.html#cb242-2"></a><span class="co">## </span></span>
<span id="cb242-3"><a href="poisson.html#cb242-3"></a><span class="co">##  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 23 24 27 30 </span></span>
<span id="cb242-4"><a href="poisson.html#cb242-4"></a><span class="co">##  2  2 11 15 26 19 16 10 13  5  5  4  3  4  3  4  2  3  1  1  1  1</span></span></code></pre></div>
<p>We could simply try grouping by each individual bark value and getting the mean and variance of the observed counts for each. This will result in some 1 case bark values having a variance of <code>NA</code> (since we can’t measure variability of one data value):</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="poisson.html#cb243-1"></a><span class="op">&gt;</span><span class="st"> </span>pos.byBark &lt;-<span class="st"> </span>possums <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb243-2"><a href="poisson.html#cb243-2"></a><span class="op">+</span><span class="st">   </span><span class="kw">group_by</span>(Bark) <span class="op">%&gt;%</span></span>
<span id="cb243-3"><a href="poisson.html#cb243-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">summarize</span>(<span class="dt">nY =</span> <span class="kw">n</span>(), <span class="dt">meanY =</span> <span class="kw">mean</span>(y), <span class="dt">varY =</span> <span class="kw">var</span>(y))</span>
<span id="cb243-4"><a href="poisson.html#cb243-4"></a><span class="op">&gt;</span><span class="st"> </span>pos.byBark <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">n=</span><span class="ot">Inf</span>)</span>
<span id="cb243-5"><a href="poisson.html#cb243-5"></a><span class="co">## # A tibble: 22 x 4</span></span>
<span id="cb243-6"><a href="poisson.html#cb243-6"></a><span class="co">##     Bark    nY meanY   varY</span></span>
<span id="cb243-7"><a href="poisson.html#cb243-7"></a><span class="co">##    &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;</span></span>
<span id="cb243-8"><a href="poisson.html#cb243-8"></a><span class="co">##  1     1     2 0.5    0.5  </span></span>
<span id="cb243-9"><a href="poisson.html#cb243-9"></a><span class="co">##  2     3     2 0      0    </span></span>
<span id="cb243-10"><a href="poisson.html#cb243-10"></a><span class="co">##  3     4    11 1      0.6  </span></span>
<span id="cb243-11"><a href="poisson.html#cb243-11"></a><span class="co">##  4     5    15 0.933  0.781</span></span>
<span id="cb243-12"><a href="poisson.html#cb243-12"></a><span class="co">##  5     6    26 1.08   1.11 </span></span>
<span id="cb243-13"><a href="poisson.html#cb243-13"></a><span class="co">##  6     7    19 1.79   1.06 </span></span>
<span id="cb243-14"><a href="poisson.html#cb243-14"></a><span class="co">##  7     8    16 1.12   0.917</span></span>
<span id="cb243-15"><a href="poisson.html#cb243-15"></a><span class="co">##  8     9    10 1.8    1.96 </span></span>
<span id="cb243-16"><a href="poisson.html#cb243-16"></a><span class="co">##  9    10    13 1.69   2.23 </span></span>
<span id="cb243-17"><a href="poisson.html#cb243-17"></a><span class="co">## 10    11     5 1.8    1.7  </span></span>
<span id="cb243-18"><a href="poisson.html#cb243-18"></a><span class="co">## 11    12     5 2      2    </span></span>
<span id="cb243-19"><a href="poisson.html#cb243-19"></a><span class="co">## 12    13     4 1      0.667</span></span>
<span id="cb243-20"><a href="poisson.html#cb243-20"></a><span class="co">## 13    14     3 1.33   2.33 </span></span>
<span id="cb243-21"><a href="poisson.html#cb243-21"></a><span class="co">## 14    15     4 3      3.33 </span></span>
<span id="cb243-22"><a href="poisson.html#cb243-22"></a><span class="co">## 15    16     3 2.33   2.33 </span></span>
<span id="cb243-23"><a href="poisson.html#cb243-23"></a><span class="co">## 16    17     4 3.5    1.67 </span></span>
<span id="cb243-24"><a href="poisson.html#cb243-24"></a><span class="co">## 17    18     2 2      2    </span></span>
<span id="cb243-25"><a href="poisson.html#cb243-25"></a><span class="co">## 18    19     3 1.33   2.33 </span></span>
<span id="cb243-26"><a href="poisson.html#cb243-26"></a><span class="co">## 19    23     1 2     NA    </span></span>
<span id="cb243-27"><a href="poisson.html#cb243-27"></a><span class="co">## 20    24     1 3     NA    </span></span>
<span id="cb243-28"><a href="poisson.html#cb243-28"></a><span class="co">## 21    27     1 1     NA    </span></span>
<span id="cb243-29"><a href="poisson.html#cb243-29"></a><span class="co">## 22    30     1 3     NA</span></span></code></pre></div>
<p>Then plot mean count vs the variance of count. The means and variances for each value of bark are similar, so we have no graphical evidence of lack of fit.</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="poisson.html#cb244-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(pos.byBark, <span class="kw">aes</span>(<span class="dt">x=</span>meanY, <span class="dt">y=</span>varY)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb244-2"><a href="poisson.html#cb244-2"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb244-3"><a href="poisson.html#cb244-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_abline</span>(<span class="dt">intercept=</span><span class="dv">0</span>, <span class="dt">slope=</span><span class="dv">1</span>, <span class="dt">linetype=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-256-1.png" width="672" /></p>
<p>Alternatively, we could first group the cases according to the <code>ntile</code> function. Here we divide cases up into 12 similar groups based on bark, then get stats for each group and plot. A similar conclusion is made with this visual. No strong evidence of a trend in variance always being bigger (or smaller) than the mean count.</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="poisson.html#cb245-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(tidyverse)</span>
<span id="cb245-2"><a href="poisson.html#cb245-2"></a><span class="op">&gt;</span><span class="st"> </span>pos.byBark2 &lt;-<span class="st"> </span>possums <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb245-3"><a href="poisson.html#cb245-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">mutate</span>(<span class="dt">Bark.grp =</span> <span class="kw">ntile</span>(Bark, <span class="dt">n=</span><span class="dv">12</span>)) <span class="op">%&gt;%</span></span>
<span id="cb245-4"><a href="poisson.html#cb245-4"></a><span class="op">+</span><span class="st">   </span><span class="kw">group_by</span>(Bark.grp) <span class="op">%&gt;%</span></span>
<span id="cb245-5"><a href="poisson.html#cb245-5"></a><span class="op">+</span><span class="st">   </span><span class="kw">summarize</span>(<span class="dt">nY =</span> <span class="kw">n</span>(), <span class="dt">meanY =</span> <span class="kw">mean</span>(y), <span class="dt">varY =</span> <span class="kw">var</span>(y))</span>
<span id="cb245-6"><a href="poisson.html#cb245-6"></a><span class="op">&gt;</span><span class="st"> </span>pos.byBark2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">n=</span><span class="ot">Inf</span>)</span>
<span id="cb245-7"><a href="poisson.html#cb245-7"></a><span class="co">## # A tibble: 12 x 4</span></span>
<span id="cb245-8"><a href="poisson.html#cb245-8"></a><span class="co">##    Bark.grp    nY meanY  varY</span></span>
<span id="cb245-9"><a href="poisson.html#cb245-9"></a><span class="co">##       &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb245-10"><a href="poisson.html#cb245-10"></a><span class="co">##  1        1    13 0.769 0.526</span></span>
<span id="cb245-11"><a href="poisson.html#cb245-11"></a><span class="co">##  2        2    13 0.923 0.577</span></span>
<span id="cb245-12"><a href="poisson.html#cb245-12"></a><span class="co">##  3        3    13 1.08  0.910</span></span>
<span id="cb245-13"><a href="poisson.html#cb245-13"></a><span class="co">##  4        4    13 1.08  1.41 </span></span>
<span id="cb245-14"><a href="poisson.html#cb245-14"></a><span class="co">##  5        5    13 1.46  1.10 </span></span>
<span id="cb245-15"><a href="poisson.html#cb245-15"></a><span class="co">##  6        6    13 1.77  1.53 </span></span>
<span id="cb245-16"><a href="poisson.html#cb245-16"></a><span class="co">##  7        7    13 1.08  0.744</span></span>
<span id="cb245-17"><a href="poisson.html#cb245-17"></a><span class="co">##  8        8    12 1.67  1.88 </span></span>
<span id="cb245-18"><a href="poisson.html#cb245-18"></a><span class="co">##  9        9    12 1.92  2.27 </span></span>
<span id="cb245-19"><a href="poisson.html#cb245-19"></a><span class="co">## 10       10    12 1.67  1.33 </span></span>
<span id="cb245-20"><a href="poisson.html#cb245-20"></a><span class="co">## 11       11    12 2.08  2.63 </span></span>
<span id="cb245-21"><a href="poisson.html#cb245-21"></a><span class="co">## 12       12    12 2.42  2.08</span></span>
<span id="cb245-22"><a href="poisson.html#cb245-22"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(pos.byBark2, <span class="kw">aes</span>(<span class="dt">x=</span>meanY, <span class="dt">y=</span>varY)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb245-23"><a href="poisson.html#cb245-23"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb245-24"><a href="poisson.html#cb245-24"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_abline</span>(<span class="dt">intercept=</span><span class="dv">0</span>, <span class="dt">slope=</span><span class="dv">1</span>, <span class="dt">linetype=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-257-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="pois-resid" class="section level2">
<h2><span class="header-section-number">5.7</span> Residuals and case influence for binomial responses</h2>
<p>We have a few options for residuals for a binomial logistic model. The two most common residuals to consider are Pearson residuals and deviance residuals.</p>
<p><strong>Pearson residuals</strong> are basically response residuals standardized based on the binomial SD:
<span class="math display">\[
pr_i = \dfrac{ y_i - \hat{\mu}(X_i)}{\sqrt{\hat{\mu}(X_i)}}
\]</span>
We can get these residuals by requesting the “pearson” type of residual:</p>
<ul>
<li><code>resid(my.glm, type = "pearson")</code></li>
<li><code>augment(my.glm,  type.residuals = "pearson")</code></li>
</ul>
<p><strong>Deviance residuals</strong> are each case’s contribution to the residual deviance, with a <span class="math inline">\(\pm\)</span> based on whether we over- or under-estimate a case’s response (the <span class="math inline">\(\pm\)</span> is denoted by <span class="math inline">\(sign(y_i - m_i\hat{\pi}(X_i))\)</span>):
<span class="math display">\[
Dres_i =  sign(y_i - \hat{\mu}(X_i)) \sqrt{2 \left[ y_i \ln \left( \dfrac{y_i}{\hat{\mu}(X_i)} \right) - (y_i- \hat{\mu}(X_i))  \right] }
\]</span>
We can get these residuals by requesting the default residual values:</p>
<ul>
<li><code>resid(my.glm)</code></li>
<li><code>augment(my.glm)</code></li>
</ul>
<p>As with model GLMs: Pearson residuals are “easy” to interpret as the number of estimated SD’s a response is from it’s estimated mean. Deviance residuals are good to check if you find significant results in a GOF test. When <span class="math inline">\(\hat{\mu}(X_i)\)</span>’s are large (at least 5), both types of residuals should be similar in value and have a <span class="math inline">\(N(0,1)\)</span> distribution (approximately). This means that most cases (~95%) should have residual values no more extreme than <span class="math inline">\(\pm 2\)</span>. Regardless of size of <span class="math inline">\(m_i\)</span>, we should plot residuals vs. quantitative predictors to assess linearity of the log odds.</p>
<p>Case influence stats of leverage and Cook’s distance can also be used to look for outliers. In a GLM, leverage measures both a cases’s “extremeness” in terms of it’s predictor values <strong>and</strong> it’s extremeness in terms of it’s <strong>weight</strong>. In a <strong>Poisson</strong> model, a case’s weight is <span class="math inline">\(\hat{\mu}(X_i)\)</span>. A case with higher values of <span class="math inline">\(\hat{\mu}(X_i)\)</span> are given more weight, and hence higher leverage, in the fitted model (e.g. in the estiamtes of <span class="math inline">\(\hat{\beta}\)</span>). The value of Cook’s distance also takes into account a cases leverage and a case’s residual value.</p>
<p>You can get Pearson residuals, leverage and Cook’s distance with <code>plot(my.glm, which = 5)</code>. You can also get leverage and Cook’s distance vs. predictor values with <code>ggnostic(my.glm, columnsY = c(".hat",".cooksd"))</code> from the <code>GGally</code> package.</p>
<div id="example-possums-2" class="section level3">
<h3><span class="header-section-number">5.7.1</span> Example: Possums</h3>
<p>The <code>ggnostic</code> plot options gives you deviance residuals against your predictor(s).</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="poisson.html#cb246-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(GGally)</span>
<span id="cb246-2"><a href="poisson.html#cb246-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggnostic</span>(pos.glm, <span class="dt">columnsY =</span> <span class="kw">c</span>(<span class="st">&quot;.resid&quot;</span>))</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-258-1.png" width="672" /></p>
<p>Alternatively, you can plot indivdidually by hand:</p>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="poisson.html#cb247-1"></a><span class="op">&gt;</span><span class="st"> </span>possums.aug &lt;-<span class="st"> </span><span class="kw">augment</span>(pos.glm, <span class="dt">data=</span>possums)</span>
<span id="cb247-2"><a href="poisson.html#cb247-2"></a><span class="op">&gt;</span><span class="st"> </span>plotA &lt;-<span class="st"> </span><span class="kw">ggplot</span>(possums.aug,  <span class="kw">aes</span>(<span class="dt">x=</span>Bark, <span class="dt">y=</span>.resid)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb247-3"><a href="poisson.html#cb247-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_jitter</span>(<span class="dt">height =</span> <span class="fl">.01</span>, <span class="dt">width =</span> <span class="fl">.05</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb247-4"><a href="poisson.html#cb247-4"></a><span class="op">+</span><span class="st">   </span><span class="kw">scale_x_log10</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb247-5"><a href="poisson.html#cb247-5"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>) <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&quot;Deviance residuals&quot;</span>)</span>
<span id="cb247-6"><a href="poisson.html#cb247-6"></a><span class="op">&gt;</span><span class="st"> </span>possums.aug &lt;-<span class="st"> </span><span class="kw">augment</span>(pos.glm, <span class="dt">data=</span>possums, <span class="dt">type.resid =</span> <span class="st">&quot;pearson&quot;</span>)</span>
<span id="cb247-7"><a href="poisson.html#cb247-7"></a><span class="op">&gt;</span><span class="st"> </span>plotB &lt;-<span class="st"> </span><span class="kw">ggplot</span>(possums.aug,  <span class="kw">aes</span>(<span class="dt">x=</span>Bark, <span class="dt">y=</span>.resid)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb247-8"><a href="poisson.html#cb247-8"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_jitter</span>(<span class="dt">height =</span> <span class="fl">.01</span>, <span class="dt">width =</span> <span class="fl">.05</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb247-9"><a href="poisson.html#cb247-9"></a><span class="op">+</span><span class="st">   </span><span class="kw">scale_x_log10</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb247-10"><a href="poisson.html#cb247-10"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>) <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&quot;Pearson residuals&quot;</span>)</span>
<span id="cb247-11"><a href="poisson.html#cb247-11"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">grid.arrange</span>(plotA, plotB, <span class="dt">nrow=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-259-1.png" width="672" /></p>
<p>We can get Cook’s distance and leverage values from <code>plot</code>:</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="poisson.html#cb248-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">plot</span>(pos.glm, <span class="dt">which=</span><span class="dv">4</span>, <span class="dt">id.n =</span> <span class="dv">10</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-260-1.png" width="672" /></p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="poisson.html#cb249-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">plot</span>(pos.glm, <span class="dt">which=</span><span class="dv">5</span>, <span class="dt">id.n =</span> <span class="dv">10</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-260-2.png" width="672" />
or use <code>ggnostic</code>:</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="poisson.html#cb250-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggnostic</span>(pos.glm, <span class="dt">columnsY=</span><span class="kw">c</span>(<span class="st">&quot;.hat&quot;</span>, <span class="st">&quot;.cooksd&quot;</span>))</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-261-1.png" width="672" /></p>
<p>Case 3 stands out with the highest Cook’s distance, likely because it has the second highest leverage (and Bark value) and it is overestimated by a decent amount. Because it has a higher estimated mean response (around 3) then all but one case in the data. Case 1 has highest leverage because it has the highest bark index and highest estimated mean. The two cases with the lowest bark index (101, 147) do not have the highest leverage values because their estimated means are the smallest in the data set. The other higher leverage cases have higher bark values and estimated means. The other higher Cook’s distance cases (75,86,114) have higher predicted values and are poorly predicted with actual counts of either 0 or 5. A quick check shows that case 3 is not all that influential in changing the effect of bark.</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="poisson.html#cb251-1"></a><span class="op">&gt;</span><span class="st"> </span>possums.aug &lt;-<span class="st"> </span><span class="kw">augment</span>(pos.glm, <span class="dt">data=</span>possums, <span class="dt">type.predict=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb251-2"><a href="poisson.html#cb251-2"></a><span class="op">&gt;</span><span class="st"> </span>plotA &lt;-<span class="st"> </span><span class="kw">ggplot</span>(possums.aug, <span class="kw">aes</span>(<span class="dt">x=</span>Bark, <span class="dt">y=</span>.hat, <span class="dt">size=</span>.fitted)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb251-3"><a href="poisson.html#cb251-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&quot;Leverage vs Bark (size=mu)&quot;</span>)</span>
<span id="cb251-4"><a href="poisson.html#cb251-4"></a><span class="op">&gt;</span><span class="st"> </span>plotB &lt;-<span class="st"> </span><span class="kw">ggplot</span>(possums.aug, <span class="kw">aes</span>(<span class="dt">x=</span>Bark, <span class="dt">y=</span>.cooksd, <span class="dt">size=</span>.fitted)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb251-5"><a href="poisson.html#cb251-5"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&quot;Cook&#39;s D vs Bark (size=mu)&quot;</span>)</span>
<span id="cb251-6"><a href="poisson.html#cb251-6"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">grid.arrange</span>(plotA, plotB, <span class="dt">nrow=</span><span class="dv">1</span>) </span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-262-1.png" width="672" /></p>
</div>
</div>
<div id="pois-quasi" class="section level2">
<h2><span class="header-section-number">5.8</span> Quasi-Poisson logistic model</h2>
<p>A quasi-Poisson model is similar in motivation and fit as a quasi-Binomial model from Section <a href="logistic.html#logistic-quasi">4.13</a>. A quasi-Poisson logistic regression model is one model option when your GOF test suggests that your Poisson model assumptions of independent event occurance and constant rate of occurances is not met. The idea behind this model is to estimate the amount of “overdispersion” and use this value to correct your Poisson model SEs.</p>
<p>In a quasi-Poisson model we let <span class="math inline">\(\psi\)</span> measure overdispersion so that the responce variance equals:
<span class="math display">\[
V_{quasi}(Y_i \mid X_i)= \psi \mu(X_i)  =\psi V_{poisson}(Y_i \mid X_i)
\]</span>
If <span class="math inline">\(\psi&gt;1\)</span>, then our responses are more variable than Poisson responses should be and <span class="math inline">\(V_{quasi}(Y_i \mid X_i) &gt; V_{poisson}(Y_i \mid X_i)\)</span>. It is possible to have underdispersion, where <span class="math inline">\(\psi &lt; 1\)</span> in which case <span class="math inline">\(V_{quasi}(Y_i \mid X_i) &lt; V_{poisson}(Y_i \mid X_i)\)</span>.</p>
<p>Steps to fitting a quasi-Poisson model:</p>
<ol style="list-style-type: decimal">
<li><p>Fit the Poisson regression model, then estimate the dispersion parameter by comparing the model residual deviance to <span class="math inline">\(n-(p+1)\)</span> which is it’s expected value if the model was adequate:
<span class="math display">\[
\hat{\psi} = \dfrac{G^2}{n-(p+1)}
\]</span></p></li>
<li><p>Parameter estimates for <span class="math inline">\(\beta\)</span> are from the Poisson model.</p></li>
<li><p>Standard errors for <span class="math inline">\(\hat{\beta}\)</span>’s are expanded (if <span class="math inline">\(\hat{\psi}&gt;1\)</span>) to account for overdispersion by a factor of <span class="math inline">\(\sqrt{\hat{\psi}}\)</span>:
<span class="math display">\[
SE_{quasi}(\hat{\beta}_i) = \sqrt{\hat{\psi}}SE_{binom}(\hat{\beta}_i)
\]</span></p></li>
<li><p>Conduct “z”-inference (Wald tests/CI) using SEs equal to <span class="math inline">\(SE_{quasi}(\hat{\beta}_i)\)</span></p></li>
<li><p>Compare quasi-Poisson models using a F-test stat equal to
<span class="math display">\[
F = \dfrac{G^2/(\textrm{# terms tested})}{\hat{\psi}}
\]</span>
using an F-distribution with degrees of freedom equal to the number of terms tested and <span class="math inline">\(n-(p+1)\)</span>. (The “usual” df for an ANOVA F test.)</p></li>
</ol>
<p>We can get inference results for steps 1-4 above by adding <code>family = quasipoisson</code> to our <code>glm</code> regression fit:</p>
<pre><code>glm(y ~ x1 + x2, family = quasipoisson, data=mydata)</code></pre>
<p>We can get compare quasi-Poisson models using deviance with the command</p>
<pre><code>anova(red.quasi, full.quasi, test = &quot;F&quot;)</code></pre>
<p>Again, the method of estimation dispersion as <span class="math inline">\(G^2/(n-(p+1))\)</span> is <em>one</em> way to estimate this parameter by comparing the actual value of <span class="math inline">\(G^2\)</span> to this expectation tells us our dispersion rate. Another way to compute this value is to look at the <strong>sum of the squared Pearson residuals</strong>, which should also have an expected value of <span class="math inline">\(n-(p+1)\)</span>. The ratio of these two quantities is actually what the <code>glm</code> function uses to compute the dispersion parameter. Often there is no pratical difference between these two ways of estimation the dispersion parameter.</p>

</div>
</div>



</div>
            </section>

          </div>
        </div>
      </div>
<a href="logistic.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="rrstudio.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
