<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Simple Linear Regression | Math 245 Notes</title>
  <meta name="description" content="Course notes and examples for Applied Regression Analysis" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Simple Linear Regression | Math 245 Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes and examples for Applied Regression Analysis" />
  <meta name="github-repo" content="kstclair/Math245notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Simple Linear Regression | Math 245 Notes" />
  
  <meta name="twitter:description" content="Course notes and examples for Applied Regression Analysis" />
  

<meta name="author" content="Katie St. Clair, Carleton College" />


<meta name="date" content="2020-08-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="review.html"/>
<link rel="next" href="mlr.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Math 245 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Getting Started</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#getting-help"><i class="fa fa-check"></i>Getting help</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="review.html"><a href="review.html"><i class="fa fa-check"></i><b>1</b> Review of Statistical Inference</a><ul>
<li class="chapter" data-level="1.1" data-path="review.html"><a href="review.html#sampling-distribution"><i class="fa fa-check"></i><b>1.1</b> Sampling Distribution</a></li>
<li class="chapter" data-level="1.2" data-path="review.html"><a href="review.html#central-limit-theorem"><i class="fa fa-check"></i><b>1.2</b> Central Limit Theorem</a><ul>
<li class="chapter" data-level="1.2.1" data-path="review.html"><a href="review.html#standard-error"><i class="fa fa-check"></i><b>1.2.1</b> Standard error</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="review.html"><a href="review.html#hypothesis-testing"><i class="fa fa-check"></i><b>1.3</b> Hypothesis testing</a></li>
<li class="chapter" data-level="1.4" data-path="review.html"><a href="review.html#confidence-intervals"><i class="fa fa-check"></i><b>1.4</b> Confidence Intervals</a></li>
<li class="chapter" data-level="1.5" data-path="review.html"><a href="review.html#review_activity"><i class="fa fa-check"></i><b>1.5</b> Review activity (day 2)</a><ul>
<li class="chapter" data-level="1.5.1" data-path="review.html"><a href="review.html#general-questions"><i class="fa fa-check"></i><b>1.5.1</b> General questions</a></li>
<li class="chapter" data-level="1.5.2" data-path="review.html"><a href="review.html#comparing-two-means"><i class="fa fa-check"></i><b>1.5.2</b> Comparing two means</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="slr.html"><a href="slr.html"><i class="fa fa-check"></i><b>2</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="2.1" data-path="slr.html"><a href="slr.html#the-variables"><i class="fa fa-check"></i><b>2.1</b> The variables</a></li>
<li class="chapter" data-level="2.2" data-path="slr.html"><a href="slr.html#slr-model"><i class="fa fa-check"></i><b>2.2</b> The model form</a><ul>
<li class="chapter" data-level="2.2.1" data-path="slr.html"><a href="slr.html#interpretation"><i class="fa fa-check"></i><b>2.2.1</b> Interpretation</a></li>
<li class="chapter" data-level="2.2.2" data-path="slr.html"><a href="slr.html#slr-model-ex"><i class="fa fa-check"></i><b>2.2.2</b> Example: Woodpecker nests</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="slr.html"><a href="slr.html#slr-est"><i class="fa fa-check"></i><b>2.3</b> Theory: Estimation</a><ul>
<li class="chapter" data-level="2.3.1" data-path="slr.html"><a href="slr.html#sampling-distributions-for-slr-estimates"><i class="fa fa-check"></i><b>2.3.1</b> Sampling Distributions for SLR estimates</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="slr.html"><a href="slr.html#slr-sim"><i class="fa fa-check"></i><b>2.4</b> SLR model simulation</a><ul>
<li class="chapter" data-level="2.4.1" data-path="slr.html"><a href="slr.html#simulation-function"><i class="fa fa-check"></i><b>2.4.1</b> Simulation function</a></li>
<li class="chapter" data-level="2.4.2" data-path="slr.html"><a href="slr.html#run-the-function-once"><i class="fa fa-check"></i><b>2.4.2</b> Run the function once</a></li>
<li class="chapter" data-level="2.4.3" data-path="slr.html"><a href="slr.html#simulated-sampling-distribution-for-hatbeta_1"><i class="fa fa-check"></i><b>2.4.3</b> Simulated sampling distribution for <span class="math inline">\(\hat{\beta}_1\)</span></a></li>
<li class="chapter" data-level="2.4.4" data-path="slr.html"><a href="slr.html#slr-simcor"><i class="fa fa-check"></i><b>2.4.4</b> Are slope and intercept estimates correlated?</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="slr.html"><a href="slr.html#slr-inf"><i class="fa fa-check"></i><b>2.5</b> Inference for mean parameters</a><ul>
<li class="chapter" data-level="2.5.1" data-path="review.html"><a href="review.html#confidence-intervals"><i class="fa fa-check"></i><b>2.5.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="2.5.2" data-path="slr.html"><a href="slr.html#hypothesis-tests"><i class="fa fa-check"></i><b>2.5.2</b> Hypothesis tests</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="slr.html"><a href="slr.html#slr-inf2"><i class="fa fa-check"></i><b>2.6</b> Inference for average or predicted response</a><ul>
<li class="chapter" data-level="2.6.1" data-path="slr.html"><a href="slr.html#confidence-intervals-for-mu_y-mid-x"><i class="fa fa-check"></i><b>2.6.1</b> Confidence intervals for <span class="math inline">\(\mu_{y \mid x}\)</span></a></li>
<li class="chapter" data-level="2.6.2" data-path="slr.html"><a href="slr.html#prediction-intervals-for-new-cases"><i class="fa fa-check"></i><b>2.6.2</b> Prediction intervals for new cases</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="slr.html"><a href="slr.html#slr-example1"><i class="fa fa-check"></i><b>2.7</b> Example: SLR model (day 3)</a><ul>
<li class="chapter" data-level="2.7.1" data-path="slr.html"><a href="slr.html#load-data"><i class="fa fa-check"></i><b>2.7.1</b> Load data</a></li>
<li class="chapter" data-level="2.7.2" data-path="slr.html"><a href="slr.html#eda"><i class="fa fa-check"></i><b>2.7.2</b> EDA</a></li>
<li class="chapter" data-level="2.7.3" data-path="slr.html"><a href="slr.html#the-least-squares-line-the-estimated-slr-model"><i class="fa fa-check"></i><b>2.7.3</b> The least squares line (the estimated SLR model):</a></li>
<li class="chapter" data-level="2.7.4" data-path="slr.html"><a href="slr.html#inference-for-coefficients"><i class="fa fa-check"></i><b>2.7.4</b> Inference for coefficients</a></li>
<li class="chapter" data-level="2.7.5" data-path="slr.html"><a href="slr.html#additional-lm-information"><i class="fa fa-check"></i><b>2.7.5</b> Additional <code>lm</code> information</a></li>
<li class="chapter" data-level="2.7.6" data-path="slr.html"><a href="slr.html#slr-broom"><i class="fa fa-check"></i><b>2.7.6</b> <code>broom</code> package: Tidy <code>lm</code> output</a></li>
<li class="chapter" data-level="2.7.7" data-path="slr.html"><a href="slr.html#inference-for-the-mean-and-predicted-response"><i class="fa fa-check"></i><b>2.7.7</b> Inference for the mean and predicted response</a></li>
<li class="chapter" data-level="2.7.8" data-path="slr.html"><a href="slr.html#adding-confidence-bands-to-a-scatterplot"><i class="fa fa-check"></i><b>2.7.8</b> Adding confidence bands to a scatterplot</a></li>
<li class="chapter" data-level="2.7.9" data-path="slr.html"><a href="slr.html#tools-for-displaying-your-model"><i class="fa fa-check"></i><b>2.7.9</b> Tools for displaying your model</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="slr.html"><a href="slr.html#slr-assump"><i class="fa fa-check"></i><b>2.8</b> Checking model assumptions and fit</a><ul>
<li class="chapter" data-level="2.8.1" data-path="slr.html"><a href="slr.html#residuals"><i class="fa fa-check"></i><b>2.8.1</b> Residuals</a></li>
<li class="chapter" data-level="2.8.2" data-path="slr.html"><a href="slr.html#residual-plot-linearity-and-constant-variance"><i class="fa fa-check"></i><b>2.8.2</b> Residual plot: linearity and constant variance</a></li>
<li class="chapter" data-level="2.8.3" data-path="slr.html"><a href="slr.html#slr-normality"><i class="fa fa-check"></i><b>2.8.3</b> Residual normal QQ plot</a></li>
<li class="chapter" data-level="2.8.4" data-path="slr.html"><a href="slr.html#slr-indep"><i class="fa fa-check"></i><b>2.8.4</b> Independence</a></li>
<li class="chapter" data-level="2.8.5" data-path="slr.html"><a href="slr.html#slr-robust"><i class="fa fa-check"></i><b>2.8.5</b> Robustness against violations</a></li>
<li class="chapter" data-level="2.8.6" data-path="slr.html"><a href="slr.html#fixes-to-violations"><i class="fa fa-check"></i><b>2.8.6</b> “Fixes” to violations</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="slr.html"><a href="slr.html#slr-example2"><i class="fa fa-check"></i><b>2.9</b> Example: SLR assumptions (day 4/5)</a><ul>
<li class="chapter" data-level="2.9.1" data-path="slr.html"><a href="slr.html#drug-offender-sentences"><i class="fa fa-check"></i><b>2.9.1</b> Drug offender sentences</a></li>
<li class="chapter" data-level="2.9.2" data-path="slr.html"><a href="slr.html#case-study-15.2---global-warming"><i class="fa fa-check"></i><b>2.9.2</b> Case study 15.2 - Global Warming</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="slr.html"><a href="slr.html#slr-trans"><i class="fa fa-check"></i><b>2.10</b> Transformations</a><ul>
<li class="chapter" data-level="2.10.1" data-path="slr.html"><a href="slr.html#transformation-choices"><i class="fa fa-check"></i><b>2.10.1</b> Transformation choices</a></li>
<li class="chapter" data-level="2.10.2" data-path="slr.html"><a href="slr.html#transformations-in-r"><i class="fa fa-check"></i><b>2.10.2</b> Transformations in R</a></li>
<li class="chapter" data-level="2.10.3" data-path="slr.html"><a href="slr.html#interpretation-1"><i class="fa fa-check"></i><b>2.10.3</b> Interpretation</a></li>
<li class="chapter" data-level="2.10.4" data-path="slr.html"><a href="slr.html#slr-logs"><i class="fa fa-check"></i><b>2.10.4</b> Review: Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="slr.html"><a href="slr.html#examples-transformations-day-6"><i class="fa fa-check"></i><b>2.11</b> Examples: Transformations (day 6)</a><ul>
<li class="chapter" data-level="2.11.1" data-path="slr.html"><a href="slr.html#cars-2004"><i class="fa fa-check"></i><b>2.11.1</b> Cars 2004</a></li>
<li class="chapter" data-level="2.11.2" data-path="slr.html"><a href="slr.html#residential-energy-survey-recs"><i class="fa fa-check"></i><b>2.11.2</b> 2005 Residential Energy Survey (RECS)</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="slr.html"><a href="slr.html#r2-and-anova-for-slr"><i class="fa fa-check"></i><b>2.12</b> <span class="math inline">\(R^2\)</span> and ANOVA for SLR</a><ul>
<li class="chapter" data-level="2.12.1" data-path="slr.html"><a href="slr.html#example-r2"><i class="fa fa-check"></i><b>2.12.1</b> Example: <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="2.12.2" data-path="slr.html"><a href="slr.html#slr-anova"><i class="fa fa-check"></i><b>2.12.2</b> ANOVA for SLR</a></li>
<li class="chapter" data-level="2.12.3" data-path="slr.html"><a href="slr.html#example-anova"><i class="fa fa-check"></i><b>2.12.3</b> Example: ANOVA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mlr.html"><a href="mlr.html"><i class="fa fa-check"></i><b>3</b> Multiple Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="slr.html"><a href="slr.html#the-variables"><i class="fa fa-check"></i><b>3.1</b> The variables</a></li>
<li class="chapter" data-level="3.2" data-path="mlr.html"><a href="mlr.html#mlr-model"><i class="fa fa-check"></i><b>3.2</b> The model form</a><ul>
<li class="chapter" data-level="3.2.1" data-path="mlr.html"><a href="mlr.html#mlr-interpretation"><i class="fa fa-check"></i><b>3.2.1</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="mlr.html"><a href="mlr.html#mlr-example1"><i class="fa fa-check"></i><b>3.3</b> Example: MLR fit and visuals</a><ul>
<li class="chapter" data-level="3.3.1" data-path="mlr.html"><a href="mlr.html#lm-fit"><i class="fa fa-check"></i><b>3.3.1</b> <code>lm</code> fit</a></li>
<li class="chapter" data-level="3.3.2" data-path="mlr.html"><a href="mlr.html#graphics-for-mlr"><i class="fa fa-check"></i><b>3.3.2</b> Graphics for MLR</a></li>
<li class="chapter" data-level="3.3.3" data-path="mlr.html"><a href="mlr.html#mlr-resid1"><i class="fa fa-check"></i><b>3.3.3</b> Residual plots for MLR</a></li>
<li class="chapter" data-level="3.3.4" data-path="mlr.html"><a href="mlr.html#eda-for-interactions"><i class="fa fa-check"></i><b>3.3.4</b> EDA for interactions</a></li>
<li class="chapter" data-level="3.3.5" data-path="mlr.html"><a href="mlr.html#quadratic-models-corn-yields-exercise-9.15"><i class="fa fa-check"></i><b>3.3.5</b> Quadratic models: Corn yields (exercise 9.15)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="mlr.html"><a href="mlr.html#mlr-cat"><i class="fa fa-check"></i><b>3.4</b> Categorical Predictors</a><ul>
<li class="chapter" data-level="3.4.1" data-path="mlr.html"><a href="mlr.html#interpretation-adding-a-categorical"><i class="fa fa-check"></i><b>3.4.1</b> Interpretation: adding a categorical</a></li>
<li class="chapter" data-level="3.4.2" data-path="mlr.html"><a href="mlr.html#interpretation-adding-a-categorical-interaction"><i class="fa fa-check"></i><b>3.4.2</b> Interpretation: adding a categorical interaction</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="mlr.html"><a href="mlr.html#mlr-inf"><i class="fa fa-check"></i><b>3.5</b> Inference for MLR</a><ul>
<li class="chapter" data-level="3.5.1" data-path="mlr.html"><a href="mlr.html#mlr-inf2"><i class="fa fa-check"></i><b>3.5.1</b> Inference for a linear combination of <span class="math inline">\(\beta\)</span>’s</a></li>
<li class="chapter" data-level="3.5.2" data-path="mlr.html"><a href="mlr.html#mlr-agstrat2"><i class="fa fa-check"></i><b>3.5.2</b> Example: Agstrat</a></li>
<li class="chapter" data-level="3.5.3" data-path="mlr.html"><a href="mlr.html#mlr-sleep2"><i class="fa fa-check"></i><b>3.5.3</b> Example: Sleep</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="mlr.html"><a href="mlr.html#mlr-anova"><i class="fa fa-check"></i><b>3.6</b> ANOVA for MLR</a><ul>
<li class="chapter" data-level="3.6.1" data-path="mlr.html"><a href="mlr.html#mean-squares"><i class="fa fa-check"></i><b>3.6.1</b> Mean Squares</a></li>
<li class="chapter" data-level="3.6.2" data-path="mlr.html"><a href="mlr.html#r2-and-adjusted-r2"><i class="fa fa-check"></i><b>3.6.2</b> <span class="math inline">\(R^2\)</span> and adjusted <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="3.6.3" data-path="mlr.html"><a href="mlr.html#anova-f-tests"><i class="fa fa-check"></i><b>3.6.3</b> ANOVA F-tests</a></li>
<li class="chapter" data-level="3.6.4" data-path="mlr.html"><a href="mlr.html#mlr-sleep3"><i class="fa fa-check"></i><b>3.6.4</b> Example: Sleep</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="mlr.html"><a href="mlr.html#model-checking"><i class="fa fa-check"></i><b>3.7</b> Model Checking</a><ul>
<li class="chapter" data-level="3.7.1" data-path="mlr.html"><a href="mlr.html#residual-plots"><i class="fa fa-check"></i><b>3.7.1</b> Residual plots</a></li>
<li class="chapter" data-level="3.7.2" data-path="mlr.html"><a href="mlr.html#outliers"><i class="fa fa-check"></i><b>3.7.2</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="mlr.html"><a href="mlr.html#mlr-visualizing-effects"><i class="fa fa-check"></i><b>3.8</b> MLR: Visualizing effects</a><ul>
<li class="chapter" data-level="3.8.1" data-path="mlr.html"><a href="mlr.html#partial-residual-plots"><i class="fa fa-check"></i><b>3.8.1</b> Partial residual plots</a></li>
<li class="chapter" data-level="3.8.2" data-path="mlr.html"><a href="mlr.html#example-sleep-1"><i class="fa fa-check"></i><b>3.8.2</b> Example: Sleep</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="mlr.html"><a href="mlr.html#collinearity"><i class="fa fa-check"></i><b>3.9</b> Collinearity</a><ul>
<li class="chapter" data-level="3.9.1" data-path="mlr.html"><a href="mlr.html#example-sleep-2"><i class="fa fa-check"></i><b>3.9.1</b> Example: Sleep</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>4</b> Logistic Regression</a><ul>
<li class="chapter" data-level="4.1" data-path="slr.html"><a href="slr.html#the-variables"><i class="fa fa-check"></i><b>4.1</b> The variables</a><ul>
<li class="chapter" data-level="4.1.1" data-path="logistic.html"><a href="logistic.html#logistic-donner1"><i class="fa fa-check"></i><b>4.1.1</b> Example: Donner party EDA</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="logistic.html"><a href="logistic.html#logistic-bernoulli"><i class="fa fa-check"></i><b>4.2</b> The Bernoulli distribution</a></li>
<li class="chapter" data-level="4.3" data-path="logistic.html"><a href="logistic.html#logistic-model"><i class="fa fa-check"></i><b>4.3</b> The logistic model form</a><ul>
<li class="chapter" data-level="4.3.1" data-path="logistic.html"><a href="logistic.html#logistic-int"><i class="fa fa-check"></i><b>4.3.1</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="logistic.html"><a href="logistic.html#logistic-est"><i class="fa fa-check"></i><b>4.4</b> Inference and estimation</a><ul>
<li class="chapter" data-level="4.4.1" data-path="logistic.html"><a href="logistic.html#confidence-intervals-for-pmbbeta_i"><i class="fa fa-check"></i><b>4.4.1</b> Confidence intervals for <span class="math inline">\(\pmb{\beta_i}\)</span></a></li>
<li class="chapter" data-level="4.4.2" data-path="logistic.html"><a href="logistic.html#hypothesis-tests-for-pmbbeta_i"><i class="fa fa-check"></i><b>4.4.2</b> Hypothesis tests for <span class="math inline">\(\pmb{\beta_i}\)</span></a></li>
<li class="chapter" data-level="4.4.3" data-path="logistic.html"><a href="logistic.html#r-glm"><i class="fa fa-check"></i><b>4.4.3</b> R <code>glm</code></a></li>
<li class="chapter" data-level="4.4.4" data-path="logistic.html"><a href="logistic.html#logistic-donner2"><i class="fa fa-check"></i><b>4.4.4</b> Example: Donner party model</a></li>
<li class="chapter" data-level="4.4.5" data-path="logistic.html"><a href="logistic.html#logistic-donner3"><i class="fa fa-check"></i><b>4.4.5</b> Example: Donner party, adding sex</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="logistic.html"><a href="logistic.html#logistic-dev"><i class="fa fa-check"></i><b>4.5</b> Deviance</a><ul>
<li class="chapter" data-level="4.5.1" data-path="logistic.html"><a href="logistic.html#drop-in-deviance-test"><i class="fa fa-check"></i><b>4.5.1</b> Drop in Deviance test</a></li>
<li class="chapter" data-level="4.5.2" data-path="logistic.html"><a href="logistic.html#example-nes"><i class="fa fa-check"></i><b>4.5.2</b> Example: NES</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="logistic.html"><a href="logistic.html#logistic-assump"><i class="fa fa-check"></i><b>4.6</b> Checking Assumptions</a><ul>
<li class="chapter" data-level="4.6.1" data-path="logistic.html"><a href="logistic.html#example-bwca1"><i class="fa fa-check"></i><b>4.6.1</b> Example: Boundary Waters Canoe Area (BWCA) blowdown</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="logistic.html"><a href="logistic.html#logistic-resid"><i class="fa fa-check"></i><b>4.7</b> Residuals and Case influence</a><ul>
<li class="chapter" data-level="4.7.1" data-path="logistic.html"><a href="logistic.html#example-bwca2"><i class="fa fa-check"></i><b>4.7.1</b> Example: Boundary Waters Canoe Area (BWCA) blowdown</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="logistic.html"><a href="logistic.html#binomial-responses"><i class="fa fa-check"></i><b>4.8</b> Binomial responses</a><ul>
<li class="chapter" data-level="4.8.1" data-path="logistic.html"><a href="logistic.html#connection-to-binary-responses"><i class="fa fa-check"></i><b>4.8.1</b> Connection to binary responses</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="logistic.html"><a href="logistic.html#inference-for-binomial-response-models"><i class="fa fa-check"></i><b>4.9</b> Inference for Binomial response models</a><ul>
<li class="chapter" data-level="4.9.1" data-path="logistic.html"><a href="logistic.html#example-krunnit-islands-archipelago-sleuth-case-study-21.1"><i class="fa fa-check"></i><b>4.9.1</b> Example: Krunnit Islands archipelago (Sleuth Case Study 21.1)</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="logistic.html"><a href="logistic.html#logistic-binomDev"><i class="fa fa-check"></i><b>4.10</b> Deviance for Binomial responses</a><ul>
<li class="chapter" data-level="4.10.1" data-path="logistic.html"><a href="logistic.html#logistic-gof"><i class="fa fa-check"></i><b>4.10.1</b> Goodness-of-fit test</a></li>
<li class="chapter" data-level="4.10.2" data-path="logistic.html"><a href="logistic.html#example-krunnit-islands-archipelago-sleuth-case-study-21.1-1"><i class="fa fa-check"></i><b>4.10.2</b> Example: Krunnit Islands archipelago (Sleuth Case Study 21.1)</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="logistic.html"><a href="logistic.html#logistic-assump"><i class="fa fa-check"></i><b>4.11</b> Checking Assumptions</a><ul>
<li class="chapter" data-level="4.11.1" data-path="logistic.html"><a href="logistic.html#example-krunnit-islands-archipelago-sleuth-case-study-21.1-2"><i class="fa fa-check"></i><b>4.11.1</b> Example: Krunnit Islands archipelago (Sleuth Case Study 21.1)</a></li>
</ul></li>
<li class="chapter" data-level="4.12" data-path="logistic.html"><a href="logistic.html#logistic-binomResid"><i class="fa fa-check"></i><b>4.12</b> Residuals and case influence for binomial responses</a><ul>
<li class="chapter" data-level="4.12.1" data-path="logistic.html"><a href="logistic.html#example-krunnit-islands-archipelago-sleuth-case-study-21.1-3"><i class="fa fa-check"></i><b>4.12.1</b> Example: Krunnit Islands archipelago (Sleuth Case Study 21.1)</a></li>
</ul></li>
<li class="chapter" data-level="4.13" data-path="logistic.html"><a href="logistic.html#logistic-quasi"><i class="fa fa-check"></i><b>4.13</b> Quasi-binomial logistic model</a><ul>
<li class="chapter" data-level="4.13.1" data-path="logistic.html"><a href="logistic.html#example-moth-predation-case-study-21.2"><i class="fa fa-check"></i><b>4.13.1</b> Example: Moth predation (Case Study 21.2)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="poisson.html"><a href="poisson.html"><i class="fa fa-check"></i><b>5</b> Poisson Regression</a><ul>
<li class="chapter" data-level="5.1" data-path="poisson.html"><a href="poisson.html#pois-dist"><i class="fa fa-check"></i><b>5.1</b> The Poisson distribution</a></li>
<li class="chapter" data-level="5.2" data-path="logistic.html"><a href="logistic.html#logistic-model"><i class="fa fa-check"></i><b>5.2</b> The Poisson model form</a><ul>
<li class="chapter" data-level="5.2.1" data-path="slr.html"><a href="slr.html#interpretation"><i class="fa fa-check"></i><b>5.2.1</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="slr.html"><a href="slr.html#eda"><i class="fa fa-check"></i><b>5.3</b> EDA</a><ul>
<li class="chapter" data-level="5.3.1" data-path="poisson.html"><a href="poisson.html#example-possums"><i class="fa fa-check"></i><b>5.3.1</b> Example: Possums</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="poisson.html"><a href="poisson.html#poisson-est"><i class="fa fa-check"></i><b>5.4</b> Inference and estimation</a><ul>
<li class="chapter" data-level="5.4.1" data-path="logistic.html"><a href="logistic.html#confidence-intervals-for-pmbbeta_i"><i class="fa fa-check"></i><b>5.4.1</b> Confidence intervals for <span class="math inline">\(\pmb{\beta_i}\)</span></a></li>
<li class="chapter" data-level="5.4.2" data-path="logistic.html"><a href="logistic.html#hypothesis-tests-for-pmbbeta_i"><i class="fa fa-check"></i><b>5.4.2</b> Hypothesis tests for <span class="math inline">\(\pmb{\beta_i}\)</span></a></li>
<li class="chapter" data-level="5.4.3" data-path="logistic.html"><a href="logistic.html#r-glm"><i class="fa fa-check"></i><b>5.4.3</b> R <code>glm</code></a></li>
<li class="chapter" data-level="5.4.4" data-path="poisson.html"><a href="poisson.html#pois-ex2"><i class="fa fa-check"></i><b>5.4.4</b> Example: Possums</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="poisson.html"><a href="poisson.html#pois-dev"><i class="fa fa-check"></i><b>5.5</b> Deviance for Binomial responses</a><ul>
<li class="chapter" data-level="5.5.1" data-path="poisson.html"><a href="poisson.html#pois-did"><i class="fa fa-check"></i><b>5.5.1</b> Drop-in-deviance test</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="poisson.html"><a href="poisson.html#pois-assump"><i class="fa fa-check"></i><b>5.6</b> Checking Assumptions</a><ul>
<li class="chapter" data-level="5.6.1" data-path="poisson.html"><a href="poisson.html#pois-gof"><i class="fa fa-check"></i><b>5.6.1</b> Goodness-of-fit test</a></li>
<li class="chapter" data-level="5.6.2" data-path="poisson.html"><a href="poisson.html#gof-alternative"><i class="fa fa-check"></i><b>5.6.2</b> GOF alternative</a></li>
<li class="chapter" data-level="5.6.3" data-path="poisson.html"><a href="poisson.html#example-possums-1"><i class="fa fa-check"></i><b>5.6.3</b> Example: Possums</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="poisson.html"><a href="poisson.html#pois-resid"><i class="fa fa-check"></i><b>5.7</b> Residuals and case influence for binomial responses</a><ul>
<li class="chapter" data-level="5.7.1" data-path="poisson.html"><a href="poisson.html#example-possums-2"><i class="fa fa-check"></i><b>5.7.1</b> Example: Possums</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="poisson.html"><a href="poisson.html#pois-quasi"><i class="fa fa-check"></i><b>5.8</b> Quasi-Poisson logistic model</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="rrstudio.html"><a href="rrstudio.html"><i class="fa fa-check"></i><b>A</b> R and Rstudio</a><ul>
<li class="chapter" data-level="A.1" data-path="rrstudio.html"><a href="rrstudio.html#running-rstudio"><i class="fa fa-check"></i><b>A.1</b> Running Rstudio</a></li>
<li class="chapter" data-level="A.2" data-path="rrstudio.html"><a href="rrstudio.html#r"><i class="fa fa-check"></i><b>A.2</b> Installing R</a></li>
<li class="chapter" data-level="A.3" data-path="rrstudio.html"><a href="rrstudio.html#rstudio"><i class="fa fa-check"></i><b>A.3</b> Installing Rstudio</a></li>
<li class="chapter" data-level="A.4" data-path="rrstudio.html"><a href="rrstudio.html#packages"><i class="fa fa-check"></i><b>A.4</b> Installing R packages</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="renviron.html"><a href="renviron.html"><i class="fa fa-check"></i><b>B</b> The R enviroment</a><ul>
<li class="chapter" data-level="B.1" data-path="renviron.html"><a href="renviron.html#workspace"><i class="fa fa-check"></i><b>B.1</b> Workspace</a></li>
<li class="chapter" data-level="B.2" data-path="renviron.html"><a href="renviron.html#working-directory"><i class="fa fa-check"></i><b>B.2</b> Working directory</a></li>
<li class="chapter" data-level="B.3" data-path="renviron.html"><a href="renviron.html#project"><i class="fa fa-check"></i><b>B.3</b> Rstudio projects</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="rreview.html"><a href="rreview.html"><i class="fa fa-check"></i><b>C</b> R for basic data analysis</a><ul>
<li class="chapter" data-level="C.1" data-path="rreview.html"><a href="rreview.html#basics"><i class="fa fa-check"></i><b>C.1</b> Basics</a><ul>
<li class="chapter" data-level="C.1.1" data-path="rreview.html"><a href="rreview.html#quick-tips"><i class="fa fa-check"></i><b>C.1.1</b> Quick Tips</a></li>
<li class="chapter" data-level="C.1.2" data-path="rreview.html"><a href="rreview.html#objects"><i class="fa fa-check"></i><b>C.1.2</b> Objects</a></li>
<li class="chapter" data-level="C.1.3" data-path="rreview.html"><a href="rreview.html#vectors"><i class="fa fa-check"></i><b>C.1.3</b> Vectors</a></li>
<li class="chapter" data-level="C.1.4" data-path="rreview.html"><a href="rreview.html#arithmetic"><i class="fa fa-check"></i><b>C.1.4</b> Arithmetic</a></li>
<li class="chapter" data-level="C.1.5" data-path="rreview.html"><a href="rreview.html#subsetting"><i class="fa fa-check"></i><b>C.1.5</b> Subsetting</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="rreview.html"><a href="rreview.html#data"><i class="fa fa-check"></i><b>C.2</b> Data</a><ul>
<li class="chapter" data-level="C.2.1" data-path="rreview.html"><a href="rreview.html#reading-data-into-r"><i class="fa fa-check"></i><b>C.2.1</b> Reading Data into R</a></li>
<li class="chapter" data-level="C.2.2" data-path="rreview.html"><a href="rreview.html#investigating-a-data-frame"><i class="fa fa-check"></i><b>C.2.2</b> Investigating a Data Frame</a></li>
<li class="chapter" data-level="C.2.3" data-path="rreview.html"><a href="rreview.html#access"><i class="fa fa-check"></i><b>C.2.3</b> Accessing Data</a></li>
<li class="chapter" data-level="C.2.4" data-path="rreview.html"><a href="rreview.html#Rreview-subset"><i class="fa fa-check"></i><b>C.2.4</b> Subsetting a Data Frame</a></li>
<li class="chapter" data-level="C.2.5" data-path="rreview.html"><a href="rreview.html#creating-a-data-frame"><i class="fa fa-check"></i><b>C.2.5</b> Creating a data frame</a></li>
<li class="chapter" data-level="C.2.6" data-path="rreview.html"><a href="rreview.html#adding-a-new-column-to-a-data-frame"><i class="fa fa-check"></i><b>C.2.6</b> Adding a new column to a data frame</a></li>
<li class="chapter" data-level="C.2.7" data-path="rreview.html"><a href="rreview.html#missing-data"><i class="fa fa-check"></i><b>C.2.7</b> Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="C.3" data-path="slr.html"><a href="slr.html#eda"><i class="fa fa-check"></i><b>C.3</b> EDA</a><ul>
<li class="chapter" data-level="C.3.1" data-path="rreview.html"><a href="rreview.html#categorical"><i class="fa fa-check"></i><b>C.3.1</b> Categorical:</a></li>
<li class="chapter" data-level="C.3.2" data-path="rreview.html"><a href="rreview.html#quantitative"><i class="fa fa-check"></i><b>C.3.2</b> Quantitative:</a></li>
<li class="chapter" data-level="C.3.3" data-path="rreview.html"><a href="rreview.html#Rreview-stats"><i class="fa fa-check"></i><b>C.3.3</b> Quantitative grouped by a categorical</a></li>
<li class="chapter" data-level="C.3.4" data-path="rreview.html"><a href="rreview.html#Rreview-graphs"><i class="fa fa-check"></i><b>C.3.4</b> Graphs</a></li>
<li class="chapter" data-level="C.3.5" data-path="rreview.html"><a href="rreview.html#reporting-results"><i class="fa fa-check"></i><b>C.3.5</b> Reporting Results</a></li>
</ul></li>
<li class="chapter" data-level="C.4" data-path="rreview.html"><a href="rreview.html#factors"><i class="fa fa-check"></i><b>C.4</b> Factor variables</a><ul>
<li class="chapter" data-level="C.4.1" data-path="rreview.html"><a href="rreview.html#renaming-factor-levels"><i class="fa fa-check"></i><b>C.4.1</b> Renaming factor levels</a></li>
<li class="chapter" data-level="C.4.2" data-path="rreview.html"><a href="rreview.html#recode-a-categorical-variable-with-many-levels"><i class="fa fa-check"></i><b>C.4.2</b> Recode a categorical variable with many levels</a></li>
<li class="chapter" data-level="C.4.3" data-path="rreview.html"><a href="rreview.html#converting-some-factor-levels-to-nas"><i class="fa fa-check"></i><b>C.4.3</b> Converting some factor levels to <code>NA</code>s</a></li>
<li class="chapter" data-level="C.4.4" data-path="rreview.html"><a href="rreview.html#changing-the-order-of-levels"><i class="fa fa-check"></i><b>C.4.4</b> Changing the order of levels</a></li>
<li class="chapter" data-level="C.4.5" data-path="rreview.html"><a href="rreview.html#recode-a-numerically-coded-categorical-variable"><i class="fa fa-check"></i><b>C.4.5</b> Recode a numerically coded categorical variable</a></li>
<li class="chapter" data-level="C.4.6" data-path="rreview.html"><a href="rreview.html#recode-a-factor-into-a-numeric"><i class="fa fa-check"></i><b>C.4.6</b> Recode a factor into a numeric</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="markdown.html"><a href="markdown.html"><i class="fa fa-check"></i><b>D</b> R Markdown</a><ul>
<li class="chapter" data-level="D.1" data-path="markdown.html"><a href="markdown.html#how-to-write-an-r-markdown-document"><i class="fa fa-check"></i><b>D.1</b> How to write an R Markdown document</a></li>
<li class="chapter" data-level="D.2" data-path="markdown.html"><a href="markdown.html#changing-r-markdown-chunk-evaluation-behavior"><i class="fa fa-check"></i><b>D.2</b> Changing R Markdown chunk evaluation behavior</a></li>
<li class="chapter" data-level="D.3" data-path="markdown.html"><a href="markdown.html#creating-a-new-r-markdown-document"><i class="fa fa-check"></i><b>D.3</b> Creating a new R Markdown document</a></li>
<li class="chapter" data-level="D.4" data-path="markdown.html"><a href="markdown.html#markdown-graphs"><i class="fa fa-check"></i><b>D.4</b> Extra: Graph formatting</a><ul>
<li class="chapter" data-level="D.4.1" data-path="markdown.html"><a href="markdown.html#adding-figure-numbers-and-captions"><i class="fa fa-check"></i><b>D.4.1</b> Adding figure numbers and captions</a></li>
<li class="chapter" data-level="D.4.2" data-path="markdown.html"><a href="markdown.html#resizing-graphs-in-markdown"><i class="fa fa-check"></i><b>D.4.2</b> Resizing graphs in Markdown</a></li>
<li class="chapter" data-level="D.4.3" data-path="markdown.html"><a href="markdown.html#changing-graph-formatting-in-r"><i class="fa fa-check"></i><b>D.4.3</b> Changing graph formatting in R</a></li>
<li class="chapter" data-level="D.4.4" data-path="markdown.html"><a href="markdown.html#hiding-r-commands"><i class="fa fa-check"></i><b>D.4.4</b> Hiding R commands</a></li>
<li class="chapter" data-level="D.4.5" data-path="markdown.html"><a href="markdown.html#global-changes-in-graph-format"><i class="fa fa-check"></i><b>D.4.5</b> Global changes in graph format</a></li>
<li class="chapter" data-level="D.4.6" data-path="markdown.html"><a href="markdown.html#comments"><i class="fa fa-check"></i><b>D.4.6</b> Comments:</a></li>
</ul></li>
<li class="chapter" data-level="D.5" data-path="markdown.html"><a href="markdown.html#markdown-tables"><i class="fa fa-check"></i><b>D.5</b> Extra: Table formatting</a><ul>
<li class="chapter" data-level="D.5.1" data-path="markdown.html"><a href="markdown.html#hiding-r-commands-and-r-output"><i class="fa fa-check"></i><b>D.5.1</b> Hiding R commands and R output</a></li>
<li class="chapter" data-level="D.5.2" data-path="markdown.html"><a href="markdown.html#markdown-tables-1"><i class="fa fa-check"></i><b>D.5.2</b> Markdown tables</a></li>
<li class="chapter" data-level="D.5.3" data-path="markdown.html"><a href="markdown.html#markdown-tables-via-kable"><i class="fa fa-check"></i><b>D.5.3</b> Markdown tables via <code>kable</code></a></li>
<li class="chapter" data-level="D.5.4" data-path="markdown.html"><a href="markdown.html#the-pander-package"><i class="fa fa-check"></i><b>D.5.4</b> The <code>pander</code> package</a></li>
<li class="chapter" data-level="D.5.5" data-path="markdown.html"><a href="markdown.html#the-stargazer-package"><i class="fa fa-check"></i><b>D.5.5</b> The <code>stargazer</code> package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="E" data-path="mathreview.html"><a href="mathreview.html"><i class="fa fa-check"></i><b>E</b> Math review</a><ul>
<li class="chapter" data-level="E.1" data-path="mathreview.html"><a href="mathreview.html#math-linear"><i class="fa fa-check"></i><b>E.1</b> Linear equations</a></li>
<li class="chapter" data-level="E.2" data-path="mathreview.html"><a href="mathreview.html#math-log"><i class="fa fa-check"></i><b>E.2</b> Logarithms</a><ul>
<li class="chapter" data-level="E.2.1" data-path="slr.html"><a href="slr.html#interpreting-logged-variables"><i class="fa fa-check"></i><b>E.2.1</b> Interpreting logged variables</a></li>
<li class="chapter" data-level="E.2.2" data-path="slr.html"><a href="slr.html#inverse-i.e.-reversing-the-log-getting-rid-of-the-log"><i class="fa fa-check"></i><b>E.2.2</b> Inverse (i.e. reversing the log, getting rid of the log, …)</a></li>
<li class="chapter" data-level="E.2.3" data-path="mathreview.html"><a href="mathreview.html#logarithms-in-r"><i class="fa fa-check"></i><b>E.2.3</b> Logarithms in R</a></li>
</ul></li>
<li class="chapter" data-level="E.3" data-path="mathreview.html"><a href="mathreview.html#math-exercises"><i class="fa fa-check"></i><b>E.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Math 245 Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="slr" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Simple Linear Regression</h1>
<p>This chapter contains content from Sleuth Chapters 7 and 8.</p>
<div id="the-variables" class="section level2">
<h2><span class="header-section-number">2.1</span> The variables</h2>
<p>Suppose we have a quantitative response variable <span class="math inline">\(y\)</span> that we want to relate to an explantory (aka predictor) variable <span class="math inline">\(x\)</span>. For now, we will assume that <span class="math inline">\(x\)</span> is also quantitative.</p>
</div>
<div id="slr-model" class="section level2">
<h2><span class="header-section-number">2.2</span> The model form</h2>
<p>This section describes the SLR model for a particular <strong>population</strong> of interest. Another way to frame the model is that it describes a hypothetical <strong>data generating process (DGP)</strong> that was used to generate the sample of data that we have on hand.</p>
<p>Let <span class="math inline">\(Y_i\)</span> be the response from unit <span class="math inline">\(i\)</span> that has explanatory (aka predictor) value <span class="math inline">\(x_i\)</span>. There are two <strong>equivalent</strong> ways to express the SLR model for <span class="math inline">\(Y\)</span>:</p>
<ul>
<li><p>Conditional normal model: Given a value <span class="math inline">\(x_i\)</span>, the response <span class="math inline">\(Y_i\)</span> follows a normal model with mean and SD given below:
<span class="math display">\[
Y_i \mid x_i \sim N(\mu_{y\mid x} = \beta_0 + \beta_1 x_i, \sigma)
\]</span></p></li>
<li><p>Mean + error: Statisticians are more likely to use a model specification that expresses <span class="math inline">\(Y\)</span> as a function of the <strong>expected value/mean</strong> of <span class="math inline">\(Y\)</span> plus an <strong>error</strong> term that models variation in responses around the mean:
<span class="math display">\[\begin{equation}
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i \ \ \ \ \ \epsilon_i \sim N(0, \sigma)
\end{equation}\]</span></p></li>
</ul>
<p><strong>Both</strong> expressions of the SLR model above say the same thing:</p>
<ul>
<li><strong>Linear Mean:</strong> <span class="math inline">\(\mu_{y\mid x} = E(Y \mid x) = \beta_0 + \beta_1 x\)</span> describes the population mean value of <span class="math inline">\(Y\)</span> given a predictor value <span class="math inline">\(x\)</span>. This mean value varies linearly with <span class="math inline">\(x\)</span> and the population parameters are <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</li>
<li><strong>Constant SD:</strong> <span class="math inline">\(SD(Y\mid x)=\sigma\)</span> describes the SD of <span class="math inline">\(Y\)</span>’s in the population around a given mean value <span class="math inline">\(\mu_{y\mid x}\)</span>. The fact that this SD <strong>does not</strong> depend on the value of <span class="math inline">\(x\)</span> is called the contant variance, or homoscedastic, assumption.</li>
<li><strong>Normality:</strong> The shape of population response values around <span class="math inline">\(\mu_{y\mid x}\)</span> is described by a normal distribution model.</li>
</ul>
<p>Finally, one last assumption is made for the SLR model:</p>
<ul>
<li><strong>Indepedence:</strong> Given a predictor value of <span class="math inline">\(x\)</span>, all responses <span class="math inline">\(Y\)</span> occur independently of each other.</li>
</ul>
<p>There are a total of <strong>three parameters</strong> in the SLR model:</p>
<ul>
<li>the two mean parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span></li>
<li>the SD parameter <span class="math inline">\(\sigma\)</span></li>
</ul>
<div id="interpretation" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Interpretation</h3>
<p>For a SLR model:</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span> is the mean response when the predictor value is 0 since <span class="math inline">\(\mu_{y \mid 0} = \beta_0 + \beta_1(0) = \beta_0\)</span>.</li>
<li><span class="math inline">\(\beta_1\)</span> tells us how the mean response changes for a one unit increase in <span class="math inline">\(x\)</span></li>
</ul>
</div>
<div id="slr-model-ex" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Example: Woodpecker nests</h3>
<p>We want to model nest depth (cm) in a tree cavity as a function of ambient air temperature (Celsius). Our SLR model for this relationships says that, given an ambient air temp <span class="math inline">\(x_i\)</span>, a randomly selected nest will have a depth <span class="math inline">\(Y_i\)</span> that is modeled as
<span class="math display">\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i \ \ \ \ \ \epsilon_i \sim N(0, \sigma)
\]</span>
This means that depth is normally distributed with a mean of <span class="math inline">\(\mu_{depth \mid temp} = \beta_0 + \beta_1 (temp)\)</span> and a SD of <span class="math inline">\(\sigma\)</span>.</p>
<hr />
</div>
</div>
<div id="slr-est" class="section level2">
<h2><span class="header-section-number">2.3</span> Theory: Estimation</h2>
<p>Let’s consider taking a random sample of size <span class="math inline">\(n\)</span> of responses and predictor values from our population (or DGP) for which the SLR model holds: <span class="math inline">\((x_1, Y_1), \dotsc, (x_n, Y_n)\)</span>. The notation here, <span class="math inline">\((x_i, Y_i)\)</span> implies that the predictor value <span class="math inline">\(x_i\)</span> is fixed, but <span class="math inline">\(Y_i\)</span> is a <strong>random variable</strong> that is generated from the SLR model described in Section <a href="slr.html#slr-model">2.2</a>. The <strong>estimation</strong> problem is that we need to use the sample of size <span class="math inline">\(n\)</span> to estimate the SLR model parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\sigma\)</span>.</p>
<p>Once we observe a sample of size <span class="math inline">\(n\)</span>, then we can use the SLR model to determine the probability of observing the sample. This probability, which depends on the actual model parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\sigma\)</span>, is called a <strong>likelihood function</strong>. We plug the observed data into this function, then find the parameters values that <strong>maximize</strong> the function using calculus. For a SLR model, this process yields the following <strong>maximum likelihood estimators (MLE)</strong> of our parameters:
<span class="math display">\[
\hat{\beta}_1 = \dfrac{\sum_{i=1}^n (x_i - \bar{x})(Y_i - \bar{Y})}{\sum_{i=1}^n (x_i - \bar{x})^2} \ \ \ \ \ \hat{\beta}_0 = \bar{Y} - \bar{\beta}_1 \bar{x} \ \ \ \ \ \hat{\sigma} = \sqrt{\dfrac{\sum_{i=1}^n (Y_i - \hat{y}_i)^2}{n-2}}
\]</span>
where <span class="math inline">\(\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i\)</span> is the <strong>predicted value</strong> of <span class="math inline">\(y\)</span> given the value <span class="math inline">\(x_i\)</span>.</p>
<div id="sampling-distributions-for-slr-estimates" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Sampling Distributions for SLR estimates</h3>
<p>The sampling distribution of a model estimate (<span class="math inline">\(\hat{\beta}_0\)</span> or <span class="math inline">\(\hat{\beta}_1\)</span>) is constructed by:</p>
<ol style="list-style-type: decimal">
<li>fix a set of predictor values: <span class="math inline">\(x_1, \dotsc, x_n\)</span></li>
<li>for each fixed <span class="math inline">\(x_i\)</span>, generate a response <span class="math inline">\(Y_i\)</span> from <span class="math inline">\(N(\beta_0 + \beta_1 x_i, \sigma)\)</span></li>
<li>compute the MLE’s <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> from the observed sample from (2)</li>
<li>repeat 2-3 lots of times, then the distribution of the estimates from part (3) show the sampling distribution of the slope or intercept estimate.</li>
</ol>
<p>Using probability theory, we can show that the sampling distributions of both <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> are approximately normal when <span class="math inline">\(n\)</span> is “large enough” (thanks to the CLT):
<span class="math display">\[
\hat{\beta}_i \sim N(\beta_i, SD(\hat{\beta}_i))
\]</span></p>
<ul>
<li><strong>Unbiased:</strong> We see that the expected value (mean) of <span class="math inline">\(\hat{\beta}_i\)</span> is the parameter <span class="math inline">\(\beta_i\)</span>, meaning it is an unbiased estimator. (It doesn’t systematically over- or under-estimate the parameter of interest.)</li>
<li><strong>Standard error:</strong> We end up estimating the SD in the sampling distribution given above. The SEs for each mean parameter estimate are
<span class="math display">\[
SE(\hat{\beta}_1) = \hat{\sigma}\sqrt{\dfrac{1}{(n-1)s^2_x}} \ \ \ \ \ SE(\hat{\beta}_0) = \hat{\sigma}\sqrt{\dfrac{1}{n} + \dfrac{\bar{x}^2}{(n-1)s^2_x}}
\]</span></li>
</ul>
<hr />
</div>
</div>
<div id="slr-sim" class="section level2">
<h2><span class="header-section-number">2.4</span> SLR model simulation</h2>
<p>Download the Markdown of this activity: <a href="https://kstclair.github.io/Math245/Rhandouts/Day3RegLineSim.Rmd">.Rmd</a>.</p>
<div id="simulation-function" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Simulation function</h3>
<p>This chunk contains code that defines our function <code>reg.sim</code> that <strong>simulates <span class="math inline">\(n\)</span> responses from a given regression model and given set of <span class="math inline">\(n\)</span> predictor values <span class="math inline">\(x\)</span></strong>. I’ve excluded it from our compiled document so see the .Rmd file to take a look at how this was created.</p>
</div>
<div id="run-the-function-once" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Run the function once</h3>
<p>Let’s use the function from (1) above. We will use the <span class="math inline">\(n=12\)</span> temps (x-values) from the woodpeckers data and assume that the <strong>true</strong> model is:
<span class="math display">\[\mu(y \mid x) = 20 - 0.4x\]</span>
(red line below) with <span class="math inline">\(\beta_0=20\)</span>, <span class="math inline">\(\beta_1=-0.4\)</span>, and <span class="math inline">\(\sigma=2\)</span>. In the code below I use the <code>set.seed()</code> command to “fix” the random number generator so I get the same answer each time this is run (so my answer in the handout is reproduced each time this file is compiled).</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="slr.html#cb17-1"></a><span class="op">&gt;</span><span class="st"> </span>wpdata&lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://people.carleton.edu/~kstclair/data/woodpeckers.csv&quot;</span>)</span>
<span id="cb17-2"><a href="slr.html#cb17-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">set.seed</span>(<span class="dv">77</span>)  </span>
<span id="cb17-3"><a href="slr.html#cb17-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">reg.sim</span>(<span class="dt">x=</span>wpdata<span class="op">$</span>temp, <span class="dt">beta0=</span><span class="dv">20</span>, <span class="dt">beta1=</span><span class="op">-</span>.<span class="dv">4</span>, <span class="dt">sigma=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-19-1.png" width="480" /></p>
<pre><code>## $b0
## [1] 20.8893
## 
## $b1
## [1] -0.4682368</code></pre>
<p>For this simulated sample (with seed of 77), the estimated regression line is <span class="math inline">\(\hat{\mu}(y \mid x) = 20.889 - 0.468x\)</span> (black line).</p>
</div>
<div id="simulated-sampling-distribution-for-hatbeta_1" class="section level3">
<h3><span class="header-section-number">2.4.3</span> Simulated sampling distribution for <span class="math inline">\(\hat{\beta}_1\)</span></h3>
<p>We will now use the <code>replicate</code> command to generate 1000 different samples which create 1000 different estimates of <span class="math inline">\(\beta_1\)</span>. A histogram of these estimates simulates the sampling distribution of estimated slope.</p>
<p><strong>What is the shape of the sampling distribution? Where is the distribution centered? How variable are these estimated slopes.</strong></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="slr.html#cb19-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">set.seed</span>(<span class="dv">7</span>)  <span class="co"># just makes simulation reproducible</span></span>
<span id="cb19-2"><a href="slr.html#cb19-2"></a><span class="op">&gt;</span><span class="st"> </span>slopes&lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">1000</span>,<span class="kw">reg.sim</span>(<span class="dt">x=</span>wpdata<span class="op">$</span>temp, <span class="dt">beta0=</span><span class="dv">20</span>, <span class="dt">beta1=</span><span class="op">-</span>.<span class="dv">4</span>, <span class="dt">sigma=</span><span class="dv">2</span>,<span class="dt">grph=</span>F)<span class="op">$</span>b1)</span>
<span id="cb19-3"><a href="slr.html#cb19-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">hist</span>(slopes); <span class="kw">abline</span>(<span class="dt">v=</span><span class="op">-</span><span class="fl">0.4</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-20-1.png" width="480" /></p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="slr.html#cb20-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">mean</span>(slopes); <span class="kw">sd</span>(slopes)</span>
<span id="cb20-2"><a href="slr.html#cb20-2"></a><span class="co">## [1] -0.3974248</span></span>
<span id="cb20-3"><a href="slr.html#cb20-3"></a><span class="co">## [1] 0.05227315</span></span></code></pre></div>
</div>
<div id="slr-simcor" class="section level3">
<h3><span class="header-section-number">2.4.4</span> Are slope and intercept estimates correlated?</h3>
<p>In regression, it is not unusual to be interested in estimating a <strong>linear combination</strong> of our model parameters. An easy example of such a combination of parameters is the mean response for a given value <span class="math inline">\(x_0\)</span> of the predictor:
<span class="math display">\[
\mu(y \mid x=x_0) = \beta_0 + \beta_1x_0
\]</span>
For a specific example, we may want to estimate the mean response (depth) for a temp of <span class="math inline">\(x_0=5\)</span> degrees: <span class="math inline">\(\mu(y \mid x=5) = \beta_0 + \beta_1 5\)</span>. If we don’t know <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, then this mean parameter is a linear combination of two unknown parameters which we need to estimate.</p>
<p>The natural estimate of this is just the estimated mean response: <span class="math inline">\(\hat{\mu}(y \mid x=x_0)=\hat{\beta}_0 + \hat{\beta}_1x_0\)</span>. To assess how variable this estimate is (i.e. to get its SE) we need to understand how (if) the individual estimates <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> are correlated. We can use a simulation to look at this issue by generating 1000 samples from our model and plotting each <span class="math inline">\((\hat{\beta}_0,\hat{\beta}_1)\)</span> pair for each sample.</p>
<p><strong>How are estimated slope and intercept associated? Any ideas why?</strong></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="slr.html#cb21-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">set.seed</span>(<span class="dv">7</span>)  <span class="co"># this seed MUST match the seed used to get slopes!</span></span>
<span id="cb21-2"><a href="slr.html#cb21-2"></a><span class="op">&gt;</span><span class="st"> </span>intercepts&lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">1000</span>,<span class="kw">reg.sim</span>(<span class="dt">x=</span>wpdata<span class="op">$</span>temp, <span class="dt">beta0=</span><span class="dv">20</span>, <span class="dt">beta1=</span><span class="op">-</span>.<span class="dv">4</span>, <span class="dt">sigma=</span><span class="dv">2</span>,<span class="dt">grph=</span>F)<span class="op">$</span>b0)</span>
<span id="cb21-3"><a href="slr.html#cb21-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">plot</span>(intercepts,slopes); <span class="kw">abline</span>(<span class="dt">h=</span><span class="op">-</span>.<span class="dv">4</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>); <span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">20</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb21-4"><a href="slr.html#cb21-4"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">title</span>(<span class="st">&quot;Estimated slopes and intercepts&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="slr.html#cb22-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">cor</span>(intercepts, slopes) <span class="co"># correlation between estimates</span></span>
<span id="cb22-2"><a href="slr.html#cb22-2"></a><span class="co">## [1] -0.6928231</span></span>
<span id="cb22-3"><a href="slr.html#cb22-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">cov</span>(intercepts, slopes) <span class="co"># covariance between estimates</span></span>
<span id="cb22-4"><a href="slr.html#cb22-4"></a><span class="co">## [1] -0.02869504</span></span></code></pre></div>
<hr />
</div>
</div>
<div id="slr-inf" class="section level2">
<h2><span class="header-section-number">2.5</span> Inference for mean parameters</h2>
<p>In intro stats, you used <span class="math inline">\(t\)</span> inference procedures for inference about population means since: (1) the sampling distribution of the sample mean was normally distributed and (2) we had to estimate its variability with a SE. The same goes for inference about the mean response parameters in a SLR model:
<span class="math display">\[
t = \dfrac{\hat{\beta}_i - \beta_i}{SE(\hat{\beta}_i)} \sim t_{df=n-2}
\]</span>
Use a t-distribution with <span class="math inline">\(n-2\)</span> degrees of freedom for inference about the mean parameters. The degrees of freedom are calculated as the sample size <span class="math inline">\(n\)</span> minus the number of terms in <span class="math inline">\(\mu_{y \mid x}\)</span> that you have to estimate with the data.</p>
<div id="confidence-intervals" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Confidence Intervals</h3>
<p>To estimate either mean parameter with <span class="math inline">\(C\)</span>% confidence, we have the general form
<span class="math display">\[
\hat{\beta}_i \pm t^* SE(\hat{\beta}_i)
\]</span>
where <span class="math inline">\(t^*\)</span> is the <span class="math inline">\((100-C)/2\)</span> percentile from the t-distribution with <span class="math inline">\(df=n-2\)</span> degrees of freedom.</p>
</div>
<div id="hypothesis-tests" class="section level3">
<h3><span class="header-section-number">2.5.2</span> Hypothesis tests</h3>
<p>We can test the hypothesis
<span class="math display">\[
H_0: \beta_i = \beta^*_i
\]</span>
with the following t-test statistic:
<span class="math display">\[
t =\dfrac{\hat{\beta}_i - \beta^*_i}{SE(\hat{\beta}_i)}
\]</span>
where <span class="math inline">\(\beta^*\)</span> is our hypothesized value of <span class="math inline">\(\beta\)</span> (intercept or slope). The t-distribution with <span class="math inline">\(n-2\)</span> degrees of freedom is used to compute the p-value that is appropriate for whatever <span class="math inline">\(H_A\)</span> is specified.</p>
<p>The usual test results given by standard regression output tests whether a parameter value (intercept or slope) is equal to 0 vs. not equal to 0:
<span class="math display">\[
H_0: \beta_i = 0 \ \ \ \ \ H_A: \beta_i \neq 0
\]</span>
with a test stat of
<span class="math display">\[
t =\dfrac{\hat{\beta}_i - 0}{SE(\hat{\beta}_i)}
\]</span></p>
<hr />
</div>
</div>
<div id="slr-inf2" class="section level2">
<h2><span class="header-section-number">2.6</span> Inference for average or predicted response</h2>
<div id="confidence-intervals-for-mu_y-mid-x" class="section level3">
<h3><span class="header-section-number">2.6.1</span> Confidence intervals for <span class="math inline">\(\mu_{y \mid x}\)</span></h3>
<p>Here we are interested in estimating not just a <span class="math inline">\(\beta\)</span> with confidence, but we want to estimate the <strong>mean</strong> response for a given value of <span class="math inline">\(x_0\)</span>. For example, suppose we want to estimate the <strong>mean</strong> nest depth when the temp is <span class="math inline">\(x_0=8\)</span> degrees. This mean parameter of interest is then:
<span class="math display">\[
\mu_{depth \mid temp=8} = \beta_0 + \beta_1 (8)
\]</span></p>
<p>Our parameter of interest is <span class="math inline">\(\mu_{y \mid x_0} = \beta_0 + \beta_1 x_0\)</span> where <span class="math inline">\(x_0\)</span> is known and <span class="math inline">\(\beta\)</span>’s need to be estimated. The natural estimator is just the fitted equation:
<span class="math display">\[
\hat{\mu}_{y \mid x_0} = \hat{\beta}_0 + \hat{\beta}_1 x_0
\]</span>
As will <em>any</em> estimator, we can measure the variability of this estimator with a SE:
<span class="math display">\[
SE(\hat{\mu}_{y \mid x_0}) = \hat{\sigma} \sqrt{\dfrac{1}{n} + \dfrac{(x_0 - \bar{x})^2}{(n-1)s^2_x}}
\]</span>
<strong>Note!</strong> This SE <strong>depends on <span class="math inline">\(\pmb{x_0}\)</span></strong>! It is miminized when <span class="math inline">\(x_0\)</span> equals the mean predictor value <span class="math inline">\(\bar{x}\)</span> and it grows as <span class="math inline">\(x_0\)</span> gets further from <span class="math inline">\(\bar{x}\)</span>. Estimation is most precise in the “middle” of the predictor range and becomes less precise at the “edges” (where we usually have less data).</p>
<p>A 95% confidence interval for the mean response <span class="math inline">\(\mu_{y \mid x_0}\)</span> looks like
<span class="math display">\[
\hat{\mu}_{y \mid x_0} \pm t^*_{df=n-2}SE(\hat{\mu}_{y \mid x_0}) 
\]</span></p>
</div>
<div id="prediction-intervals-for-new-cases" class="section level3">
<h3><span class="header-section-number">2.6.2</span> Prediction intervals for new cases</h3>
<p>To predict <em>one individual’s future response</em> <span class="math inline">\(Y\)</span> for the predictor value <span class="math inline">\(x_0\)</span>, we just use the fitted equation:
<span class="math display">\[
pred_{y \mid x_0} = \hat{\beta}_0 + \hat{\beta}_1 x_0
\]</span>
(We use <span class="math inline">\(pred_{y \mid x_0}\)</span> to remind us which predictor value as used for prediction.)</p>
<p>Recall that the SLR model assumes the <span class="math inline">\(Y\)</span> values when <span class="math inline">\(x=x_0\)</span> are normally distributed with mean <span class="math inline">\(\mu_{y \mid x_0}\)</span> and SD <span class="math inline">\(\sigma\)</span>. The SE of this prediction at <span class="math inline">\(x_0\)</span> takes into account (1) uncertainty in estimating the <em>mean</em> <span class="math inline">\(\mu_{y \mid x_0}\)</span> and (2) variation in <span class="math inline">\(Y\)</span>’s around the mean response (<span class="math inline">\(\sigma\)</span>):
<span class="math display">\[
SE(pred_{y \mid x_0}) = \hat{\sigma} \sqrt{1 + \dfrac{1}{n} + \dfrac{(x_0 - \bar{x})^2}{(n-1)s^2_x}} = \sqrt{\hat{\sigma}^2 + SE(\hat{\mu}_{y \mid x_0})^2  }
\]</span>
A 95% <strong>prediction</strong> interval for a future individual response at <span class="math inline">\(x=x_0\)</span> looks like
<span class="math display">\[
pred_{y \mid x_0} \pm t^*_{df=n-2}SE(pred_{y \mid x_0})
\]</span></p>
<p>Predictions intervals feel and look similar to the mean response intervals above, but there is a very important conceptual difference: <em>prediction</em> means we are trying to “guess” at <em>one individual response</em> as opposed to the mean response of a large group of individuals. For example, if we want to understand nest depths for all nest build when temp is 8 degrees, then we care about estimating a fixed (but unknown) mean depth <span class="math inline">\(\mu_{depth \mid temp=8}\)</span>. If we see a bird starting to build a nest at 8 degrees, then we care about predicting this one, randomly determined depth <span class="math inline">\(Y\)</span> using <span class="math inline">\(pred_{depth \mid temp=8}\)</span> and would use a prediction interval.</p>
<hr />
</div>
</div>
<div id="slr-example1" class="section level2">
<h2><span class="header-section-number">2.7</span> Example: SLR model (day 3)</h2>
<p>We will revisit the woodpecker nesting data first described in Section <a href="slr.html#slr-model-ex">2.2.2</a>.</p>
<div id="load-data" class="section level3">
<h3><span class="header-section-number">2.7.1</span> Load data</h3>
<p>Let’s suppose these 16 nests are a random sample of all nests in the collection region. The command <code>head(dataname)</code> produces a view of the first 5 rows of data.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="slr.html#cb23-1"></a><span class="op">&gt;</span><span class="st"> </span>wpdata &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://people.carleton.edu/~kstclair/data/woodpeckers.csv&quot;</span>)</span>
<span id="cb23-2"><a href="slr.html#cb23-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">head</span>(wpdata)</span>
<span id="cb23-3"><a href="slr.html#cb23-3"></a><span class="co">##   temp depth</span></span>
<span id="cb23-4"><a href="slr.html#cb23-4"></a><span class="co">## 1   -6  21.1</span></span>
<span id="cb23-5"><a href="slr.html#cb23-5"></a><span class="co">## 2   -3  26.0</span></span>
<span id="cb23-6"><a href="slr.html#cb23-6"></a><span class="co">## 3   -2  18.0</span></span>
<span id="cb23-7"><a href="slr.html#cb23-7"></a><span class="co">## 4    1  19.2</span></span>
<span id="cb23-8"><a href="slr.html#cb23-8"></a><span class="co">## 5    6  16.9</span></span>
<span id="cb23-9"><a href="slr.html#cb23-9"></a><span class="co">## 6   10  18.1</span></span>
<span id="cb23-10"><a href="slr.html#cb23-10"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">dim</span>(wpdata)</span>
<span id="cb23-11"><a href="slr.html#cb23-11"></a><span class="co">## [1] 12  2</span></span></code></pre></div>
</div>
<div id="eda" class="section level3">
<h3><span class="header-section-number">2.7.2</span> EDA</h3>
<p>Start with univariate exploration:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="slr.html#cb24-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(wpdata)</span>
<span id="cb24-2"><a href="slr.html#cb24-2"></a><span class="co">##       temp           depth      </span></span>
<span id="cb24-3"><a href="slr.html#cb24-3"></a><span class="co">##  Min.   :-6.00   Min.   :10.50  </span></span>
<span id="cb24-4"><a href="slr.html#cb24-4"></a><span class="co">##  1st Qu.: 0.25   1st Qu.:12.03  </span></span>
<span id="cb24-5"><a href="slr.html#cb24-5"></a><span class="co">##  Median :10.50   Median :16.85  </span></span>
<span id="cb24-6"><a href="slr.html#cb24-6"></a><span class="co">##  Mean   :11.00   Mean   :16.36  </span></span>
<span id="cb24-7"><a href="slr.html#cb24-7"></a><span class="co">##  3rd Qu.:21.75   3rd Qu.:18.38  </span></span>
<span id="cb24-8"><a href="slr.html#cb24-8"></a><span class="co">##  Max.   :26.00   Max.   :26.00</span></span>
<span id="cb24-9"><a href="slr.html#cb24-9"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb24-10"><a href="slr.html#cb24-10"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">hist</span>(wpdata<span class="op">$</span>temp)</span>
<span id="cb24-11"><a href="slr.html#cb24-11"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">hist</span>(wpdata<span class="op">$</span>depth)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="slr.html#cb25-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))  </span></code></pre></div>
<p>Graphically explore the (“bivariate”) relationship between temp and depth with a scatterplot using the command <code>plot(y,x)</code>. Here is the <code>plot</code> version (with <code>pch</code> point character changed to give filled circles):</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="slr.html#cb26-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">plot</span>(depth <span class="op">~</span><span class="st"> </span>temp, <span class="dt">data=</span>wpdata, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">xlab=</span><span class="st">&quot;air temperature (C)&quot;</span>, </span>
<span id="cb26-2"><a href="slr.html#cb26-2"></a><span class="op">+</span><span class="st">      </span><span class="dt">ylab=</span><span class="st">&quot;nest depth (cm)&quot;</span>, <span class="dt">main=</span><span class="st">&quot;woodpeckers scatterplot&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-25-1.png" width="576" /></p>
<p>Here is the <code>ggplot2</code> version with <code>labs</code> added to change labels and title:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="slr.html#cb27-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(ggplot2)</span>
<span id="cb27-2"><a href="slr.html#cb27-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(wpdata, <span class="kw">aes</span>(<span class="dt">x=</span>temp, <span class="dt">y =</span> depth)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb27-3"><a href="slr.html#cb27-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;air temperature (C)&quot;</span>, <span class="dt">y=</span> <span class="st">&quot;nest depth (cm)&quot;</span>, <span class="dt">title=</span> <span class="st">&quot;woodpeckers scatterplot&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-26-1.png" width="576" /></p>
</div>
<div id="the-least-squares-line-the-estimated-slr-model" class="section level3">
<h3><span class="header-section-number">2.7.3</span> The least squares line (the estimated SLR model):</h3>
<p>You fit the linear model with mean <span class="math inline">\(\mu_{Y \mid x} = \beta_0 + \beta_1 x\)</span> with the linear model function <code>lm(y ~ x, data=)</code>.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="slr.html#cb28-1"></a><span class="op">&gt;</span><span class="st"> </span>wood.lm &lt;-<span class="st"> </span><span class="kw">lm</span>(depth<span class="op">~</span>temp, <span class="dt">data=</span>wpdata)</span>
<span id="cb28-2"><a href="slr.html#cb28-2"></a><span class="op">&gt;</span><span class="st"> </span>wood.lm</span>
<span id="cb28-3"><a href="slr.html#cb28-3"></a><span class="co">## </span></span>
<span id="cb28-4"><a href="slr.html#cb28-4"></a><span class="co">## Call:</span></span>
<span id="cb28-5"><a href="slr.html#cb28-5"></a><span class="co">## lm(formula = depth ~ temp, data = wpdata)</span></span>
<span id="cb28-6"><a href="slr.html#cb28-6"></a><span class="co">## </span></span>
<span id="cb28-7"><a href="slr.html#cb28-7"></a><span class="co">## Coefficients:</span></span>
<span id="cb28-8"><a href="slr.html#cb28-8"></a><span class="co">## (Intercept)         temp  </span></span>
<span id="cb28-9"><a href="slr.html#cb28-9"></a><span class="co">##     20.1223      -0.3422</span></span></code></pre></div>
<p>We have mean parameter estimates:
<span class="math display">\[
\hat{\beta}_0 = 20.122 \ \ \ \ \hat{\beta}_0 = -0.342
\]</span></p>
<p>The object <code>wood.lm</code> is called a <em>linear model object</em> in R. We can add the regression line from this object to an existing <em>base R</em> plot of the data using the <code>abline</code> command.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="slr.html#cb29-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">plot</span>(depth <span class="op">~</span><span class="st"> </span>temp, <span class="dt">data=</span>wpdata, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">xlab=</span><span class="st">&quot;air temperature (C)&quot;</span>, </span>
<span id="cb29-2"><a href="slr.html#cb29-2"></a><span class="op">+</span><span class="st">      </span><span class="dt">ylab=</span><span class="st">&quot;nest depth (cm)&quot;</span>, <span class="dt">main=</span><span class="st">&quot;regression of depth on temp&quot;</span>)</span>
<span id="cb29-3"><a href="slr.html#cb29-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">abline</span>(wood.lm)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-29-1.png" width="576" /></p>
<p>The <code>ggplot2</code> package contains a <code>geom_smooth</code> geometry to add this SLR line:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="slr.html#cb30-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(wpdata, <span class="kw">aes</span>(<span class="dt">x=</span>temp, <span class="dt">y =</span> depth)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb30-2"><a href="slr.html#cb30-2"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb30-3"><a href="slr.html#cb30-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb30-4"><a href="slr.html#cb30-4"></a><span class="op">+</span><span class="st">   </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;air temperature (C)&quot;</span>, <span class="dt">y=</span> <span class="st">&quot;nest depth (cm)&quot;</span>, <span class="dt">title=</span> <span class="st">&quot;woodpeckers scatterplot&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-30-1.png" width="576" /></p>
<p>With <code>geom_smooth</code>, you need to specify the type of method used to relate <span class="math inline">\(x\)</span> to <span class="math inline">\(y\)</span>. Adding <code>se=FALSE</code> removes a confidence interval for the mean trend. Notice that the <code>aes</code> aesthetic given in the <code>ggplot</code> function specifies the x and y variables to plot. The <code>geom</code>’s that follow this part of the command use this <code>aes</code> to create points and an estimated line.</p>
</div>
<div id="inference-for-coefficients" class="section level3">
<h3><span class="header-section-number">2.7.4</span> Inference for coefficients</h3>
<p>The <code>summary</code> command is used for statistical inference for the intercept <span class="math inline">\(\beta_0\)</span> and slope <span class="math inline">\(\beta_1\)</span>:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="slr.html#cb31-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(wood.lm)</span>
<span id="cb31-2"><a href="slr.html#cb31-2"></a><span class="co">## </span></span>
<span id="cb31-3"><a href="slr.html#cb31-3"></a><span class="co">## Call:</span></span>
<span id="cb31-4"><a href="slr.html#cb31-4"></a><span class="co">## lm(formula = depth ~ temp, data = wpdata)</span></span>
<span id="cb31-5"><a href="slr.html#cb31-5"></a><span class="co">## </span></span>
<span id="cb31-6"><a href="slr.html#cb31-6"></a><span class="co">## Residuals:</span></span>
<span id="cb31-7"><a href="slr.html#cb31-7"></a><span class="co">##     Min      1Q  Median      3Q     Max </span></span>
<span id="cb31-8"><a href="slr.html#cb31-8"></a><span class="co">## -2.8066 -1.3321 -0.6529  0.6811  4.8512 </span></span>
<span id="cb31-9"><a href="slr.html#cb31-9"></a><span class="co">## </span></span>
<span id="cb31-10"><a href="slr.html#cb31-10"></a><span class="co">## Coefficients:</span></span>
<span id="cb31-11"><a href="slr.html#cb31-11"></a><span class="co">##             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb31-12"><a href="slr.html#cb31-12"></a><span class="co">## (Intercept) 20.12228    0.94024  21.401 1.11e-09 ***</span></span>
<span id="cb31-13"><a href="slr.html#cb31-13"></a><span class="co">## temp        -0.34218    0.05961  -5.741 0.000188 ***</span></span>
<span id="cb31-14"><a href="slr.html#cb31-14"></a><span class="co">## ---</span></span>
<span id="cb31-15"><a href="slr.html#cb31-15"></a><span class="co">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb31-16"><a href="slr.html#cb31-16"></a><span class="co">## </span></span>
<span id="cb31-17"><a href="slr.html#cb31-17"></a><span class="co">## Residual standard error: 2.335 on 10 degrees of freedom</span></span>
<span id="cb31-18"><a href="slr.html#cb31-18"></a><span class="co">## Multiple R-squared:  0.7672,	Adjusted R-squared:  0.7439 </span></span>
<span id="cb31-19"><a href="slr.html#cb31-19"></a><span class="co">## F-statistic: 32.96 on 1 and 10 DF,  p-value: 0.0001875</span></span></code></pre></div>
<p>This output gives the mean parameter estimates in the <code>Estimate</code> column of the main table:
<span class="math display">\[
\hat{\beta}_0 = 20.122 \ \ \ \ \hat{\beta}_0 = -0.342
\]</span>
The estimated model SD <span class="math inline">\(\sigma\)</span> is given by <code>Residual standard error</code>:
<span class="math display">\[
\hat{\sigma} = 2.335
\]</span></p>
<p>You should know how to verify (or find) the test stats and p-values for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> given by the <code>summary</code> command if you are given the estimates and SEs. For the slope test <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs. <span class="math inline">\(H_A: \beta_1 \neq 0\)</span> we get a <span class="math inline">\(t\)</span> test stat of</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="slr.html#cb32-1"></a><span class="op">&gt;</span><span class="st"> </span>(<span class="op">-</span><span class="fl">0.34218</span> <span class="op">-</span><span class="st"> </span><span class="dv">0</span>)<span class="op">/</span><span class="fl">0.05961</span></span>
<span id="cb32-2"><a href="slr.html#cb32-2"></a><span class="co">## [1] -5.740312</span></span></code></pre></div>
<p>The p-value for this two sided test is the probability of being above +5.741 and below -5.741, or double the probability below -5.741 (since the t-distribution is symmetric around 0):</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="slr.html#cb33-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">pt</span>(<span class="op">-</span><span class="fl">5.741</span>,<span class="dv">10</span>)</span>
<span id="cb33-2"><a href="slr.html#cb33-2"></a><span class="co">## [1] 9.373105e-05</span></span>
<span id="cb33-3"><a href="slr.html#cb33-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span><span class="kw">pt</span>(<span class="op">-</span><span class="fl">5.741</span>,<span class="dv">10</span>)</span>
<span id="cb33-4"><a href="slr.html#cb33-4"></a><span class="co">## [1] 0.0001874621</span></span></code></pre></div>
<p>A 95% confidence interval for the slope <span class="math inline">\(\beta_1\)</span> is computed from the t distribution with 10 degrees of freedom:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="slr.html#cb34-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">qt</span>(.<span class="dv">975</span>,<span class="dv">10</span>)</span>
<span id="cb34-2"><a href="slr.html#cb34-2"></a><span class="co">## [1] 2.228139</span></span>
<span id="cb34-3"><a href="slr.html#cb34-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="fl">-.34218</span> <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">*</span><span class="kw">qt</span>(.<span class="dv">975</span>,<span class="dv">10</span>)<span class="op">*</span>.<span class="dv">05961</span></span>
<span id="cb34-4"><a href="slr.html#cb34-4"></a><span class="co">## [1] -0.4749994 -0.2093606</span></span>
<span id="cb34-5"><a href="slr.html#cb34-5"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">confint</span>(wood.lm)</span>
<span id="cb34-6"><a href="slr.html#cb34-6"></a><span class="co">##                  2.5 %     97.5 %</span></span>
<span id="cb34-7"><a href="slr.html#cb34-7"></a><span class="co">## (Intercept) 18.0272874 22.2172802</span></span>
<span id="cb34-8"><a href="slr.html#cb34-8"></a><span class="co">## temp        -0.4749868 -0.2093679</span></span></code></pre></div>
<p>The <code>confint</code> function gives the most accurate interval (no rounding error) but you need to know how to compute these CIs ``by hand."</p>
</div>
<div id="additional-lm-information" class="section level3">
<h3><span class="header-section-number">2.7.5</span> Additional <code>lm</code> information</h3>
<p>The function <code>lm</code> creates a <em>linear model</em> object in R that has lots of information associated with it. Information includes the coefficient values, fitted values (<span class="math inline">\(\hat{y}_i\)</span>), and residuals (<span class="math inline">\(y_i - \hat{y}_i\)</span>):</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="slr.html#cb35-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">attributes</span>(wood.lm)</span>
<span id="cb35-2"><a href="slr.html#cb35-2"></a><span class="co">## $names</span></span>
<span id="cb35-3"><a href="slr.html#cb35-3"></a><span class="co">##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         </span></span>
<span id="cb35-4"><a href="slr.html#cb35-4"></a><span class="co">##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  </span></span>
<span id="cb35-5"><a href="slr.html#cb35-5"></a><span class="co">##  [9] &quot;xlevels&quot;       &quot;call&quot;          &quot;terms&quot;         &quot;model&quot;        </span></span>
<span id="cb35-6"><a href="slr.html#cb35-6"></a><span class="co">## </span></span>
<span id="cb35-7"><a href="slr.html#cb35-7"></a><span class="co">## $class</span></span>
<span id="cb35-8"><a href="slr.html#cb35-8"></a><span class="co">## [1] &quot;lm&quot;</span></span>
<span id="cb35-9"><a href="slr.html#cb35-9"></a><span class="op">&gt;</span><span class="st"> </span>wood.lm<span class="op">$</span>coefficients</span>
<span id="cb35-10"><a href="slr.html#cb35-10"></a><span class="co">## (Intercept)        temp </span></span>
<span id="cb35-11"><a href="slr.html#cb35-11"></a><span class="co">##  20.1222838  -0.3421773</span></span>
<span id="cb35-12"><a href="slr.html#cb35-12"></a><span class="op">&gt;</span><span class="st"> </span>wood.lm<span class="op">$</span>fitted.values   <span class="co"># predicted y values (y-hat)</span></span>
<span id="cb35-13"><a href="slr.html#cb35-13"></a><span class="co">##        1        2        3        4        5        6        7        8 </span></span>
<span id="cb35-14"><a href="slr.html#cb35-14"></a><span class="co">## 22.17535 21.14882 20.80664 19.78011 18.06922 16.70051 16.35833 13.62091 </span></span>
<span id="cb35-15"><a href="slr.html#cb35-15"></a><span class="co">##        9       10       11       12 </span></span>
<span id="cb35-16"><a href="slr.html#cb35-16"></a><span class="co">## 12.93656 11.91003 11.56785 11.22567</span></span>
<span id="cb35-17"><a href="slr.html#cb35-17"></a><span class="op">&gt;</span><span class="st"> </span>wood.lm<span class="op">$</span>residuals       <span class="co"># residuals for each data point</span></span>
<span id="cb35-18"><a href="slr.html#cb35-18"></a><span class="co">##          1          2          3          4          5          6          7 </span></span>
<span id="cb35-19"><a href="slr.html#cb35-19"></a><span class="co">## -1.0753477  4.8511843 -2.8066384 -0.5801065 -1.1692199  1.3994894  0.4416667 </span></span>
<span id="cb35-20"><a href="slr.html#cb35-20"></a><span class="co">##          8          9         10         11         12 </span></span>
<span id="cb35-21"><a href="slr.html#cb35-21"></a><span class="co">## -1.8209148 -1.9365602  0.1899718  3.2321491 -0.7256736</span></span></code></pre></div>
<p>There are also functions that act on <code>lm</code> objects like</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="slr.html#cb36-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">fitted</span>(wood.lm)</span>
<span id="cb36-2"><a href="slr.html#cb36-2"></a><span class="co">##        1        2        3        4        5        6        7        8 </span></span>
<span id="cb36-3"><a href="slr.html#cb36-3"></a><span class="co">## 22.17535 21.14882 20.80664 19.78011 18.06922 16.70051 16.35833 13.62091 </span></span>
<span id="cb36-4"><a href="slr.html#cb36-4"></a><span class="co">##        9       10       11       12 </span></span>
<span id="cb36-5"><a href="slr.html#cb36-5"></a><span class="co">## 12.93656 11.91003 11.56785 11.22567</span></span>
<span id="cb36-6"><a href="slr.html#cb36-6"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">resid</span>(wood.lm)</span>
<span id="cb36-7"><a href="slr.html#cb36-7"></a><span class="co">##          1          2          3          4          5          6          7 </span></span>
<span id="cb36-8"><a href="slr.html#cb36-8"></a><span class="co">## -1.0753477  4.8511843 -2.8066384 -0.5801065 -1.1692199  1.3994894  0.4416667 </span></span>
<span id="cb36-9"><a href="slr.html#cb36-9"></a><span class="co">##          8          9         10         11         12 </span></span>
<span id="cb36-10"><a href="slr.html#cb36-10"></a><span class="co">## -1.8209148 -1.9365602  0.1899718  3.2321491 -0.7256736</span></span>
<span id="cb36-11"><a href="slr.html#cb36-11"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">vcov</span>(wood.lm)  <span class="co"># variance and covariance matrix of beta estimates</span></span>
<span id="cb36-12"><a href="slr.html#cb36-12"></a><span class="co">##             (Intercept)         temp</span></span>
<span id="cb36-13"><a href="slr.html#cb36-13"></a><span class="co">## (Intercept)  0.88406062 -0.039081046</span></span>
<span id="cb36-14"><a href="slr.html#cb36-14"></a><span class="co">## temp        -0.03908105  0.003552822</span></span></code></pre></div>
</div>
<div id="slr-broom" class="section level3">
<h3><span class="header-section-number">2.7.6</span> <code>broom</code> package: Tidy <code>lm</code> output</h3>
<p>The <code>broom</code> package contains functions that convert model objects (like a <code>lm</code> object) into “tidy” data frames. The <code>tidy</code> command summarizes model results:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="slr.html#cb37-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(broom)</span>
<span id="cb37-2"><a href="slr.html#cb37-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">tidy</span>(wood.lm)</span>
<span id="cb37-3"><a href="slr.html#cb37-3"></a><span class="co">## # A tibble: 2 x 5</span></span>
<span id="cb37-4"><a href="slr.html#cb37-4"></a><span class="co">##   term        estimate std.error statistic       p.value</span></span>
<span id="cb37-5"><a href="slr.html#cb37-5"></a><span class="co">##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;</span></span>
<span id="cb37-6"><a href="slr.html#cb37-6"></a><span class="co">## 1 (Intercept)   20.1      0.940      21.4  0.00000000111</span></span>
<span id="cb37-7"><a href="slr.html#cb37-7"></a><span class="co">## 2 temp          -0.342    0.0596     -5.74 0.000188</span></span></code></pre></div>
<p>Notice that the output object is called a “tibble” which is a type of data frame in R.</p>
<p>Here we can add confidence intervals for the model parameters to the output:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="slr.html#cb38-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">tidy</span>(wood.lm, <span class="dt">conf.int=</span><span class="ot">TRUE</span>)</span>
<span id="cb38-2"><a href="slr.html#cb38-2"></a><span class="co">## # A tibble: 2 x 7</span></span>
<span id="cb38-3"><a href="slr.html#cb38-3"></a><span class="co">##   term        estimate std.error statistic       p.value conf.low conf.high</span></span>
<span id="cb38-4"><a href="slr.html#cb38-4"></a><span class="co">##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb38-5"><a href="slr.html#cb38-5"></a><span class="co">## 1 (Intercept)   20.1      0.940      21.4  0.00000000111   18.0      22.2  </span></span>
<span id="cb38-6"><a href="slr.html#cb38-6"></a><span class="co">## 2 temp          -0.342    0.0596     -5.74 0.000188        -0.475    -0.209</span></span></code></pre></div>
<p>The <code>augment</code> command augments the data frame used to create a <code>lm</code> with predicted values and residuals from the <code>lm</code> model:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="slr.html#cb39-1"></a><span class="op">&gt;</span><span class="st"> </span>wpdata.aug &lt;-<span class="st"> </span><span class="kw">augment</span>(wood.lm)</span>
<span id="cb39-2"><a href="slr.html#cb39-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">head</span>(wpdata.aug)</span>
<span id="cb39-3"><a href="slr.html#cb39-3"></a><span class="co">## # A tibble: 6 x 9</span></span>
<span id="cb39-4"><a href="slr.html#cb39-4"></a><span class="co">##   depth  temp .fitted .se.fit .resid   .hat .sigma .cooksd .std.resid</span></span>
<span id="cb39-5"><a href="slr.html#cb39-5"></a><span class="co">##   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;</span></span>
<span id="cb39-6"><a href="slr.html#cb39-6"></a><span class="co">## 1  21.1    -6    22.2   1.22  -1.08  0.272    2.42 0.0544      -0.540</span></span>
<span id="cb39-7"><a href="slr.html#cb39-7"></a><span class="co">## 2  26      -3    21.1   1.07   4.85  0.211    1.66 0.732        2.34 </span></span>
<span id="cb39-8"><a href="slr.html#cb39-8"></a><span class="co">## 3  18      -2    20.8   1.03  -2.81  0.194    2.23 0.215       -1.34 </span></span>
<span id="cb39-9"><a href="slr.html#cb39-9"></a><span class="co">## 4  19.2     1    19.8   0.900 -0.580 0.149    2.45 0.00632     -0.269</span></span>
<span id="cb39-10"><a href="slr.html#cb39-10"></a><span class="co">## 5  16.9     6    18.1   0.737 -1.17  0.0996   2.43 0.0154      -0.528</span></span>
<span id="cb39-11"><a href="slr.html#cb39-11"></a><span class="co">## 6  18.1    10    16.7   0.677  1.40  0.0840   2.41 0.0180       0.626</span></span></code></pre></div>
<p>The <code>.fitted</code> column gives the fitted values <span class="math inline">\(\hat{y}_i\)</span> for each case and the <code>.resid</code> gives the residuals <span class="math inline">\(y_i - \hat{y}_i\)</span>.</p>
</div>
<div id="inference-for-the-mean-and-predicted-response" class="section level3">
<h3><span class="header-section-number">2.7.7</span> Inference for the mean and predicted response</h3>
<p>We can get a 95% confidence interval for the mean nest depth at 8 degrees Celsius <span class="math inline">\(\mu(depth\mid temp=8)\)</span> with the <code>predict</code> command with interval type <code>confidence</code> specified:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="slr.html#cb40-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">predict</span>(wood.lm, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">temp=</span><span class="dv">8</span>), <span class="dt">interval =</span> <span class="st">&quot;confidence&quot;</span>, <span class="dt">se.fit=</span>T)</span>
<span id="cb40-2"><a href="slr.html#cb40-2"></a><span class="co">## $fit</span></span>
<span id="cb40-3"><a href="slr.html#cb40-3"></a><span class="co">##        fit      lwr      upr</span></span>
<span id="cb40-4"><a href="slr.html#cb40-4"></a><span class="co">## 1 17.38487 15.83132 18.93841</span></span>
<span id="cb40-5"><a href="slr.html#cb40-5"></a><span class="co">## </span></span>
<span id="cb40-6"><a href="slr.html#cb40-6"></a><span class="co">## $se.fit</span></span>
<span id="cb40-7"><a href="slr.html#cb40-7"></a><span class="co">## [1] 0.6972406</span></span>
<span id="cb40-8"><a href="slr.html#cb40-8"></a><span class="co">## </span></span>
<span id="cb40-9"><a href="slr.html#cb40-9"></a><span class="co">## $df</span></span>
<span id="cb40-10"><a href="slr.html#cb40-10"></a><span class="co">## [1] 10</span></span>
<span id="cb40-11"><a href="slr.html#cb40-11"></a><span class="co">## </span></span>
<span id="cb40-12"><a href="slr.html#cb40-12"></a><span class="co">## $residual.scale</span></span>
<span id="cb40-13"><a href="slr.html#cb40-13"></a><span class="co">## [1] 2.33453</span></span></code></pre></div>
<p>The argument <code>se.fit=T</code> provides the SE of the mean response estimate. The estimated mean depth of all nests built at 8 degrees is 17.38 cm with a SE of 0.697 cm. We are 95% confident that the mean depth at 8 degrees is between 15.83 to 18.9 cm.</p>
<p>You can verify the computation of the SE and CI using summary stats for <code>temp</code> and the estimated parameter values from the <code>summary</code> command:
<span class="math display">\[
\hat{\mu}_{temp \mid 8} = \hat{\beta}_0 + \hat{\beta}_1 (8) = 20.122 + (-0.342 )(8) = 17.385
\]</span>
<span class="math display">\[
SE(\hat{\mu}_{depth \mid 8}) = \hat{\sigma} \sqrt{\dfrac{1}{n} + \dfrac{(x_0 - \bar{x})^2}{(n-1)s^2_x}} = 2.335 \sqrt{\dfrac{1}{12} + \dfrac{(8-11)^2}{(12-1)11.809^2}} = 0.6972
\]</span></p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="slr.html#cb41-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">nrow</span>(wpdata)</span>
<span id="cb41-2"><a href="slr.html#cb41-2"></a><span class="co">## [1] 12</span></span>
<span id="cb41-3"><a href="slr.html#cb41-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">mean</span>(wpdata<span class="op">$</span>temp)</span>
<span id="cb41-4"><a href="slr.html#cb41-4"></a><span class="co">## [1] 11</span></span>
<span id="cb41-5"><a href="slr.html#cb41-5"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">sd</span>(wpdata<span class="op">$</span>temp)</span>
<span id="cb41-6"><a href="slr.html#cb41-6"></a><span class="co">## [1] 11.80909</span></span>
<span id="cb41-7"><a href="slr.html#cb41-7"></a><span class="op">&gt;</span><span class="st"> </span>mn.est.se &lt;-<span class="st"> </span><span class="fl">2.33453</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">12</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">8-11</span>)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>((<span class="dv">12-1</span>)<span class="op">*</span><span class="fl">11.80909</span><span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb41-8"><a href="slr.html#cb41-8"></a><span class="op">&gt;</span><span class="st"> </span>mn.est.se</span>
<span id="cb41-9"><a href="slr.html#cb41-9"></a><span class="co">## [1] 0.6972407</span></span>
<span id="cb41-10"><a href="slr.html#cb41-10"></a><span class="op">&gt;</span><span class="st"> </span>mn.est &lt;-<span class="st"> </span><span class="fl">20.12228</span> <span class="fl">-0.34218</span><span class="op">*</span><span class="dv">8</span></span>
<span id="cb41-11"><a href="slr.html#cb41-11"></a><span class="op">&gt;</span><span class="st"> </span>mn.est</span>
<span id="cb41-12"><a href="slr.html#cb41-12"></a><span class="co">## [1] 17.38484</span></span>
<span id="cb41-13"><a href="slr.html#cb41-13"></a><span class="op">&gt;</span><span class="st"> </span>mn.est <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">*</span><span class="kw">qt</span>(.<span class="dv">975</span>,<span class="dv">10</span>)<span class="op">*</span>mn.est.se</span>
<span id="cb41-14"><a href="slr.html#cb41-14"></a><span class="co">## [1] 15.83129 18.93839</span></span></code></pre></div>
<p>You can also include more than one predictor value temp in this function:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="slr.html#cb42-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">predict</span>(wood.lm, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">temp=</span><span class="kw">c</span>(<span class="dv">8</span>,<span class="dv">20</span>)), <span class="dt">interval =</span> <span class="st">&quot;confidence&quot;</span>, <span class="dt">se.fit=</span>T)</span>
<span id="cb42-2"><a href="slr.html#cb42-2"></a><span class="co">## $fit</span></span>
<span id="cb42-3"><a href="slr.html#cb42-3"></a><span class="co">##        fit      lwr      upr</span></span>
<span id="cb42-4"><a href="slr.html#cb42-4"></a><span class="co">## 1 17.38487 15.83132 18.93841</span></span>
<span id="cb42-5"><a href="slr.html#cb42-5"></a><span class="co">## 2 13.27874 11.35950 15.19798</span></span>
<span id="cb42-6"><a href="slr.html#cb42-6"></a><span class="co">## </span></span>
<span id="cb42-7"><a href="slr.html#cb42-7"></a><span class="co">## $se.fit</span></span>
<span id="cb42-8"><a href="slr.html#cb42-8"></a><span class="co">##         1         2 </span></span>
<span id="cb42-9"><a href="slr.html#cb42-9"></a><span class="co">## 0.6972406 0.8613639 </span></span>
<span id="cb42-10"><a href="slr.html#cb42-10"></a><span class="co">## </span></span>
<span id="cb42-11"><a href="slr.html#cb42-11"></a><span class="co">## $df</span></span>
<span id="cb42-12"><a href="slr.html#cb42-12"></a><span class="co">## [1] 10</span></span>
<span id="cb42-13"><a href="slr.html#cb42-13"></a><span class="co">## </span></span>
<span id="cb42-14"><a href="slr.html#cb42-14"></a><span class="co">## $residual.scale</span></span>
<span id="cb42-15"><a href="slr.html#cb42-15"></a><span class="co">## [1] 2.33453</span></span></code></pre></div>
<p>We can get a 95% prediction interval for the depth of one depth constructed at 8 degrees Celsius <span class="math inline">\(pred_{depth \mid temp=8}\)</span> with the <code>predict</code> command with interval type <code>prediction</code> specified:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="slr.html#cb43-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">predict</span>(wood.lm, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">temp=</span><span class="dv">8</span>), <span class="dt">interval =</span> <span class="st">&quot;prediction&quot;</span>)</span>
<span id="cb43-2"><a href="slr.html#cb43-2"></a><span class="co">##        fit      lwr      upr</span></span>
<span id="cb43-3"><a href="slr.html#cb43-3"></a><span class="co">## 1 17.38487 11.95617 22.81356</span></span></code></pre></div>
<p>We are 95% confident that a new nest built at 8 degrees will have a depth between 11.96 to 22.81 cm.</p>
<p>R does not give us the SE for prediction <span class="math inline">\(SE(pred(Y \mid x_0)) = \sqrt{\hat{\sigma}^2 + SE(\hat{\mu})^2}\)</span> so we need to compute it by hand if we want its value:
<span class="math display">\[
SE(pred_{depth \mid 8}) = \sqrt{\hat{\sigma}^2 + SE(\hat{\mu})^2} =  \sqrt{2.335^2 + 0.6972^2} = 2.436
\]</span></p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="slr.html#cb44-1"></a><span class="op">&gt;</span><span class="st"> </span>se.pred &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="fl">2.33453</span><span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.6972406</span><span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb44-2"><a href="slr.html#cb44-2"></a><span class="op">&gt;</span><span class="st"> </span>se.pred</span>
<span id="cb44-3"><a href="slr.html#cb44-3"></a><span class="co">## [1] 2.436427</span></span></code></pre></div>
<p>The predicted depth of one nest build at 8 degress is 17.38 cm with a SE of 2.44 cm. The 95% prediction interval produced above can be verified as follows:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="slr.html#cb45-1"></a><span class="op">&gt;</span><span class="st"> </span>yhat &lt;-<span class="st">  </span><span class="fl">20.12228</span> <span class="fl">-0.34218</span><span class="op">*</span><span class="dv">8</span></span>
<span id="cb45-2"><a href="slr.html#cb45-2"></a><span class="op">&gt;</span><span class="st"> </span>yhat</span>
<span id="cb45-3"><a href="slr.html#cb45-3"></a><span class="co">## [1] 17.38484</span></span>
<span id="cb45-4"><a href="slr.html#cb45-4"></a><span class="op">&gt;</span><span class="st"> </span>yhat <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="op">*</span><span class="kw">qt</span>(.<span class="dv">975</span>,<span class="dv">10</span>)<span class="op">*</span>se.pred</span>
<span id="cb45-5"><a href="slr.html#cb45-5"></a><span class="co">## [1] 11.95614 22.81354</span></span></code></pre></div>
</div>
<div id="adding-confidence-bands-to-a-scatterplot" class="section level3">
<h3><span class="header-section-number">2.7.8</span> Adding confidence bands to a scatterplot</h3>
<p>The <code>geom_smooth</code> function in <code>ggplot2</code> adds a 95% confidence interval for <span class="math inline">\(\mu_{y \mid x}\)</span> around the estimated mean line:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="slr.html#cb46-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(wpdata, <span class="kw">aes</span>(<span class="dt">x=</span>temp, <span class="dt">y =</span> depth)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb46-2"><a href="slr.html#cb46-2"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb46-3"><a href="slr.html#cb46-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb46-4"><a href="slr.html#cb46-4"></a><span class="op">+</span><span class="st">   </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;air temperature (C)&quot;</span>, <span class="dt">y=</span> <span class="st">&quot;nest depth (cm)&quot;</span>, <span class="dt">title=</span> <span class="st">&quot;woodpeckers scatterplot with mean confidence interval&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<p>Adding prediction interval bands takes slightly more work. First, create a new version of the data set that includes prediction intervals for each case in the data:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="slr.html#cb47-1"></a><span class="op">&gt;</span><span class="st"> </span>wpdata.pred &lt;-<span class="st"> </span><span class="kw">data.frame</span>(wpdata, <span class="kw">predict</span>(wood.lm, <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>))</span>
<span id="cb47-2"><a href="slr.html#cb47-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">head</span>(wpdata.pred)</span>
<span id="cb47-3"><a href="slr.html#cb47-3"></a><span class="co">##   temp depth      fit      lwr      upr</span></span>
<span id="cb47-4"><a href="slr.html#cb47-4"></a><span class="co">## 1   -6  21.1 22.17535 16.30939 28.04131</span></span>
<span id="cb47-5"><a href="slr.html#cb47-5"></a><span class="co">## 2   -3  26.0 21.14882 15.42438 26.87325</span></span>
<span id="cb47-6"><a href="slr.html#cb47-6"></a><span class="co">## 3   -2  18.0 20.80664 15.12396 26.48932</span></span>
<span id="cb47-7"><a href="slr.html#cb47-7"></a><span class="co">## 4    1  19.2 19.78011 14.20554 25.35468</span></span>
<span id="cb47-8"><a href="slr.html#cb47-8"></a><span class="co">## 5    6  16.9 18.06922 12.61459 23.52385</span></span>
<span id="cb47-9"><a href="slr.html#cb47-9"></a><span class="co">## 6   10  18.1 16.70051 11.28483 22.11620</span></span></code></pre></div>
<p>Then add a <code>geom_ribbon</code> layer to the previous plot, with <code>ymin</code> and <code>ymax</code> determined by the prediction interval’s lower (<code>lwr</code>) and upper (<code>upr</code>) bounds. The <code>fill</code> arguments in both layers below are not really needed, but they are used here to provide a legend label for the plot:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="slr.html#cb48-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(wpdata.pred, <span class="kw">aes</span>(<span class="dt">x=</span>temp, <span class="dt">y =</span> depth)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb48-2"><a href="slr.html#cb48-2"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb48-3"><a href="slr.html#cb48-3"></a><span class="op">+</span><span class="st">     </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">x=</span>temp, <span class="dt">ymin =</span> lwr, <span class="dt">ymax =</span> upr, <span class="dt">fill =</span> <span class="st">&quot;prediction&quot;</span>), <span class="dt">alpha =</span> <span class="fl">.1</span>) <span class="op">+</span></span>
<span id="cb48-4"><a href="slr.html#cb48-4"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="kw">aes</span>(<span class="dt">fill =</span> <span class="st">&quot;confidence&quot;</span>), <span class="dt">alpha =</span> <span class="fl">.4</span>) <span class="op">+</span></span>
<span id="cb48-5"><a href="slr.html#cb48-5"></a><span class="op">+</span><span class="st">   </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;air temperature (C)&quot;</span>, <span class="dt">y=</span> <span class="st">&quot;nest depth (cm)&quot;</span>, </span>
<span id="cb48-6"><a href="slr.html#cb48-6"></a><span class="op">+</span><span class="st">        </span><span class="dt">title=</span> <span class="st">&quot;woodpeckers scatterplot&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;Type&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
</div>
<div id="tools-for-displaying-your-model" class="section level3">
<h3><span class="header-section-number">2.7.9</span> Tools for displaying your model</h3>
<p>As described in the Formatting Tables in Markdown (Section <a href="markdown.html#markdown-tables">D.5</a>), you can use the package <code>stargazer</code> to create a nice table of model results in your pdf. The entire R chunk to do this in a <code>pdf</code> doc format is shown below (but not evaluated in this html book). You will need to add the R chunk option <code>results='asis'</code> to get the table formatted correctly. I also include the <code>message=FALSE</code> option in the chunk below that runs the library command to suppress the automatic message created when running the <code>library</code> command with <code>stargazer</code>.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode markdown"><code class="sourceCode markdown"><span id="cb49-1"><a href="slr.html#cb49-1"></a><span class="bn">```{r, results=&#39;asis&#39;, message=FALSE}</span></span>
<span id="cb49-2"><a href="slr.html#cb49-2"></a><span class="bn">library(stargazer)</span></span>
<span id="cb49-3"><a href="slr.html#cb49-3"></a><span class="bn">stargazer(wood.lm, header=FALSE, single.row = TRUE, title = &quot;SLR of depth on temp&quot;)</span></span>
<span id="cb49-4"><a href="slr.html#cb49-4"></a><span class="bn">```</span></span></code></pre></div>
<p>````</p>
<p>The <code>kable</code> function (from the <code>knitr</code> package) works well in all output environments (e.g. pdf, html, word). The input to this function needs to be a data frame, so we can use the <code>tidy</code> version of our model summary:</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="slr.html#cb50-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(knitr)</span>
<span id="cb50-2"><a href="slr.html#cb50-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">kable</span>(<span class="kw">tidy</span>(wood.lm, <span class="dt">conf.int =</span> <span class="ot">TRUE</span>), <span class="dt">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">20.122</td>
<td align="right">0.94</td>
<td align="right">21.401</td>
<td align="right">0</td>
<td align="right">18.027</td>
<td align="right">22.217</td>
</tr>
<tr class="even">
<td align="left">temp</td>
<td align="right">-0.342</td>
<td align="right">0.06</td>
<td align="right">-5.741</td>
<td align="right">0</td>
<td align="right">-0.475</td>
<td align="right">-0.209</td>
</tr>
</tbody>
</table>
<hr />
</div>
</div>
<div id="slr-assump" class="section level2">
<h2><span class="header-section-number">2.8</span> Checking model assumptions and fit</h2>
<p>Recall the SLR model assumptions from <a href="slr.html#slr-model">2.2</a>:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i \ \ \ \ \ \epsilon_i \sim N(0, \sigma)
\]</span></p>
<ul>
<li><strong>Linearity:</strong> The mean response varies linearly with <span class="math inline">\(x\)</span>.</li>
<li><strong>Constant SD:</strong> <span class="math inline">\(SD(Y\mid x)=\sigma\)</span> describes the SD of <span class="math inline">\(Y\)</span>’s in the population around a given mean value <span class="math inline">\(\mu_{y\mid x}\)</span>. An <strong>equivalent</strong> statement of this assumption is that the model <em>errors</em> should not be associated with <span class="math inline">\(x\)</span>.</li>
<li><strong>Normality:</strong> The shape of population response values around <span class="math inline">\(\mu_{y\mid x}\)</span> is described by a normal distribution model.<br />
</li>
<li><strong>Indepedence:</strong> Given a predictor value of <span class="math inline">\(x\)</span>, all responses <span class="math inline">\(Y\)</span> occur independently of each other. An <strong>equivalent</strong> statement of this assumption is that the model <em>errors</em> are independent.</li>
</ul>
<div id="residuals" class="section level3">
<h3><span class="header-section-number">2.8.1</span> Residuals</h3>
<p><strong>If</strong> all four model assumptions are met, then our model errors <span class="math inline">\(\epsilon_i\)</span>’s will be independent and distributed like <span class="math inline">\(N(0,\sigma)\)</span>. Now we can’t actually “see” the model errors unless we know the true parameter values in the population since
<span class="math display">\[
\epsilon_i = y_i - (\beta_0 + \beta_1 x_i)
\]</span></p>
<p>The closest thing we have to the model errors are the fitted model residuals computed using the <strong>estimated</strong> model parameters:
<span class="math display">\[
r_i = y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i)
\]</span>
Residuals for a fitted model are a <strong>diagnostic</strong> tool to help check whether a model fit to data seems to match the true model form that generated the data.</p>
</div>
<div id="residual-plot-linearity-and-constant-variance" class="section level3">
<h3><span class="header-section-number">2.8.2</span> Residual plot: linearity and constant variance</h3>
<p>A <strong>residual</strong> plot is constructed by plotting <span class="math inline">\(r_i\)</span> (y-axis) against <span class="math inline">\(x_i\)</span> (x-axis). A horizontal reference line at <span class="math inline">\(y=0\)</span> is usually added (since the mean residual value is always 0).</p>
<ul>
<li><strong>Linearity</strong>: This assumption is met if, at each x-value, you see similar scatter of points (residuals) above and below the 0-reference line.</li>
<li><strong>Constant variance</strong>: This assumption is met if you see a similar magnitude of point scatter around the 0-reference line as you move along the x-axis.</li>
</ul>
<p>A residual plot that meets both these conditions is called a <strong>null</strong> plot.</p>
<p>Watch out for</p>
<ul>
<li><strong>curvature</strong> which suggests the mean function relating <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> may not be linear</li>
<li><strong>nonconstant variation</strong> which is seem in “fan” shaped plots</li>
<li><strong>outliers</strong> which can have a large influence on the fitted model</li>
</ul>
<div id="example-residual-plot" class="section level4">
<h4><span class="header-section-number">2.8.2.1</span> Example: Residual plot</h4>
<p>Let’s revisit the woodpecker nesting depth model and use the <code>broom</code> package to add residuals to the <code>wpdata</code> data frame (Section <a href="slr.html#slr-broom">2.7.6</a>):</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="slr.html#cb51-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="co"># model fit above in Section 2.7 example</span></span>
<span id="cb51-2"><a href="slr.html#cb51-2"></a><span class="er">&gt;</span><span class="st"> </span>wpdata&lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://people.carleton.edu/~kstclair/data/woodpeckers.csv&quot;</span>)</span>
<span id="cb51-3"><a href="slr.html#cb51-3"></a><span class="op">&gt;</span><span class="st"> </span>wood.lm&lt;-<span class="st"> </span><span class="kw">lm</span>(depth<span class="op">~</span>temp, <span class="dt">data=</span>wpdata)</span>
<span id="cb51-4"><a href="slr.html#cb51-4"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(broom)</span>
<span id="cb51-5"><a href="slr.html#cb51-5"></a><span class="op">&gt;</span><span class="st"> </span>wpdata.aug &lt;-<span class="st"> </span><span class="kw">augment</span>(wood.lm)</span>
<span id="cb51-6"><a href="slr.html#cb51-6"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">head</span>(wpdata.aug)</span>
<span id="cb51-7"><a href="slr.html#cb51-7"></a><span class="co">## # A tibble: 6 x 9</span></span>
<span id="cb51-8"><a href="slr.html#cb51-8"></a><span class="co">##   depth  temp .fitted .se.fit .resid   .hat .sigma .cooksd .std.resid</span></span>
<span id="cb51-9"><a href="slr.html#cb51-9"></a><span class="co">##   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;</span></span>
<span id="cb51-10"><a href="slr.html#cb51-10"></a><span class="co">## 1  21.1    -6    22.2   1.22  -1.08  0.272    2.42 0.0544      -0.540</span></span>
<span id="cb51-11"><a href="slr.html#cb51-11"></a><span class="co">## 2  26      -3    21.1   1.07   4.85  0.211    1.66 0.732        2.34 </span></span>
<span id="cb51-12"><a href="slr.html#cb51-12"></a><span class="co">## 3  18      -2    20.8   1.03  -2.81  0.194    2.23 0.215       -1.34 </span></span>
<span id="cb51-13"><a href="slr.html#cb51-13"></a><span class="co">## 4  19.2     1    19.8   0.900 -0.580 0.149    2.45 0.00632     -0.269</span></span>
<span id="cb51-14"><a href="slr.html#cb51-14"></a><span class="co">## 5  16.9     6    18.1   0.737 -1.17  0.0996   2.43 0.0154      -0.528</span></span>
<span id="cb51-15"><a href="slr.html#cb51-15"></a><span class="co">## 6  18.1    10    16.7   0.677  1.40  0.0840   2.41 0.0180       0.626</span></span></code></pre></div>
<p>The residual plot will put the predictor <code>temp</code> on the x-axis and <code>.resid</code> on the y-axis:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="slr.html#cb52-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(ggplot2)</span>
<span id="cb52-2"><a href="slr.html#cb52-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(wpdata.aug, <span class="kw">aes</span>(<span class="dt">x =</span> temp, <span class="dt">y =</span> .resid)) <span class="op">+</span></span>
<span id="cb52-3"><a href="slr.html#cb52-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_point</span>()  <span class="op">+</span></span>
<span id="cb52-4"><a href="slr.html#cb52-4"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">linetype=</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<p>Don’t forget to use the augmented data frame <code>wpdata.aug</code> that contains the residuals. The layer <code>geom_hline</code> adds the horizontal reference line at 0.</p>
<p><strong>Interpretation:</strong> There are no majors trends seen in this residual plot. Generally, it is hard to prove or disprove model assumptions when we only observe 12 data points!</p>
</div>
</div>
<div id="slr-normality" class="section level3">
<h3><span class="header-section-number">2.8.3</span> Residual normal QQ plot</h3>
<p>A <strong>normal QQ plot</strong> for a variable plots observed <strong>q</strong>uartiles against the theoretical <strong>q</strong>uartiles from a normal model. If these points follow a line then the data is approximately normal. Here is a general guide for interpreting non-linear trends that indicate a non-normal distribution:</p>
<ul>
<li>Concave up: the distribution is right skewed</li>
<li>Concave down: the distribution is left skewed</li>
<li>S-shaped: the distribution is symmetric but the tails are either too short (not enough variation) or too long (too much variation) to be normally distributed.</li>
<li>More help! Check out <a href="https://seankross.com/2016/02/29/A-Q-Q-Plot-Dissection-Kit.html">this website</a> for a deeper discussion of the interpretation of normal QQ plots</li>
</ul>
<p>We can check the <strong>normality assumption</strong> by plotting residuals with a normal QQ plot. You can also use a histogram of residuals to help interpret the normal QQ plot.</p>
<div id="example-residual-normal-qq-plot" class="section level4">
<h4><span class="header-section-number">2.8.3.1</span> Example: Residual normal QQ plot</h4>
<p>Back to the augmented woodpecker data set. A histogram of the residuals shows a slightly right skewed distribution.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="slr.html#cb53-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">hist</span>(wpdata.aug<span class="op">$</span>.resid)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<p>A quick way to get a normal QQ plot of residuals is to plug the <code>lm</code> object into the <code>plot</code> command and request plot number 2:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="slr.html#cb54-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">plot</span>(wood.lm, <span class="dt">which =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<p>Alternatively, you could use a <code>ggplot</code>. The aesthetic used for a QQ plot in a <code>ggplot</code> is <code>sample = variable</code>, then <code>geom_qq</code> and <code>geom_qq_line</code> are the layers used:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="slr.html#cb55-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(wpdata.aug, <span class="kw">aes</span>(<span class="dt">sample =</span> .resid)) <span class="op">+</span></span>
<span id="cb55-2"><a href="slr.html#cb55-2"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_qq</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb55-3"><a href="slr.html#cb55-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_qq_line</span>()</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<p><strong>Interpretation:</strong> The QQ plot also suggests a slightly longer right tail because it is (sort of) concave up. But, the QQ plot also clearly shows that this feature could just be due to two cases with residual values that are slightly higher than all others. Again, because there are only 12 data points these two cases could just be due to chance and we can conclude that there aren’t any strong indications of a non-normal distribution.</p>
</div>
</div>
<div id="slr-indep" class="section level3">
<h3><span class="header-section-number">2.8.4</span> Independence</h3>
<p>Independence of errors is probably the hardest assumption to check because it often depends on how the data was collected. Two common scenarios that lead to data that violates this assumption are</p>
<ul>
<li><strong>temporal correlation:</strong> This means correlation of errors because measurements were collected over time. Responses (and errors) measured close in time are more likely to be similar in value that responses measured further apart in time. For example, daily temperature readings in Northfield are temporally correlated.</li>
<li><strong>spatial correlation:</strong> This means correlation of errors because measurements were collected over a spatial region Responses (and errors) measured close together in space are more likely to be similar in value that responses measured further apart in space. For example, home values a sample of houses in St. Paul are likely spatially correlated since the value of a house is likely more similar to it’s neighbor than to a house across town.</li>
</ul>
<p>One method of checking for these two types of dependence is to plot the model residuals <span class="math inline">\(r_i\)</span> (y-axis) against a variable that measures, or is associated, with time or space. For the time example, plot residuals against day of the year. For the spatial example, plot residuals against a categorical “neighborhood” variable.</p>
</div>
<div id="slr-robust" class="section level3">
<h3><span class="header-section-number">2.8.5</span> Robustness against violations</h3>
<p><strong>Robustness</strong> of a statistical method means the conclusions we make using the method aren’t all that senstive to assumptions used to construct the method. Can we trust our SLR model inferences if a model assumption is violated?</p>
<p>Inference about <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\mu_{y \mid x}\)</span> from a SLR model are only robust against violations of the normality assumption. If <span class="math inline">\(n\)</span> is large enough, then the Central Limit Theorem tells us that t-tests and t-CIs are still accurate.</p>
<p>SLR modeling is <strong>not</strong> robust against any other violations:</p>
<ul>
<li><strong>Linearity:</strong> If your fitted mean model doesn’t match the form of the true mean then you will get incorrect inferences about predictor effects, mean responses, predicted responses, etc. Even your estimated model SD will be wrong!</li>
<li><strong>Constant variance and independence:</strong> If violated, the SE’s produced by the SLR model fit will not accuractely reflect the true uncertainty in our estimated parameters or predictions.</li>
<li><strong>Normality for prediction</strong> If the normality assumption is violated, then our prediction intervals will not capture the value of a new response “95% of the time”. (There is no CLT and “large n” to help us here when we are trying to predict <em>one</em> response!)</li>
</ul>
</div>
<div id="fixes-to-violations" class="section level3">
<h3><span class="header-section-number">2.8.6</span> “Fixes” to violations</h3>
<p>Here are some suggestions if a particular assumption is violated. The first part to consider “fixing” is linearity. If the mean function is not correctly specified then that will likely cause the other assumptions to not hold.</p>
<ul>
<li><strong>Linearity:</strong> transform one or both variables to a different scale (e.g. logarithm, square root, reciprocal), modify the mean function (e.g. add a quadratic term), try non-linear regression</li>
<li><strong>Constant variance:</strong> tranform the response variable, weighted regression</li>
<li><strong>Normality:</strong> transform the response variable</li>
<li><strong>Independence:</strong> add more predictors, use a model with correlated errors (e.g. mixed effects, time series, spatial, etc)</li>
</ul>
<hr />
</div>
</div>
<div id="slr-example2" class="section level2">
<h2><span class="header-section-number">2.9</span> Example: SLR assumptions (day 4/5)</h2>
<div id="drug-offender-sentences" class="section level3">
<h3><span class="header-section-number">2.9.1</span> Drug offender sentences</h3>
<p>The data set <code>DrugOffenses2.csv</code> contains data on 24,011 individuals convicted on federal drug charges during 2013 and 2014. We will subset these individuals to look only at cases given non-life prison sentences (<code>sentence2 &gt; 0</code>), then look at the SLR of an individual’s sentence length (<code>sent.nonlife</code>) in months against their <a href="https://en.wikipedia.org/wiki/United_States_Federal_Sentencing_Guidelines#Criminal_history">crimal history points</a> (`CRIMPTS).</p>
<div id="basic-eda-shows-that-both-sentencing-and-points-variables-are-right-skewed-and-there-are-non-responses-in-each-variable." class="section level4">
<h4><span class="header-section-number">2.9.1.1</span> Basic EDA shows that both sentencing and points variables are right skewed, and there are non-responses in each variable.</h4>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="slr.html#cb56-1"></a><span class="op">&gt;</span><span class="st"> </span>drug &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://people.carleton.edu/~kstclair/data/DrugOffenses2.csv&quot;</span>)</span>
<span id="cb56-2"><a href="slr.html#cb56-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">dim</span>(drug)</span>
<span id="cb56-3"><a href="slr.html#cb56-3"></a><span class="co">## [1] 24011    55</span></span>
<span id="cb56-4"><a href="slr.html#cb56-4"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(dplyr)</span>
<span id="cb56-5"><a href="slr.html#cb56-5"></a><span class="op">&gt;</span><span class="st"> </span>drugPrison &lt;-<span class="st"> </span><span class="kw">filter</span>(drug, sentence2 <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)</span>
<span id="cb56-6"><a href="slr.html#cb56-6"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb56-7"><a href="slr.html#cb56-7"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">hist</span>(drugPrison<span class="op">$</span>CRIMPTS, <span class="dt">main=</span><span class="st">&quot;criminal points&quot;</span>)</span>
<span id="cb56-8"><a href="slr.html#cb56-8"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">hist</span>(drugPrison<span class="op">$</span>sent.nolife, <span class="dt">main=</span><span class="st">&quot;sentence&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-55-1.png" width="480" /></p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="slr.html#cb57-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb57-2"><a href="slr.html#cb57-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(drugPrison<span class="op">$</span>CRIMPTS)</span>
<span id="cb57-3"><a href="slr.html#cb57-3"></a><span class="co">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s </span></span>
<span id="cb57-4"><a href="slr.html#cb57-4"></a><span class="co">##    0.00    0.00    2.00    3.51    5.00   42.00    2012</span></span>
<span id="cb57-5"><a href="slr.html#cb57-5"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(drugPrison<span class="op">$</span>sent.nolife)</span>
<span id="cb57-6"><a href="slr.html#cb57-6"></a><span class="co">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s </span></span>
<span id="cb57-7"><a href="slr.html#cb57-7"></a><span class="co">##    0.03   21.00   48.00   65.41   87.00  960.00      45</span></span></code></pre></div>
</div>
<div id="usual-scatterplot" class="section level4">
<h4><span class="header-section-number">2.9.1.2</span> Usual scatterplot</h4>
<p>The usual scatterplot suffers from <strong>overplotting</strong> when we have a large data sets or datasets with very discrete variables. It is hard to see where the majority of cases are in this plot and difficult to discern any trend in the response as we change the predictor variable.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="slr.html#cb58-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(ggplot2)</span>
<span id="cb58-2"><a href="slr.html#cb58-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(drugPrison, <span class="kw">aes</span>(<span class="dt">x=</span>CRIMPTS, <span class="dt">y=</span>sent.nolife)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb58-3"><a href="slr.html#cb58-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_point</span>()  <span class="op">+</span><span class="st"> </span></span>
<span id="cb58-4"><a href="slr.html#cb58-4"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-56-1.png" width="480" /></p>
</div>
<div id="jittering-and-a-loess-smoother" class="section level4">
<h4><span class="header-section-number">2.9.1.3</span> Jittering and a <em>loess</em> smoother</h4>
<p>Two ways to minimize the effect of overplotting are to</p>
<ul>
<li>“jitter” the plotted points by adding a small amount of random noise. This can be done by using <code>geom_jitter</code> instead of <code>geom_point</code></li>
<li>use a more transparent plotting symbol. Then when points are overlapping, we will see darker colors which indicate a higher density of observations in that region of the graph. We do this by adding <code>alpha=</code> to the <code>geom_jitter</code> and make the <code>alpha</code> value less than 1 (smaller values mean more transparent points).</li>
</ul>
<p>We will also use a <code>loess</code> smoother line to the scatterplot to help reveal the true trend in sentencing as the point history changes. A smoother is a non-parameteric way to locally “average” the response as we change the predictor value. (Non-parametric means this isn’t a parameterized curve like a line or quadratic function, which means we don’t end up with a nice formula for <span class="math inline">\(y\)</span> given <span class="math inline">\(x\)</span> from such a model.) We fit the <code>loess</code> model to our plot by adding another layer of <code>geom_smooth(method = "loess", se=FALSE)</code>. In the commands below, the <code>aes(color=)</code> just adds a color legend to the plot.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="slr.html#cb59-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(drugPrison, <span class="kw">aes</span>(<span class="dt">x=</span>CRIMPTS, <span class="dt">y=</span>sent.nolife)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb59-2"><a href="slr.html#cb59-2"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_jitter</span>(<span class="dt">alpha =</span> <span class="fl">.2</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb59-3"><a href="slr.html#cb59-3"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="kw">aes</span>(<span class="dt">color=</span><span class="st">&quot;lm&quot;</span>)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb59-4"><a href="slr.html#cb59-4"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;loess&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="kw">aes</span>(<span class="dt">color=</span><span class="st">&quot;smoother&quot;</span>))</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-57-1.png" width="480" /></p>
</div>
<div id="residual-plot-and-loess-smoother" class="section level4">
<h4><span class="header-section-number">2.9.1.4</span> Residual plot and <code>loess</code> smoother</h4>
<p>The scatterplot and loess smoother suggest there is slight quadratic relationship between points history and sentence length, with a positive trend up to about 20 points and a negative trend after. We can see this too in the residual plot with loess smoother added. The variation around the regression line seems fairly similar for any points value up to about 20 points, and after 20 points there are fewer cases which seem to be slightly less variable. (Note that “similar variation” means the spread around the line is of similar <em>magnitude for any value of x</em>, not that the spread around the line is <em>symmetric</em>. As we see next, the spread around the line (residuals) is skewed right.)</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="slr.html#cb60-1"></a><span class="op">&gt;</span><span class="st"> </span>drug.lm &lt;-<span class="st"> </span><span class="kw">lm</span>(sent.nolife <span class="op">~</span><span class="st"> </span>CRIMPTS, <span class="dt">data=</span>drugPrison)</span>
<span id="cb60-2"><a href="slr.html#cb60-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(broom)</span>
<span id="cb60-3"><a href="slr.html#cb60-3"></a><span class="op">&gt;</span><span class="st"> </span>drugPrison.aug &lt;-<span class="st"> </span><span class="kw">augment</span>(drug.lm)</span>
<span id="cb60-4"><a href="slr.html#cb60-4"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(drugPrison.aug, <span class="kw">aes</span>(<span class="dt">x=</span>CRIMPTS, <span class="dt">y=</span>.resid)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb60-5"><a href="slr.html#cb60-5"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_jitter</span>(<span class="dt">alpha =</span> <span class="fl">.2</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb60-6"><a href="slr.html#cb60-6"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="kw">aes</span>(<span class="dt">color=</span><span class="st">&quot;lm&quot;</span>)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb60-7"><a href="slr.html#cb60-7"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;loess&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="kw">aes</span>(<span class="dt">color=</span><span class="st">&quot;smoother&quot;</span>))</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-58-1.png" width="480" /></p>
</div>
<div id="checking-normality" class="section level4">
<h4><span class="header-section-number">2.9.1.5</span> Checking normality</h4>
<p>The residuals for this model are not normally distributed, there is a strong skew to the right. <strong>If</strong> the linear model fit the trend of the data, this non-normality would <strong>not</strong> be a concern for inference about the mean parameters <span class="math inline">\(\beta\)</span>. It would only be a concern if we wanted to <strong>predict</strong> one individual’s sentence length with confidence given their criminal history points.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="slr.html#cb61-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb61-2"><a href="slr.html#cb61-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">hist</span>(<span class="kw">resid</span>(drug.lm), <span class="dt">main=</span><span class="st">&quot;Histogram of residuals&quot;</span>)</span>
<span id="cb61-3"><a href="slr.html#cb61-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">plot</span>(drug.lm, <span class="dt">which =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-59-1.png" width="480" /></p>
</div>
</div>
<div id="case-study-15.2---global-warming" class="section level3">
<h3><span class="header-section-number">2.9.2</span> Case study 15.2 - Global Warming</h3>
<p>Let’s look at the regression of global mean temperature deviation (Celsius) on year (1850 through 2010). The scatterplot suggests a curved relationship with time. Temperature deviation is the mean yearly temp minus the mean temp from all 161 years.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="slr.html#cb62-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(Sleuth3)</span>
<span id="cb62-2"><a href="slr.html#cb62-2"></a><span class="op">&gt;</span><span class="st"> </span>temps &lt;-<span class="st"> </span>case1502</span>
<span id="cb62-3"><a href="slr.html#cb62-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(temps)</span>
<span id="cb62-4"><a href="slr.html#cb62-4"></a><span class="co">##       Year       Temperature     </span></span>
<span id="cb62-5"><a href="slr.html#cb62-5"></a><span class="co">##  Min.   :1850   Min.   :-0.6060  </span></span>
<span id="cb62-6"><a href="slr.html#cb62-6"></a><span class="co">##  1st Qu.:1890   1st Qu.:-0.3000  </span></span>
<span id="cb62-7"><a href="slr.html#cb62-7"></a><span class="co">##  Median :1930   Median :-0.1740  </span></span>
<span id="cb62-8"><a href="slr.html#cb62-8"></a><span class="co">##  Mean   :1930   Mean   :-0.1153  </span></span>
<span id="cb62-9"><a href="slr.html#cb62-9"></a><span class="co">##  3rd Qu.:1970   3rd Qu.: 0.0260  </span></span>
<span id="cb62-10"><a href="slr.html#cb62-10"></a><span class="co">##  Max.   :2010   Max.   : 0.6200</span></span>
<span id="cb62-11"><a href="slr.html#cb62-11"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(temps, <span class="kw">aes</span>(<span class="dt">x =</span> Year, <span class="dt">y =</span> Temperature)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb62-12"><a href="slr.html#cb62-12"></a><span class="op">+</span><span class="st">         </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb62-13"><a href="slr.html#cb62-13"></a><span class="op">+</span><span class="st">         </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb62-14"><a href="slr.html#cb62-14"></a><span class="op">+</span><span class="st">         </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<div id="independent-residuals" class="section level4">
<h4><span class="header-section-number">2.9.2.1</span> Independent residuals?</h4>
<p>After fitting our regression of <code>Temperature</code> on <code>Year</code> and <code>Year^2</code> (due to curvature), a check of the residual plot (residuals vs. <code>Year</code>) shows no obvious signs of curvature in residuals so the quadratic mean function with time seems adequate.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="slr.html#cb63-1"></a><span class="op">&gt;</span><span class="st"> </span>temps.lm &lt;-<span class="st"> </span><span class="kw">lm</span>(Temperature <span class="op">~</span><span class="st"> </span>Year <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(Year<span class="op">^</span><span class="dv">2</span>), <span class="dt">data=</span>temps)</span>
<span id="cb63-2"><a href="slr.html#cb63-2"></a><span class="op">&gt;</span><span class="st"> </span>temps.aug &lt;-<span class="st"> </span><span class="kw">augment</span>(temps.lm)</span>
<span id="cb63-3"><a href="slr.html#cb63-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(temps.aug, <span class="kw">aes</span>(<span class="dt">x =</span> Year, <span class="dt">y =</span> .resid)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb63-4"><a href="slr.html#cb63-4"></a><span class="op">+</span><span class="st">         </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb63-5"><a href="slr.html#cb63-5"></a><span class="op">+</span><span class="st">         </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
<p>The independence assumption will be violated for this model if residuals closer in time (x) are more similar than residuals further apart in time. This is hard to see in the basic residual plot above. To see this idea better, we can look at line plot of residuals vs. time:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="slr.html#cb64-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(temps.aug, <span class="kw">aes</span>(<span class="dt">x =</span> Year, <span class="dt">y =</span> .resid)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb64-2"><a href="slr.html#cb64-2"></a><span class="op">+</span><span class="st">         </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb64-3"><a href="slr.html#cb64-3"></a><span class="op">+</span><span class="st">         </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb64-4"><a href="slr.html#cb64-4"></a><span class="op">+</span><span class="st">         </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<p>With this plot is it clear that if one year has a negative residual (lower than expected temps), the next year’s residual is often also negative. Same is true for positive residuals. This indicates that there is a temporal association in these residuals, which means that they are not indepedent. A SLR model is not appropriate for this data because the SEs will not accurately reflect the uncertainty in our estimates when independence is violated.</p>
</div>
<div id="autocorrelation" class="section level4">
<h4><span class="header-section-number">2.9.2.2</span> Autocorrelation</h4>
<p>The <strong>correlation</strong> statistic is used to assess the strength and direction of a linear relationship between two quantitative variables. The <strong>autocorrelation</strong> is used to assess how correlated values are for the <strong>same</strong> quantitative variable. Autocorrelation is computed by pairing responses by a <strong>lag</strong> amount. Lag of 1 means we are computing correlation for responses that differ by one spot in the vector of responses. For our time and temp data, this means looking at the correlation between responses that differ by a year. Lag 2 means looking at correlation between responses that differ by 2 years, and so on.</p>
<p>We can use autocorrelation to verify that residuals closer together in time are more similar than those further apart in time:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="slr.html#cb65-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">acf</span>(<span class="kw">resid</span>(temps.lm))</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-63-1.png" width="672" /></p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="slr.html#cb66-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">acf</span>(<span class="kw">resid</span>(temps.lm), <span class="dt">plot=</span><span class="ot">FALSE</span>)</span>
<span id="cb66-2"><a href="slr.html#cb66-2"></a><span class="co">## </span></span>
<span id="cb66-3"><a href="slr.html#cb66-3"></a><span class="co">## Autocorrelations of series &#39;resid(temps.lm)&#39;, by lag</span></span>
<span id="cb66-4"><a href="slr.html#cb66-4"></a><span class="co">## </span></span>
<span id="cb66-5"><a href="slr.html#cb66-5"></a><span class="co">##      0      1      2      3      4      5      6      7      8      9     10 </span></span>
<span id="cb66-6"><a href="slr.html#cb66-6"></a><span class="co">##  1.000  0.592  0.446  0.336  0.380  0.313  0.270  0.261  0.272  0.287  0.236 </span></span>
<span id="cb66-7"><a href="slr.html#cb66-7"></a><span class="co">##     11     12     13     14     15     16     17     18     19     20     21 </span></span>
<span id="cb66-8"><a href="slr.html#cb66-8"></a><span class="co">##  0.164  0.083 -0.004  0.014 -0.007 -0.067 -0.022 -0.038 -0.069 -0.065 -0.140 </span></span>
<span id="cb66-9"><a href="slr.html#cb66-9"></a><span class="co">##     22 </span></span>
<span id="cb66-10"><a href="slr.html#cb66-10"></a><span class="co">## -0.162</span></span></code></pre></div>
<p>Residuals that differ by one year have a correlation of 0.592, indicating a moderate positive correlation. This is what were able to see in the line plot above. Residuals that differ from 2-9 years have correlations between about 0.45 to 0.25. After years there is little to no autocorrelation between residuals.</p>
<hr />
</div>
</div>
</div>
<div id="slr-trans" class="section level2">
<h2><span class="header-section-number">2.10</span> Transformations</h2>
<p>Transformations of one or both variables in SLR is done to fix one, or both, of these assumption violations: linearity and constant variance. Tranformations are often explored via trial-and-error, use plots of transformed variables and residual plots from potential transformed SLR models to find the “best” SLR model. “Best” is determined by a model that <strong>most satisfies the SLR assumptions</strong>, not a model that yields the “strongest” relationship between variables. A transformation choice can also be determined from a theoretical model that we have from a specific application.</p>
<div id="transformation-choices" class="section level3">
<h3><span class="header-section-number">2.10.1</span> Transformation choices</h3>
<p>We need to look at non-linear functions of a variable. A linear transformation, like changing a measure from cm to feet would only change the numbers you see on the axes label and not the relative location of points on the plot. Common transformations to consider are the following:</p>
<ul>
<li><strong>logarithms</strong>: Any log-base can be explored but base choice will only affect how you interpret a model, not affect the linearity or constant variance assumptions. E.g. if <span class="math inline">\(\log_2(y)\)</span> vs. <span class="math inline">\(x\)</span> looks nonlinear, then <span class="math inline">\(\log_{10}(y)\)</span> vs. <span class="math inline">\(x\)</span> will also be nonlinear. Logarithms are nice because they are easily interpretable in a SLR model (more to come). In R,</li>
</ul>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="slr.html#cb67-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">log</span>(<span class="dv">2</span>)  <span class="co"># the natural log function (ln)</span></span>
<span id="cb67-2"><a href="slr.html#cb67-2"></a><span class="co">## [1] 0.6931472</span></span>
<span id="cb67-3"><a href="slr.html#cb67-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">log10</span>(<span class="dv">2</span>) <span class="co"># base 10</span></span>
<span id="cb67-4"><a href="slr.html#cb67-4"></a><span class="co">## [1] 0.30103</span></span>
<span id="cb67-5"><a href="slr.html#cb67-5"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">log2</span>(<span class="dv">2</span>)  <span class="co"># base 2</span></span>
<span id="cb67-6"><a href="slr.html#cb67-6"></a><span class="co">## [1] 1</span></span></code></pre></div>
<ul>
<li><strong>square root</strong>: A square root transformation is an “in between” no transformation and a logarithm transformation (see the Figure below)</li>
</ul>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="slr.html#cb68-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">4</span>)  <span class="co"># square root function</span></span>
<span id="cb68-2"><a href="slr.html#cb68-2"></a><span class="co">## [1] 2</span></span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-66-1.png" width="672" /></p>
</div>
<div id="transformations-in-r" class="section level3">
<h3><span class="header-section-number">2.10.2</span> Transformations in R</h3>
<p>We can visualize square root and logarithms in a<code>ggplot2</code> scatterplot by adding a layer that changes the scale of an axes. For example, <code>scale_x_sqrt()</code> will change the <code>geom_point()</code> scatterplot to a plot of <span class="math inline">\(y\)</span> aganist <span class="math inline">\(\sqrt{x}\)</span> but the axes numeric labels on the x-axis will still measure <span class="math inline">\(x\)</span>. The layer <code>scale_y_log10()</code> will convert <span class="math inline">\(y\)</span> to the base-10 logarithm. If you want a transformation that is not one of these two, then you can transform the variable in the aesthetic: <code>ggplot(data, aes(x = 1/x, y = y))</code> would plot <span class="math inline">\(y\)</span> against the reciprocal <span class="math inline">\(1/x\)</span>.</p>
<p>You can apply transformations directly in the <code>lm</code> command too, e.g. <code>lm(log(y) ~ log(x), data)</code> fits the regression of <span class="math inline">\(\log(y)\)</span> against <span class="math inline">\(\log(x)\)</span>. If a transformation involves a mathematics function (like power <code>^</code> or division <code>/</code>) on the right side of the formula symbol <code>~</code>, then you need to use the “as is” operator function <code>I()</code>. E.g. the regression of <span class="math inline">\(y\)</span> against the reciprocal <span class="math inline">\(1/x\)</span> is <code>lm(y ~ I(1/x), data)</code>.</p>
</div>
<div id="interpretation-1" class="section level3">
<h3><span class="header-section-number">2.10.3</span> Interpretation</h3>
<p>In general, models with transformed variables should be interpreted as a usual SLR but with the transformed variable scale. For example, the SLR for <span class="math inline">\(\sqrt{y}\)</span> against <span class="math inline">\(\sqrt{x}\)</span> has a mean function that looks like
<span class="math display">\[
\mu_{\sqrt{y} \mid x} = \beta_0  + \beta_1 \sqrt{x}
\]</span>
so a one unit increase in the <strong>square root</strong> of <span class="math inline">\(x\)</span> in associated with a <span class="math inline">\(\beta_1\)</span> change in the mean of the <strong>square root</strong> of <span class="math inline">\(y\)</span>.</p>
<p>Models that use logarithms have a nicer interpretation. Section <a href="slr.html#slr-logs">2.10.4</a> has more review of logarithms but the three common SLR models that use logarithms are given here.</p>
<ul>
<li><strong>Logarithmic model</strong>: The regression of <span class="math inline">\(Y\)</span> on <span class="math inline">\(\log(x)\)</span> has the mean function
<span class="math display">\[
\mu(Y \mid \log(x)) = \beta_0 + \beta_1 \log(x)
\]</span>
Multiplying <span class="math inline">\(x\)</span> by a factor <span class="math inline">\(m\)</span> is associated with a mean function change of
<span class="math display">\[
\mu(Y \mid \log(mx)) - \mu(Y \mid \log(x)) = \beta_1(\log(m) + \log(x)) - \beta_1 \log(x) = \beta_1 \log(m)
\]</span>
If <strong>base-2</strong> is used for the tranformation of <span class="math inline">\(x\)</span> then a <strong>doubling</strong> of <span class="math inline">\(x\)</span> (so <span class="math inline">\(m=2\)</span>) is associated with a change in mean <span class="math inline">\(y\)</span> of <span class="math inline">\(\beta_1 \log_2(2) = \beta_1\)</span>.</li>
<li><strong>Exponential model</strong>: The regression of <span class="math inline">\(\log(Y)\)</span> on <span class="math inline">\(x\)</span> has the mean function
<span class="math display">\[
\mu(\log(Y) \mid x) = median(\log(Y) \mid x) = \beta_0 + \beta_1 x
\]</span>
Since the median of a logged-variable equals the log of the median of the variable, we can “untransform” this model and write it in terms of the median of <span class="math inline">\(Y\)</span> (assuming here that <code>log</code> is the natural log):
<span class="math display">\[
median(Y \mid x) = e^{\log(median(Y \mid x))} = e^{median(\log(Y) \mid x)} = e^{\beta_0}e^{\beta_1 x}
\]</span>
Note that the <em>mean</em> of a logged-variable <em>does not</em> equal the log of the mean of the variable, so we can’t express the untransformed model in terms of the median of <span class="math inline">\(Y\)</span>.</li>
</ul>
<p>A one unit increase in <span class="math inline">\(x\)</span> is associated with a <span class="math inline">\(e^{\beta_1}\)</span>-factor change in the <em>median</em> function since
<span class="math display">\[
median(Y \mid x+1) = e^{\beta_0}e^{\beta_1 (x+1)} = e^{\beta_0}e^{\beta_1 x}e^{\beta_1} = median(Y \mid x) e^{\beta_1} 
\]</span>
- - <strong>Power model</strong>: The regression of <span class="math inline">\(\log(Y)\)</span> on <span class="math inline">\(\log(x)\)</span> has the mean function
<span class="math display">\[
\mu(\log(Y) \mid \log(x)) = median(\log(Y) \mid\log(x)) = \beta_0 + \beta_1 \log(x)
\]</span>
Using the same logic as the exponential model, inference on the untransformed scale of <span class="math inline">\(Y\)</span> is about the <em>median</em> of <span class="math inline">\(Y\)</span>:
<span class="math display">\[
median(Y \mid x) = e^{\log(median(Y \mid x))} = e^{median(\log(Y) \mid x)} = e^{\beta_0}e^{\beta_1 \log(x)} = e^{\beta_0}(e^{\log(x)})^{\beta_1} =  e^{\beta_0}x^{\beta_1}
\]</span></p>
<p>An m-fold (multiplicative) change in <span class="math inline">\(x\)</span> is associated with a <span class="math inline">\(m^{\beta_1}\)</span>-factor change in the <em>median</em> function since
<span class="math display">\[
median(Y \mid mx) = e^{\beta_0}e^{\beta_1 \log(mx)} = e^{\beta_0}(e^{\log(x)})^{\beta_1}(e^{\log(m)})^{\beta_1}  = median(Y \mid x) m^{\beta_1} 
\]</span></p>
</div>
<div id="slr-logs" class="section level3">
<h3><span class="header-section-number">2.10.4</span> Review: Logarithms</h3>
<p>Let <span class="math inline">\(b&gt;0\)</span> and <span class="math inline">\(x&gt;0\)</span>. The logarithm (base-<span class="math inline">\(b\)</span>) of <span class="math inline">\(x\)</span> is denoted <span class="math inline">\(\log_b(x)\)</span> and equal to
<span class="math display">\[
\log_b(x) = a
\]</span>
where <span class="math inline">\(a\)</span> tells us what power we must raise <span class="math inline">\(b\)</span> to to obtain the value <span class="math inline">\(x\)</span>:
<span class="math display">\[
b^a = x
\]</span></p>
<p>Easy examples are: <span class="math inline">\(b=2\)</span>, <span class="math inline">\(x=8\)</span> and <span class="math inline">\(a=3\)</span>,
<span class="math display">\[
\log_2(8) = 3
\]</span>
since <span class="math inline">\(2^3 = 8\)</span>. Or using base <span class="math inline">\(b=10\)</span>, then
<span class="math display">\[
\log_{10}(0.01) = -2
\]</span>
since <span class="math inline">\(10^{-2} = 0.01\)</span>.</p>
<p>Some basic facts logarithm facts are
<span class="math display">\[
\log_b(b) = 1
\]</span>
since <span class="math inline">\(b^1 = b\)</span> and
<span class="math display">\[
\log_b(1) = 0
\]</span>
since <span class="math inline">\(b^0 = 1\)</span>.</p>
<div id="interpreting-logged-variables" class="section level4">
<h4><span class="header-section-number">2.10.4.1</span> Interpreting logged variables</h4>
<p><strong>Multiplicative</strong> changes in <span class="math inline">\(x\)</span> result in <strong>additive</strong> changes in <span class="math inline">\(\log_b(x)\)</span>. If <span class="math inline">\(m&gt;0\)</span>, then
<span class="math display">\[
\log_b(mx) = \log_b(m)  + \log_b(x) 
\]</span>
For example,
<span class="math display">\[
\log_2(16) = \log_2(2\times 8) = \log_2(2) + \log_2(8) = 1 + 3 = 4
\]</span></p>
</div>
<div id="inverse-i.e.-reversing-the-log-getting-rid-of-the-log" class="section level4">
<h4><span class="header-section-number">2.10.4.2</span> Inverse (i.e. reversing the log, getting rid of the log, …)</h4>
<p>The logarithm and exponential functions are inverses of one another. This means we can “get rid” of the log by calculating <span class="math inline">\(b\)</span> raised to the logged-function:
<span class="math display">\[
b^{\log_b(x)} = x
\]</span>
This will be useful in regression when we have a linear relationship between logged-response <span class="math inline">\(y\)</span> and a set of predictors. We need to</p>
<p>For example, suppose we know that
<span class="math display">\[
\log_2(y) = 3 + 5x
\]</span>
To return this to an expression on the original (unlogged) scale of <span class="math inline">\(y\)</span>, we need take both sides raised to the base 2:
<span class="math display">\[
2^{\log_2(y)} = 2^{3 + 5x}
\]</span>
Simplifying both sides gives
<span class="math display">\[
y = 2^3 \times 2^{5x}
\]</span></p>
</div>
<div id="logarithm-practice-questions-day-6" class="section level4">
<h4><span class="header-section-number">2.10.4.3</span> Logarithm Practice Questions (day 6)</h4>
<p>Solutions are posted on the class Moodle site.</p>
<ol style="list-style-type: decimal">
<li><p>Write the following as the sum of two logarithms. Simplify as much as possible:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\log_2(2x)\)</span></li>
<li><span class="math inline">\(\log_2(0.5x)\)</span></li>
<li><span class="math inline">\(\ln(2x)\)</span> where <span class="math inline">\(\ln\)</span> is the natural log (base-<span class="math inline">\(e\)</span>)</li>
</ol></li>
<li><p>Write the following expressions in terms of <span class="math inline">\(y\)</span>, not <span class="math inline">\(\log(y)\)</span>. Simplify as much as possible:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\log_2(y) = 1 - 3x\)</span></li>
<li><span class="math inline">\(\log_{10}(y) = -2 + 0.4x\)</span></li>
<li><span class="math inline">\(\ln(y) = 1 - 3x\)</span></li>
</ol></li>
<li><p>Write the following expressions in terms of <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>, not <span class="math inline">\(\log(y)\)</span> and <span class="math inline">\(\log(x)\)</span>. Simplify as much as possible:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\log_2(y) = 1 - 3\log_2(x)\)</span></li>
<li><span class="math inline">\(\ln(y) = -2 + 0.4\ln(x)\)</span></li>
<li><span class="math inline">\(\ln(y) = 1 - 3\log_2(x)\)</span></li>
</ol></li>
<li><p>Logarithmic model: Regression of <span class="math inline">\(Y\)</span> on <span class="math inline">\(\log(x)\)</span> obtains the following estimated mean of <span class="math inline">\(Y\)</span>:
<span class="math display">\[
\hat{\mu}(Y \mid x) = 1 - 3 \log_2(x)
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>What is the change in estimated mean response if we double the value of <span class="math inline">\(x\)</span>?</li>
<li>What is the change in estimated mean response if we triple the value of <span class="math inline">\(x\)</span>?</li>
<li>What is the change in estimated mean response if we reduce the value of <span class="math inline">\(x\)</span> by 20%?</li>
</ol></li>
<li><p>Exponential model: Regression of <span class="math inline">\(\log_2(Y)\)</span> on <span class="math inline">\(x\)</span> obtains the following estimated <em>median</em> of <span class="math inline">\(Y\)</span>:
<span class="math display">\[
\hat{median}(\log_2(Y) \mid x) = -2 + 0.4x
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>Write the median in terms of <span class="math inline">\(Y\)</span> instead of <span class="math inline">\(\log_2(Y)\)</span>. Simplify as much as possible.</li>
<li>What is the multiplicative change in estimated median response if we increase <span class="math inline">\(x\)</span> by 1 unit?</li>
<li>What is the percent change in estimated median response if we increase <span class="math inline">\(x\)</span> by 1 unit?</li>
<li>What is the multiplicative change in estimated median response if we decrease <span class="math inline">\(x\)</span> by 2 units?</li>
<li>What is the percent change in estimated median response if we decrease <span class="math inline">\(x\)</span> by 2 units?</li>
</ol></li>
<li><p>Power model: Regression of <span class="math inline">\(\log_2(Y)\)</span> on <span class="math inline">\(\log_2(x)\)</span> obtains the following estimated <em>median</em> of <span class="math inline">\(Y\)</span>:
<span class="math display">\[
\hat{median}(\log_2(Y) \mid x) = 1 -3\log_2(x)
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>Write the median in terms of <span class="math inline">\(Y\)</span> and <span class="math inline">\(x\)</span> instead of <span class="math inline">\(\log\)</span>s. Simplify as much as possible.</li>
<li>What is the multiplicative change in estimated median response if we increase <span class="math inline">\(x\)</span> by 50%?</li>
<li>What is the percent change in estimated median response if we increase <span class="math inline">\(x\)</span> by 50%?</li>
<li>What is the multiplicative change in estimated median response if we reduce the value of <span class="math inline">\(x\)</span> by 20%?</li>
<li>What is the percent change in estimated median response if we reduce the value of <span class="math inline">\(x\)</span> by 20%?</li>
</ol></li>
</ol>
<hr />
</div>
</div>
</div>
<div id="examples-transformations-day-6" class="section level2">
<h2><span class="header-section-number">2.11</span> Examples: Transformations (day 6)</h2>
<p>A solution to these examples is found on the class Moodle page.</p>
<div id="cars-2004" class="section level3">
<h3><span class="header-section-number">2.11.1</span> Cars 2004</h3>
<p>This is a dataset with stats taken from 230 car makes and models from 2004.</p>
<p><strong>(1a) Is city MPG a linear function of car weight (lbs)?</strong></p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="slr.html#cb69-1"></a><span class="op">&gt;</span><span class="st"> </span>cars &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://people.carleton.edu/~kstclair/data/cars2004.csv&quot;</span>)</span>
<span id="cb69-2"><a href="slr.html#cb69-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(cars[, <span class="kw">c</span>(<span class="st">&quot;city.mpg&quot;</span>,<span class="st">&quot;weight&quot;</span>)])</span>
<span id="cb69-3"><a href="slr.html#cb69-3"></a><span class="co">##     city.mpg         weight    </span></span>
<span id="cb69-4"><a href="slr.html#cb69-4"></a><span class="co">##  Min.   :10.00   Min.   :1850  </span></span>
<span id="cb69-5"><a href="slr.html#cb69-5"></a><span class="co">##  1st Qu.:16.00   1st Qu.:3185  </span></span>
<span id="cb69-6"><a href="slr.html#cb69-6"></a><span class="co">##  Median :18.00   Median :3606  </span></span>
<span id="cb69-7"><a href="slr.html#cb69-7"></a><span class="co">##  Mean   :19.22   Mean   :3738  </span></span>
<span id="cb69-8"><a href="slr.html#cb69-8"></a><span class="co">##  3rd Qu.:21.00   3rd Qu.:4237  </span></span>
<span id="cb69-9"><a href="slr.html#cb69-9"></a><span class="co">##  Max.   :60.00   Max.   :7608</span></span>
<span id="cb69-10"><a href="slr.html#cb69-10"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(ggplot2)</span>
<span id="cb69-11"><a href="slr.html#cb69-11"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(cars, <span class="kw">aes</span>(<span class="dt">x=</span> weight, <span class="dt">y =</span> city.mpg)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb69-12"><a href="slr.html#cb69-12"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb69-13"><a href="slr.html#cb69-13"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb69-14"><a href="slr.html#cb69-14"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="dt">color=</span><span class="st">&quot;red&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb69-15"><a href="slr.html#cb69-15"></a><span class="op">+</span><span class="st">   </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&quot;City MPG vs. car weight&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-67-1.png" width="384" /></p>
<p><strong>(1b) Explore some transformations: which gives the most linear relationship?</strong>
Use layers of the type <code>scale_x_log10()</code> or <code>scale_y_sqrt()</code> to change a particular axes</p>
<p><strong>(1c) Fit the regression of 1/mpg on weight and check residuals</strong></p>
</div>
<div id="residential-energy-survey-recs" class="section level3">
<h3><span class="header-section-number">2.11.2</span> 2005 Residential Energy Survey (RECS)</h3>
<p>RECS surveys households across the US. We are treating this sample of 4,382 households as an equally-weighted sample of US households. Our goal now is to model total energy costs (<code>CostTotal</code>) as a function of the size of the housing unit (<code>SqftMeasure</code>).</p>
<p><strong>(2a) Total energy cost vs. size</strong>
With over 4,000 cases, we reduce point transparency with <code>alpha</code> to avoid overplotting. Assess the scatterplot in terms of (1) linearity, (2)constant variance, and (3) normal errors.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="slr.html#cb70-1"></a><span class="op">&gt;</span><span class="st"> </span>energy &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://people.carleton.edu/~kstclair/data/EnergySurvey.csv&quot;</span>)</span>
<span id="cb70-2"><a href="slr.html#cb70-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">dim</span>(energy)</span>
<span id="cb70-3"><a href="slr.html#cb70-3"></a><span class="co">## [1] 4382   16</span></span>
<span id="cb70-4"><a href="slr.html#cb70-4"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(energy[,<span class="kw">c</span>(<span class="st">&quot;CostTotal&quot;</span>,<span class="st">&quot;SqftMeasure&quot;</span>)])</span>
<span id="cb70-5"><a href="slr.html#cb70-5"></a><span class="co">##    CostTotal      SqftMeasure   </span></span>
<span id="cb70-6"><a href="slr.html#cb70-6"></a><span class="co">##  Min.   :   57   Min.   :  167  </span></span>
<span id="cb70-7"><a href="slr.html#cb70-7"></a><span class="co">##  1st Qu.: 1138   1st Qu.: 1056  </span></span>
<span id="cb70-8"><a href="slr.html#cb70-8"></a><span class="co">##  Median : 1673   Median : 1848  </span></span>
<span id="cb70-9"><a href="slr.html#cb70-9"></a><span class="co">##  Mean   : 1841   Mean   : 2284  </span></span>
<span id="cb70-10"><a href="slr.html#cb70-10"></a><span class="co">##  3rd Qu.: 2331   3rd Qu.: 3042  </span></span>
<span id="cb70-11"><a href="slr.html#cb70-11"></a><span class="co">##  Max.   :10346   Max.   :11383  </span></span>
<span id="cb70-12"><a href="slr.html#cb70-12"></a><span class="co">##  NA&#39;s   :1</span></span>
<span id="cb70-13"><a href="slr.html#cb70-13"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(ggplot2)</span>
<span id="cb70-14"><a href="slr.html#cb70-14"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(energy, <span class="kw">aes</span>(<span class="dt">x =</span> SqftMeasure, <span class="dt">y =</span> CostTotal)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb70-15"><a href="slr.html#cb70-15"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">.1</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb70-16"><a href="slr.html#cb70-16"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-68-1.png" width="384" /></p>
<p><strong>(2b) Find a transformation that yields a linear model</strong>
As done in example 1, use trial-and-error to find a transformation that yields a a linear relationship. Once this is found, we can fit a SLR model to the transformed variables. The basic transformations to consider (for <span class="math inline">\(y\)</span>, or <span class="math inline">\(x\)</span>, or both) are <code>log10</code> (log base-10), <code>sqrt</code>, and inverse.</p>
<p><strong>(2c) Fit the “best” model from (2b)</strong></p>
<p><strong>(2d) Once you find a model that “fits”, interpret your model parameters.</strong></p>
<ul>
<li>What is the fitted model?</li>
<li>How does cost change if house size is doubled? Get a CI for this effect.</li>
<li>How does cost change if house size decreases by 10%? Get a CI for the effect.</li>
</ul>
<hr />
</div>
</div>
<div id="r2-and-anova-for-slr" class="section level2">
<h2><span class="header-section-number">2.12</span> <span class="math inline">\(R^2\)</span> and ANOVA for SLR</h2>
<p>After we check the fit of a model and determine that there are no concerns with the SLR assumptions, we can summarize it with inference, interpretations and measures of “strength” of the association. One common measure of strength is called “R-squared”:
<span class="math display">\[
R^2 = 1- \dfrac{(n-2)\hat{\sigma}^2}{(n-1)s^2_y} 
\]</span>
<span class="math inline">\(R^2\)</span> measures the proportion of total variation in the response that is <strong>explained</strong> by the model. Total variation in <span class="math inline">\(y\)</span> is measured, in part, by the sample SD of the response, which is a piece of the denominator above. The numerator measures the varation in <span class="math inline">\(y\)</span> around the regression line (<span class="math inline">\(\hat{\sigma}\)</span>), which is a measure of <strong>unexplained</strong>, or residual, variation. One <em>minus</em> the unexplained variation proportion gives us the value of <span class="math inline">\(R^2\)</span>.</p>
<div id="example-r2" class="section level3">
<h3><span class="header-section-number">2.12.1</span> Example: <span class="math inline">\(R^2\)</span></h3>
<p>Let’s revisit the woodpecker nest depth model:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="slr.html#cb71-1"></a><span class="op">&gt;</span><span class="st"> </span>wpdata&lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://people.carleton.edu/~kstclair/data/woodpeckers.csv&quot;</span>)</span>
<span id="cb71-2"><a href="slr.html#cb71-2"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(ggplot2)</span>
<span id="cb71-3"><a href="slr.html#cb71-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">ggplot</span>(wpdata, <span class="kw">aes</span>(<span class="dt">x=</span>temp, <span class="dt">y=</span>depth)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb71-4"><a href="slr.html#cb71-4"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb71-5"><a href="slr.html#cb71-5"></a><span class="op">+</span><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb71-6"><a href="slr.html#cb71-6"></a><span class="op">+</span><span class="st">   </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;air temperature (C)&quot;</span>, <span class="dt">y=</span><span class="st">&quot;nest depth (cm)&quot;</span>, <span class="dt">title=</span><span class="st">&quot;woodpeckers scatterplot&quot;</span>)</span></code></pre></div>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-69-1.png" width="672" /></p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="slr.html#cb72-1"></a><span class="op">&gt;</span><span class="st"> </span>wood.lm&lt;-<span class="st"> </span><span class="kw">lm</span>(depth<span class="op">~</span>temp, <span class="dt">data=</span>wpdata)</span></code></pre></div>
<p>We get <span class="math inline">\(R^2\)</span> in the <code>Multiple R-squared</code> entry in the <code>lm</code> <code>summary</code> output:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="slr.html#cb73-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(wood.lm)</span>
<span id="cb73-2"><a href="slr.html#cb73-2"></a><span class="co">## </span></span>
<span id="cb73-3"><a href="slr.html#cb73-3"></a><span class="co">## Call:</span></span>
<span id="cb73-4"><a href="slr.html#cb73-4"></a><span class="co">## lm(formula = depth ~ temp, data = wpdata)</span></span>
<span id="cb73-5"><a href="slr.html#cb73-5"></a><span class="co">## </span></span>
<span id="cb73-6"><a href="slr.html#cb73-6"></a><span class="co">## Residuals:</span></span>
<span id="cb73-7"><a href="slr.html#cb73-7"></a><span class="co">##     Min      1Q  Median      3Q     Max </span></span>
<span id="cb73-8"><a href="slr.html#cb73-8"></a><span class="co">## -2.8066 -1.3321 -0.6529  0.6811  4.8512 </span></span>
<span id="cb73-9"><a href="slr.html#cb73-9"></a><span class="co">## </span></span>
<span id="cb73-10"><a href="slr.html#cb73-10"></a><span class="co">## Coefficients:</span></span>
<span id="cb73-11"><a href="slr.html#cb73-11"></a><span class="co">##             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb73-12"><a href="slr.html#cb73-12"></a><span class="co">## (Intercept) 20.12228    0.94024  21.401 1.11e-09 ***</span></span>
<span id="cb73-13"><a href="slr.html#cb73-13"></a><span class="co">## temp        -0.34218    0.05961  -5.741 0.000188 ***</span></span>
<span id="cb73-14"><a href="slr.html#cb73-14"></a><span class="co">## ---</span></span>
<span id="cb73-15"><a href="slr.html#cb73-15"></a><span class="co">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb73-16"><a href="slr.html#cb73-16"></a><span class="co">## </span></span>
<span id="cb73-17"><a href="slr.html#cb73-17"></a><span class="co">## Residual standard error: 2.335 on 10 degrees of freedom</span></span>
<span id="cb73-18"><a href="slr.html#cb73-18"></a><span class="co">## Multiple R-squared:  0.7672,	Adjusted R-squared:  0.7439 </span></span>
<span id="cb73-19"><a href="slr.html#cb73-19"></a><span class="co">## F-statistic: 32.96 on 1 and 10 DF,  p-value: 0.0001875</span></span></code></pre></div>
<p>Here we have <span class="math inline">\(R^2 = 0.7672\)</span>, meaning the regression of depth on temp helps explain about 76.7% of the observed variation in depth. We can see how R computes this value by looking at the sample SD of <span class="math inline">\(y\)</span>, <span class="math inline">\(s^2_y = 4.6133124\)</span> and the estimated model SD <span class="math inline">\(\hat{\sigma} =2.3345298\)</span></p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="slr.html#cb74-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">sd</span>(wpdata<span class="op">$</span>depth)        <span class="co"># sample SD of y</span></span>
<span id="cb74-2"><a href="slr.html#cb74-2"></a><span class="co">## [1] 4.613312</span></span>
<span id="cb74-3"><a href="slr.html#cb74-3"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(wood.lm)<span class="op">$</span>sigma  <span class="co"># mode SD estimate</span></span>
<span id="cb74-4"><a href="slr.html#cb74-4"></a><span class="co">## [1] 2.33453</span></span>
<span id="cb74-5"><a href="slr.html#cb74-5"></a><span class="op">&gt;</span><span class="st"> </span>n &lt;-<span class="st"> </span><span class="dv">12</span></span>
<span id="cb74-6"><a href="slr.html#cb74-6"></a><span class="op">&gt;</span><span class="st"> </span>(n<span class="dv">-2</span>)<span class="op">*</span><span class="kw">summary</span>(wood.lm)<span class="op">$</span>sigma<span class="op">^</span><span class="dv">2</span><span class="op">/</span>((n<span class="dv">-1</span>)<span class="op">*</span><span class="kw">sd</span>(wpdata<span class="op">$</span>depth)<span class="op">^</span><span class="dv">2</span>)   <span class="co"># unexplained</span></span>
<span id="cb74-7"><a href="slr.html#cb74-7"></a><span class="co">## [1] 0.2327986</span></span>
<span id="cb74-8"><a href="slr.html#cb74-8"></a><span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(n<span class="dv">-2</span>)<span class="op">*</span><span class="kw">summary</span>(wood.lm)<span class="op">$</span>sigma<span class="op">^</span><span class="dv">2</span><span class="op">/</span>((n<span class="dv">-1</span>)<span class="op">*</span><span class="kw">sd</span>(wpdata<span class="op">$</span>depth)<span class="op">^</span><span class="dv">2</span>)  <span class="co"># explained</span></span>
<span id="cb74-9"><a href="slr.html#cb74-9"></a><span class="co">## [1] 0.7672014</span></span></code></pre></div>
</div>
<div id="slr-anova" class="section level3">
<h3><span class="header-section-number">2.12.2</span> ANOVA for SLR</h3>
<p>Analysis of Variance (ANOVA) decomposes the <strong>total variation in <span class="math inline">\(y_i\)</span></strong>, <span class="math inline">\(y_i - \bar{y}\)</span>, into a portion that is <strong>explained</strong> by a model, <span class="math inline">\(\hat{y}_i - \bar{y}\)</span>, and a portion that is <strong>unexplained</strong>, <span class="math inline">\(y_i - \hat{y}_i\)</span>:
<span class="math display">\[
y_i - \bar{y} = (y_i - \hat{y}_i) + (\hat{y}_i - \bar{y})
\]</span>
For row 2 in the <code>wpdata</code>, the total variation is show in red in the plot below while the explained variation is in blue and unexplained in green. Notice that the “explained” portion is what gets us closer to the actual response <span class="math inline">\(y=26\)</span> (compared to just the mean response), which is what you would expect to see if temp is useful in explaining why we see variation in nest depths.</p>
<p><img src="Math245notes_files/figure-html/unnamed-chunk-72-1.png" width="672" /></p>
<p>The next step in ANOVA, is to total the <strong>squared</strong> variation distances across all <span class="math inline">\(n\)</span> data points (squared because we don’t care if the differences are positive or negative). Some very useful mathematics is used to prove that the total squared variation of all <span class="math inline">\(n\)</span> cases is equal to
<span class="math display">\[
\sum_{i=1}^n (y_i - \bar{y})^2 = \sum_{i=1}^n  (y_i - \hat{y}_i)^2 + \sum_{i=1}^n  (\hat{y}_i - \bar{y})^2
\]</span></p>
<p>The three components are called:</p>
<ul>
<li><strong>total variation:</strong> <span class="math inline">\(SST = \sum_{i=1}^n (y_i - \bar{y})^2 = (n-1)s^2_y\)</span></li>
<li><strong>regression (explained) variation:</strong> <span class="math inline">\(SSreg = \sum_{i=1}^n (\hat{y}_i - \bar{y})^2\)</span></li>
<li><strong>residual (unexplained) variation:</strong> <span class="math inline">\(SSR = \sum_{i=1}^n (y_i - \hat{y}_i)^2 = (n-2)\hat{\sigma}^2\)</span></li>
</ul>
<p>These sum of squares (SS) can also be used to compute <span class="math inline">\(R^2\)</span> since
<span class="math display">\[
R^2 = 1- \dfrac{(n-2)\hat{\sigma}^2}{(n-1)s^2_y} = 1- \dfrac{SSR}{SST} = \dfrac{SSreg}{SST}
\]</span></p>
</div>
<div id="example-anova" class="section level3">
<h3><span class="header-section-number">2.12.3</span> Example: ANOVA</h3>
<p>Back to the nest depth model. The <code>anova</code> function extracts the sum of square values from our <code>lm</code>:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="slr.html#cb75-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">anova</span>(wood.lm)   <span class="co"># ANOVA Table</span></span>
<span id="cb75-2"><a href="slr.html#cb75-2"></a><span class="co">## Analysis of Variance Table</span></span>
<span id="cb75-3"><a href="slr.html#cb75-3"></a><span class="co">## </span></span>
<span id="cb75-4"><a href="slr.html#cb75-4"></a><span class="co">## Response: depth</span></span>
<span id="cb75-5"><a href="slr.html#cb75-5"></a><span class="co">##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    </span></span>
<span id="cb75-6"><a href="slr.html#cb75-6"></a><span class="co">## temp       1 179.61  179.61  32.956 0.0001875 ***</span></span>
<span id="cb75-7"><a href="slr.html#cb75-7"></a><span class="co">## Residuals 10  54.50    5.45                      </span></span>
<span id="cb75-8"><a href="slr.html#cb75-8"></a><span class="co">## ---</span></span>
<span id="cb75-9"><a href="slr.html#cb75-9"></a><span class="co">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span></code></pre></div>
<p>For this model we have
- <strong>regression (explained) variation:</strong> from the <code>temp</code> row, <span class="math inline">\(SSreg = 179.61\)</span>
- <strong>residual (unexplained) variation:</strong> from the <code>Residuals</code> row, <span class="math inline">\(SSR = 54.60\)</span>
- <strong>total variation:</strong> adding the two SS values gives total variation <span class="math inline">\(SST = SSreg + SSR = 179.61 + 54.60 = 234.21\)</span></p>
<p>The ANOVA SS can also give us the value of <span class="math inline">\(R^2\)</span> for the model:
<span class="math display">\[
R^2 =  \dfrac{179.61}{179.61 + 54.60} = 0.7668759
\]</span></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="review.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mlr.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
